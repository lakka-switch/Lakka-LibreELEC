From d7b42091953fb77f80afec9c96e9605828a226b8 Mon Sep 17 00:00:00 2001
From: lufi <lufi@>
Date: Tue, 24 Jul 2018 20:18:46 -0400
Subject: [PATCH 1/8] First iteration of switch

Add CI/CD

Some optimizations, seems that everything here is more or less actually needed.

Remove hardcoded path

OK

works but graphics issues

committing

Fixed graphics artifacts

Merged branches together (nf and non-_nf)

compile flags

wow this works!

yes

Added the files

Update Makefile

Remove leftovers, cleanup libnx target.

Fix Threading stacksize and conflicts, parity with RA codebase
---
 .gitignore                                    |    3 +
 Makefile                                      |    6 +-
 Makefile.libretro                             |   27 +
 frontend/libretro.c                           |   11 +-
 frontend/main.c                               |    2 +-
 frontend/plugin_lib.c                         |    1 +
 frontend/switch/pthread.c                     |   60 +
 frontend/switch/pthread.h                     |  166 ++
 frontend/switch/sys/mman.h                    |  125 ++
 frontend/switch/zconf.h                       |  511 +++++
 frontend/switch/zlib.h                        | 1768 +++++++++++++++
 libpcsxcore/mdec.c                            |    2 +-
 libpcsxcore/new_dynarec/backends/psx/emu_if.c |   17 +-
 libpcsxcore/psxbios.c                         |  100 +-
 libpcsxcore/psxcommon.h                       |    2 +
 plugins/gpu_unai/README_senquack.txt          |  956 ++++++++
 plugins/gpu_unai/debug.h                      |    0
 plugins/gpu_unai/gpu.cpp                      | 1059 ++++-----
 plugins/gpu_unai/gpu.h                        |   99 +-
 plugins/gpu_unai/gpu_blit.h                   |   24 +-
 plugins/gpu_unai/gpu_command.h                |  669 +++---
 plugins/gpu_unai/gpu_fixedpoint.h             |  107 +-
 plugins/gpu_unai/gpu_inner.h                  |  913 +++++---
 plugins/gpu_unai/gpu_inner_blend.h            |  268 ++-
 plugins/gpu_unai/gpu_inner_blend_arm5.h       |  100 +
 plugins/gpu_unai/gpu_inner_blend_arm7.h       |  107 +
 plugins/gpu_unai/gpu_inner_light.h            |  293 ++-
 plugins/gpu_unai/gpu_inner_quantization.h     |  108 +
 plugins/gpu_unai/gpu_raster_image.h           |   98 +-
 plugins/gpu_unai/gpu_raster_line.h            |  874 ++++++--
 plugins/gpu_unai/gpu_raster_polygon.h         | 1997 +++++++++++------
 plugins/gpu_unai/gpu_raster_sprite.h          |  217 +-
 plugins/gpu_unai/gpu_unai.h                   |  315 +++
 plugins/gpu_unai/gpulib_if.cpp                |  714 +++---
 plugins/gpu_unai/port.h                       |   36 -
 plugins/gpu_unai/profiler.h                   |    4 -
 plugins/gpulib/gpu.c                          |  103 +-
 37 files changed, 8981 insertions(+), 2881 deletions(-)
 create mode 100644 frontend/switch/pthread.c
 create mode 100644 frontend/switch/pthread.h
 create mode 100644 frontend/switch/sys/mman.h
 create mode 100644 frontend/switch/zconf.h
 create mode 100644 frontend/switch/zlib.h
 create mode 100644 plugins/gpu_unai/README_senquack.txt
 delete mode 100644 plugins/gpu_unai/debug.h
 create mode 100644 plugins/gpu_unai/gpu_inner_blend_arm5.h
 create mode 100644 plugins/gpu_unai/gpu_inner_blend_arm7.h
 create mode 100644 plugins/gpu_unai/gpu_inner_quantization.h
 create mode 100644 plugins/gpu_unai/gpu_unai.h
 delete mode 100644 plugins/gpu_unai/port.h
 delete mode 100644 plugins/gpu_unai/profiler.h

diff --git a/.gitignore b/.gitignore
index 25002703..27671da9 100644
--- a/.gitignore
+++ b/.gitignore
@@ -11,3 +11,6 @@ frontend/revision.h
 tools
 .pcsx/
 obj/
+
+# Switch
+*.d
diff --git a/Makefile b/Makefile
index 98498c87..18529795 100644
--- a/Makefile
+++ b/Makefile
@@ -9,7 +9,7 @@ else
 ifeq ($(platform), vita)
 CFLAGS += -O3 -DNDEBUG
 else
-CFLAGS += -O2 -DNDEBUG
+CFLAGS += -O3 -DNDEBUG
 endif
 endif
 CXXFLAGS += $(CFLAGS)
@@ -151,7 +151,7 @@ OBJS += plugins/gpu_unai/gpulib_if.o
 ifeq "$(ARCH)" "arm"
 OBJS += plugins/gpu_unai/gpu_arm.o
 endif
-plugins/gpu_unai/gpulib_if.o: CFLAGS += -DREARMED -O3 
+plugins/gpu_unai/gpulib_if.o: CFLAGS += -DREARMED -O3
 CC_LINK = $(CXX)
 endif
 
@@ -315,7 +315,7 @@ frontend/libpicofe/%.c:
 	@exit 1
 
 libpcsxcore/gte_nf.o: libpcsxcore/gte.c
-	$(CC) -c -o $@ $^ $(CFLAGS) -DFLAGLESS
+	$(CC) -c -o $@ $^ $(CFLAGS)
 
 frontend/revision.h: FORCE
 	@(git describe || echo) | sed -e 's/.*/#define REV "\0"/' > $@_
diff --git a/Makefile.libretro b/Makefile.libretro
index c40f64b7..3da2a39e 100644
--- a/Makefile.libretro
+++ b/Makefile.libretro
@@ -22,6 +22,10 @@ AS ?= as
 CC_AS ?= $(CC)
 CFLAGS ?=
 
+CFLAGS += -DINLINE="static __inline__" -Dasm="__asm__ __volatile__" -DUSE_GPULIB=1
+USE_DYNAREC = 0
+BUILTIN_GPU = unai
+
 TARGET_NAME := pcsx_rearmed
 GIT_VERSION := " $(shell git rev-parse --short HEAD || echo unknown)"
 ifneq ($(GIT_VERSION)," unknown")
@@ -40,10 +44,13 @@ LIBM := -lm
 MMAP_WIN32 = 0
 EXTRA_LDFLAGS =
 
+
 # Unix
 ifeq ($(platform), unix)
 	TARGET := $(TARGET_NAME)_libretro.so
 	fpic := -fPIC
+	BUILTIN_GPU = unai
+	USE_DYNAREC = 0
 ifneq ($(findstring SunOS,$(shell uname -s)),)
 	CC = gcc
 endif
@@ -83,6 +90,26 @@ else ifeq ($(platform),$(filter $(platform),ios-arm64))
 	BUILTIN_GPU = peops
 	TARGET := $(TARGET_NAME)_libretro_ios.dylib
 
+# Nintendo Switch (libnx)
+else ifeq ($(platform), libnx)
+   export DEPSDIR := $(CURDIR)/
+   include $(DEVKITPRO)/libnx/switch_rules
+   TARGET := $(TARGET_NAME)_libretro_$(platform).a
+   ARCH := arm64
+   BUILTIN_GPU = unai
+   HAVE_VFS_FD = 0
+   DEFINES_THREAD := -Dpthread_t=Thread -Dpthread_mutex_t=Mutex -Dpthread_mutexattr_t='void*' -Dpthread_attr_t=int -Dpthread_cond_t=CondVar -Dpthread_condattr_t='int' -D_SYS__PTHREADTYPES_H_
+   CFLAGS += -O3 -fomit-frame-pointer -ffast-math -I$(DEVKITPRO)/libnx/include/ -fPIE -Wl,--allow-multiple-definition -include $(LIBNX)/include/switch.h
+   CFLAGS += -specs=$(DEVKITPRO)/libnx/switch.specs -DNO_OS -DNO_DYLIB -DNO_SOCKET -D__arm64__ -D__ARM_NEON__
+   CFLAGS += -D__SWITCH__
+   CFLAGS += -DARM -D__aarch64__=1 -march=armv8-a -mtune=cortex-a57 -mtp=soft -DHAVE_INTTYPES -DLSB_FIRST -DINLINE=inline -ffast-math -mcpu=cortex-a57+crc+fp+simd -ffunction-sections
+   CFLAGS += -Ifrontend/switch -ftree-vectorize
+   CFLAGS += $(DEFINES_THREAD)
+   OBJS += frontend/switch/pthread.o
+   LIBPTHREAD :=
+   USE_DYNAREC = 0
+   STATIC_LINKING=1
+
 else ifneq (,$(findstring ios,$(platform)))
 	ARCH := arm
 	USE_DYNAREC ?= 1
diff --git a/frontend/libretro.c b/frontend/libretro.c
index 31872f4d..4fe35cb4 100644
--- a/frontend/libretro.c
+++ b/frontend/libretro.c
@@ -15,6 +15,10 @@
 #include <sys/syscall.h>
 #endif
 
+#ifdef SWITCH
+#include <switch.h>
+#endif
+
 #include "../libpcsxcore/misc.h"
 #include "../libpcsxcore/psxcounters.h"
 #include "../libpcsxcore/psxmem_map.h"
@@ -38,6 +42,11 @@
 #include "3ds/3ds_utils.h"
 #endif
 
+//#ifdef SWITCH
+//#include <switch.h>
+//#endif
+
+
 #define PORTS_NUMBER 8
 
 #ifndef MIN
@@ -2063,7 +2072,7 @@ void retro_init(void)
 
 #ifdef _3DS
    vout_buf = linearMemAlign(VOUT_MAX_WIDTH * VOUT_MAX_HEIGHT * 2, 0x80);
-#elif defined(_POSIX_C_SOURCE) && (_POSIX_C_SOURCE >= 200112L) && !defined(VITA)
+#elif defined(_POSIX_C_SOURCE) && (_POSIX_C_SOURCE >= 200112L) && !defined(VITA) && !defined(__SWITCH__)
 	posix_memalign(&vout_buf, 16, VOUT_MAX_WIDTH * VOUT_MAX_HEIGHT * 2);
 #else
 	vout_buf = malloc(VOUT_MAX_WIDTH * VOUT_MAX_HEIGHT * 2);
diff --git a/frontend/main.c b/frontend/main.c
index 860dec0d..45d25288 100644
--- a/frontend/main.c
+++ b/frontend/main.c
@@ -773,7 +773,7 @@ int emu_save_state(int slot)
 		return ret;
 
 	ret = SaveState(fname);
-#if defined(HAVE_PRE_ARMV7) && !defined(_3DS) /* XXX GPH hack */
+#if defined(HAVE_PRE_ARMV7) && !defined(_3DS) && !defined(__SWITCH__) /* XXX GPH hack */
 	sync();
 #endif
 	SysPrintf("* %s \"%s\" [%d]\n",
diff --git a/frontend/plugin_lib.c b/frontend/plugin_lib.c
index eee255b7..af4c596b 100644
--- a/frontend/plugin_lib.c
+++ b/frontend/plugin_lib.c
@@ -859,3 +859,4 @@ void pl_init(void)
 	psxMapHook = pl_emu_mmap;
 	psxUnmapHook = pl_emu_munmap;
 }
+
diff --git a/frontend/switch/pthread.c b/frontend/switch/pthread.c
new file mode 100644
index 00000000..beab4376
--- /dev/null
+++ b/frontend/switch/pthread.c
@@ -0,0 +1,60 @@
+/* Copyright  (C) 2018 - M4xw <m4x@m4xw.net>, RetroArch Team
+ *
+ * ---------------------------------------------------------------------------------------
+ * The following license statement only applies to this file (switch_pthread.c).
+ * ---------------------------------------------------------------------------------------
+ *
+ * Permission is hereby granted, free of charge,
+ * to any person obtaining a copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation the rights to
+ * use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,
+ * and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ * WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+#include "pthread.h"
+
+#define STACKSIZE 1000000 * 12 // 12 MB
+static uint32_t threadCounter = 1;
+int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine)(void *), void *arg)
+{
+   u32 prio = 0;
+
+   Thread new_switch_thread;
+
+   svcGetThreadPriority(&prio, CUR_THREAD_HANDLE);
+
+   // Launch threads on Core 1
+   int rc = threadCreate(&new_switch_thread, (void (*)(void *))start_routine, arg, STACKSIZE, prio - 1, 1);
+
+   if (R_FAILED(rc))
+   {
+      return EAGAIN;
+   }
+
+   printf("[Threading]: Starting Thread(#%i)\n", threadCounter);
+   if (R_FAILED(threadStart(&new_switch_thread)))
+   {
+      threadClose(&new_switch_thread);
+      return -1;
+   }
+
+   *thread = new_switch_thread;
+
+   return 0;
+}
+
+void pthread_exit(void *retval)
+{
+   (void)retval;
+   printf("[Threading]: Exiting Thread\n");
+   svcExitThread();
+}
diff --git a/frontend/switch/pthread.h b/frontend/switch/pthread.h
new file mode 100644
index 00000000..d01fd8cf
--- /dev/null
+++ b/frontend/switch/pthread.h
@@ -0,0 +1,166 @@
+/* Copyright  (C) 2018 - M4xw <m4x@m4xw.net>, RetroArch Team
+ *
+ * ---------------------------------------------------------------------------------------
+ * The following license statement only applies to this file (switch_pthread.h).
+ * ---------------------------------------------------------------------------------------
+ *
+ * Permission is hereby granted, free of charge,
+ * to any person obtaining a copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation the rights to
+ * use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,
+ * and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
+ * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ * WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+#ifndef _SWITCH_PTHREAD_WRAP_
+#define _SWITCH_PTHREAD_WRAP_
+
+#include <time.h>
+#include <stdio.h>
+#include <switch.h>
+#include <errno.h>
+
+#define THREADVARS_MAGIC 0x21545624 /* !TV$ */
+int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine)(void *), void *arg);
+void pthread_exit(void *retval);
+
+/* This structure is exactly 0x20 bytes, if more is needed modify getThreadVars() below */
+typedef struct
+{
+   /* Magic value used to check if the struct is initialized */
+   u32 magic;
+
+   /* Thread handle, for mutexes */
+   Handle handle;
+
+   /* Pointer to the current thread (if exists) */
+   Thread *thread_ptr;
+
+   /* Pointer to this thread's newlib state */
+   struct _reent *reent;
+
+   /* Pointer to this thread's thread-local segment */
+   void *tls_tp; /* !! Offset needs to be TLS+0x1F8 for __aarch64_read_tp !! */
+} ThreadVars;
+
+static INLINE ThreadVars *getThreadVars(void)
+{
+   return (ThreadVars *)((u8 *)armGetTls() + 0x1E0);
+}
+
+static INLINE Thread threadGetCurrent(void)
+{
+   ThreadVars *tv = getThreadVars();
+   return *tv->thread_ptr;
+}
+
+static INLINE pthread_t pthread_self(void)
+{
+   return threadGetCurrent();
+}
+
+static INLINE int pthread_mutex_init(pthread_mutex_t *mutex, const pthread_mutexattr_t *attr)
+{
+   mutexInit(mutex);
+
+   return 0;
+}
+
+static INLINE int pthread_mutex_destroy(pthread_mutex_t *mutex)
+{
+   /* Nothing */
+   *mutex = 0;
+
+   return 0;
+}
+
+static INLINE int pthread_mutex_lock(pthread_mutex_t *mutex)
+{
+   mutexLock(mutex);
+   return 0;
+}
+
+static INLINE int pthread_mutex_unlock(pthread_mutex_t *mutex)
+{
+   mutexUnlock(mutex);
+
+   return 0;
+}
+
+INLINE int pthread_detach(pthread_t thread)
+{
+   (void)thread;
+   /* Nothing for now */
+   return 0;
+}
+
+static INLINE int pthread_join(pthread_t thread, void **retval)
+{
+   printf("[Threading]: Waiting for Thread Exit\n");
+   threadWaitForExit(&thread);
+   threadClose(&thread);
+
+   return 0;
+}
+
+static INLINE int pthread_mutex_trylock(pthread_mutex_t *mutex)
+{
+   return mutexTryLock(mutex) ? 0 : 1;
+}
+
+static INLINE int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex)
+{
+   condvarWait(cond, mutex);
+
+   return 0;
+}
+
+static INLINE int pthread_cond_timedwait(pthread_cond_t *cond, pthread_mutex_t *mutex, const struct timespec *abstime)
+{
+   condvarWaitTimeout(cond, mutex, abstime->tv_nsec);
+
+   return 0;
+}
+
+static INLINE int pthread_cond_init(pthread_cond_t *cond, const pthread_condattr_t *attr)
+{
+   condvarInit(cond);
+
+   return 0;
+}
+
+static INLINE int pthread_cond_signal(pthread_cond_t *cond)
+{
+   condvarWakeOne(cond);
+   return 0;
+}
+
+static INLINE int pthread_cond_broadcast(pthread_cond_t *cond)
+{
+   condvarWakeAll(cond);
+   return 0;
+}
+
+INLINE int pthread_cond_destroy(pthread_cond_t *cond)
+{
+   /* Nothing */
+   return 0;
+}
+
+INLINE int pthread_equal(pthread_t t1, pthread_t t2)
+{
+   if (t1.handle == t2.handle)
+      return 1;
+
+   return 0;
+}
+
+#endif
diff --git a/frontend/switch/sys/mman.h b/frontend/switch/sys/mman.h
new file mode 100644
index 00000000..5e8d22ef
--- /dev/null
+++ b/frontend/switch/sys/mman.h
@@ -0,0 +1,125 @@
+#ifndef MMAN_H
+#define MMAN_H
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include <stdlib.h>
+#include <stdio.h>
+#include <stdint.h>
+#include <malloc.h>
+#include <switch.h>
+#include <stdlib.h>
+
+//#include "3ds_utils.h"
+
+#define PROT_READ       0b001
+#define PROT_WRITE      0b010
+#define PROT_EXEC       0b100
+#define MAP_PRIVATE     2
+#define MAP_FIXED       0x10
+#define MAP_ANONYMOUS   0x20
+
+#define MAP_FAILED      ((void *)-1)
+
+static void* dynarec_cache = NULL;
+static void* dynarec_cache_mapping = NULL;
+
+static inline void* mmap(void *addr, size_t len, int prot, int flags, int fd, off_t offset)
+{
+   (void)fd;
+   (void)offset;
+
+   //void* addr_out;
+    Result rc = svcMapPhysicalMemory(addr, len);
+    if (R_FAILED(rc))
+    {
+        printf("mmap failed\n");
+        return malloc(len);
+    }
+
+    return addr;
+
+//   if((prot == (PROT_READ | PROT_WRITE | PROT_EXEC)) &&
+//      (flags == (MAP_PRIVATE | MAP_ANONYMOUS)))
+//   {
+//      if(true)// __ctr_svchax)
+//     {
+//         /* this hack works only for pcsx_rearmed */
+//         uint32_t currentHandle;
+//
+//         if(!dynarec_cache)
+//            dynarec_cache = memalign(0x1000, len);
+//
+//         //svcDuplicateHandle(&currentHandle, 0xFFFF8001);
+//         //svcControlProcessMemory(currentHandle, addr, dynarec_cache,
+//         //                        len, MEMOP_MAP, prot);
+//         svcCloseHandle(currentHandle);
+//         dynarec_cache_mapping = addr;
+//         return addr;
+//      }
+//      else
+//      {
+//         printf("tried to mmap RWX pages without svcControlProcessMemory access !\n");
+//         return MAP_FAILED;
+//      }
+//
+//   }
+
+//   addr_out = memalign(0x1000, len);
+//   if(!addr_out)
+//      return MAP_FAILED;
+//
+//   return addr_out;
+}
+
+static inline int mprotect(void *addr, size_t len, int prot)
+{
+    return 0;
+   //if(true) // __ctr_svchax)
+   //{
+   //   uint32_t currentHandle;
+   //   //svcDuplicateHandle(&currentHandle, 0xFFFF8001);
+   //   //svcControlProcessMemory(currentHandle, addr, NULL,
+   //   //                        len, MEMOP_PROT, prot);
+   //   svcCloseHandle(currentHandle);
+   //   return 0;
+   //}
+
+   //printf("mprotect called without svcControlProcessMemory access !\n");
+   //return -1;
+}
+
+static inline int munmap(void *addr, size_t len)
+{
+    Result rc = svcUnmapPhysicalMemory(addr, len);
+    if (R_FAILED(rc))
+    {
+        printf("munmap failed\n");
+        free(addr);
+    }
+    return 0;
+//   if((addr == dynarec_cache_mapping) && true)//__ctr_svchax)
+//   {
+//      uint32_t currentHandle;
+//      //svcDuplicateHandle(&currentHandle, 0xFFFF8001);
+//      //svcControlProcessMemory(currentHandle,
+//      //                        dynarec_cache, dynarec_cache_mapping,
+//      //                        len, MEMOP_UNMAP, 0b111);
+//      svcCloseHandle(currentHandle);
+//      dynarec_cache_mapping = NULL;
+//
+//   }
+//   else
+      free(addr);
+
+   return 0;
+}
+
+#ifdef __cplusplus
+};
+#endif
+
+#endif // MMAN_H
+
diff --git a/frontend/switch/zconf.h b/frontend/switch/zconf.h
new file mode 100644
index 00000000..996fff29
--- /dev/null
+++ b/frontend/switch/zconf.h
@@ -0,0 +1,511 @@
+/* zconf.h -- configuration of the zlib compression library
+ * Copyright (C) 1995-2013 Jean-loup Gailly.
+ * For conditions of distribution and use, see copyright notice in zlib.h
+ */
+
+/* @(#) $Id$ */
+
+#ifndef ZCONF_H
+#define ZCONF_H
+
+/*
+ * If you *really* need a unique prefix for all types and library functions,
+ * compile with -DZ_PREFIX. The "standard" zlib should be compiled without it.
+ * Even better than compiling with -DZ_PREFIX would be to use configure to set
+ * this permanently in zconf.h using "./configure --zprefix".
+ */
+#ifdef Z_PREFIX     /* may be set to #if 1 by ./configure */
+#  define Z_PREFIX_SET
+
+/* all linked symbols */
+#  define _dist_code            z__dist_code
+#  define _length_code          z__length_code
+#  define _tr_align             z__tr_align
+#  define _tr_flush_bits        z__tr_flush_bits
+#  define _tr_flush_block       z__tr_flush_block
+#  define _tr_init              z__tr_init
+#  define _tr_stored_block      z__tr_stored_block
+#  define _tr_tally             z__tr_tally
+#  define adler32               z_adler32
+#  define adler32_combine       z_adler32_combine
+#  define adler32_combine64     z_adler32_combine64
+#  ifndef Z_SOLO
+#    define compress              z_compress
+#    define compress2             z_compress2
+#    define compressBound         z_compressBound
+#  endif
+#  define crc32                 z_crc32
+#  define crc32_combine         z_crc32_combine
+#  define crc32_combine64       z_crc32_combine64
+#  define deflate               z_deflate
+#  define deflateBound          z_deflateBound
+#  define deflateCopy           z_deflateCopy
+#  define deflateEnd            z_deflateEnd
+#  define deflateInit2_         z_deflateInit2_
+#  define deflateInit_          z_deflateInit_
+#  define deflateParams         z_deflateParams
+#  define deflatePending        z_deflatePending
+#  define deflatePrime          z_deflatePrime
+#  define deflateReset          z_deflateReset
+#  define deflateResetKeep      z_deflateResetKeep
+#  define deflateSetDictionary  z_deflateSetDictionary
+#  define deflateSetHeader      z_deflateSetHeader
+#  define deflateTune           z_deflateTune
+#  define deflate_copyright     z_deflate_copyright
+#  define get_crc_table         z_get_crc_table
+#  ifndef Z_SOLO
+#    define gz_error              z_gz_error
+#    define gz_intmax             z_gz_intmax
+#    define gz_strwinerror        z_gz_strwinerror
+#    define gzbuffer              z_gzbuffer
+#    define gzclearerr            z_gzclearerr
+#    define gzclose               z_gzclose
+#    define gzclose_r             z_gzclose_r
+#    define gzclose_w             z_gzclose_w
+#    define gzdirect              z_gzdirect
+#    define gzdopen               z_gzdopen
+#    define gzeof                 z_gzeof
+#    define gzerror               z_gzerror
+#    define gzflush               z_gzflush
+#    define gzgetc                z_gzgetc
+#    define gzgetc_               z_gzgetc_
+#    define gzgets                z_gzgets
+#    define gzoffset              z_gzoffset
+#    define gzoffset64            z_gzoffset64
+#    define gzopen                z_gzopen
+#    define gzopen64              z_gzopen64
+#    ifdef _WIN32
+#      define gzopen_w              z_gzopen_w
+#    endif
+#    define gzprintf              z_gzprintf
+#    define gzvprintf             z_gzvprintf
+#    define gzputc                z_gzputc
+#    define gzputs                z_gzputs
+#    define gzread                z_gzread
+#    define gzrewind              z_gzrewind
+#    define gzseek                z_gzseek
+#    define gzseek64              z_gzseek64
+#    define gzsetparams           z_gzsetparams
+#    define gztell                z_gztell
+#    define gztell64              z_gztell64
+#    define gzungetc              z_gzungetc
+#    define gzwrite               z_gzwrite
+#  endif
+#  define inflate               z_inflate
+#  define inflateBack           z_inflateBack
+#  define inflateBackEnd        z_inflateBackEnd
+#  define inflateBackInit_      z_inflateBackInit_
+#  define inflateCopy           z_inflateCopy
+#  define inflateEnd            z_inflateEnd
+#  define inflateGetHeader      z_inflateGetHeader
+#  define inflateInit2_         z_inflateInit2_
+#  define inflateInit_          z_inflateInit_
+#  define inflateMark           z_inflateMark
+#  define inflatePrime          z_inflatePrime
+#  define inflateReset          z_inflateReset
+#  define inflateReset2         z_inflateReset2
+#  define inflateSetDictionary  z_inflateSetDictionary
+#  define inflateGetDictionary  z_inflateGetDictionary
+#  define inflateSync           z_inflateSync
+#  define inflateSyncPoint      z_inflateSyncPoint
+#  define inflateUndermine      z_inflateUndermine
+#  define inflateResetKeep      z_inflateResetKeep
+#  define inflate_copyright     z_inflate_copyright
+#  define inflate_fast          z_inflate_fast
+#  define inflate_table         z_inflate_table
+#  ifndef Z_SOLO
+#    define uncompress            z_uncompress
+#  endif
+#  define zError                z_zError
+#  ifndef Z_SOLO
+#    define zcalloc               z_zcalloc
+#    define zcfree                z_zcfree
+#  endif
+#  define zlibCompileFlags      z_zlibCompileFlags
+#  define zlibVersion           z_zlibVersion
+
+/* all zlib typedefs in zlib.h and zconf.h */
+#  define Byte                  z_Byte
+#  define Bytef                 z_Bytef
+#  define alloc_func            z_alloc_func
+#  define charf                 z_charf
+#  define free_func             z_free_func
+#  ifndef Z_SOLO
+#    define gzFile                z_gzFile
+#  endif
+#  define gz_header             z_gz_header
+#  define gz_headerp            z_gz_headerp
+#  define in_func               z_in_func
+#  define intf                  z_intf
+#  define out_func              z_out_func
+#  define uInt                  z_uInt
+#  define uIntf                 z_uIntf
+#  define uLong                 z_uLong
+#  define uLongf                z_uLongf
+#  define voidp                 z_voidp
+#  define voidpc                z_voidpc
+#  define voidpf                z_voidpf
+
+/* all zlib structs in zlib.h and zconf.h */
+#  define gz_header_s           z_gz_header_s
+#  define internal_state        z_internal_state
+
+#endif
+
+#if defined(__MSDOS__) && !defined(MSDOS)
+#  define MSDOS
+#endif
+#if (defined(OS_2) || defined(__OS2__)) && !defined(OS2)
+#  define OS2
+#endif
+#if defined(_WINDOWS) && !defined(WINDOWS)
+#  define WINDOWS
+#endif
+#if defined(_WIN32) || defined(_WIN32_WCE) || defined(__WIN32__)
+#  ifndef WIN32
+#    define WIN32
+#  endif
+#endif
+#if (defined(MSDOS) || defined(OS2) || defined(WINDOWS)) && !defined(WIN32)
+#  if !defined(__GNUC__) && !defined(__FLAT__) && !defined(__386__)
+#    ifndef SYS16BIT
+#      define SYS16BIT
+#    endif
+#  endif
+#endif
+
+/*
+ * Compile with -DMAXSEG_64K if the alloc function cannot allocate more
+ * than 64k bytes at a time (needed on systems with 16-bit int).
+ */
+#ifdef SYS16BIT
+#  define MAXSEG_64K
+#endif
+#ifdef MSDOS
+#  define UNALIGNED_OK
+#endif
+
+#ifdef __STDC_VERSION__
+#  ifndef STDC
+#    define STDC
+#  endif
+#  if __STDC_VERSION__ >= 199901L
+#    ifndef STDC99
+#      define STDC99
+#    endif
+#  endif
+#endif
+#if !defined(STDC) && (defined(__STDC__) || defined(__cplusplus))
+#  define STDC
+#endif
+#if !defined(STDC) && (defined(__GNUC__) || defined(__BORLANDC__))
+#  define STDC
+#endif
+#if !defined(STDC) && (defined(MSDOS) || defined(WINDOWS) || defined(WIN32))
+#  define STDC
+#endif
+#if !defined(STDC) && (defined(OS2) || defined(__HOS_AIX__))
+#  define STDC
+#endif
+
+#if defined(__OS400__) && !defined(STDC)    /* iSeries (formerly AS/400). */
+#  define STDC
+#endif
+
+#ifndef STDC
+#  ifndef const /* cannot use !defined(STDC) && !defined(const) on Mac */
+#    define const       /* note: need a more gentle solution here */
+#  endif
+#endif
+
+#if defined(ZLIB_CONST) && !defined(z_const)
+#  define z_const const
+#else
+#  define z_const
+#endif
+
+/* Some Mac compilers merge all .h files incorrectly: */
+#if defined(__MWERKS__)||defined(applec)||defined(THINK_C)||defined(__SC__)
+#  define NO_DUMMY_DECL
+#endif
+
+/* Maximum value for memLevel in deflateInit2 */
+#ifndef MAX_MEM_LEVEL
+#  ifdef MAXSEG_64K
+#    define MAX_MEM_LEVEL 8
+#  else
+#    define MAX_MEM_LEVEL 9
+#  endif
+#endif
+
+/* Maximum value for windowBits in deflateInit2 and inflateInit2.
+ * WARNING: reducing MAX_WBITS makes minigzip unable to extract .gz files
+ * created by gzip. (Files created by minigzip can still be extracted by
+ * gzip.)
+ */
+#ifndef MAX_WBITS
+#  define MAX_WBITS   15 /* 32K LZ77 window */
+#endif
+
+/* The memory requirements for deflate are (in bytes):
+            (1 << (windowBits+2)) +  (1 << (memLevel+9))
+ that is: 128K for windowBits=15  +  128K for memLevel = 8  (default values)
+ plus a few kilobytes for small objects. For example, if you want to reduce
+ the default memory requirements from 256K to 128K, compile with
+     make CFLAGS="-O -DMAX_WBITS=14 -DMAX_MEM_LEVEL=7"
+ Of course this will generally degrade compression (there's no free lunch).
+
+   The memory requirements for inflate are (in bytes) 1 << windowBits
+ that is, 32K for windowBits=15 (default value) plus a few kilobytes
+ for small objects.
+*/
+
+                        /* Type declarations */
+
+#ifndef OF /* function prototypes */
+#  ifdef STDC
+#    define OF(args)  args
+#  else
+#    define OF(args)  ()
+#  endif
+#endif
+
+#ifndef Z_ARG /* function prototypes for stdarg */
+#  if defined(STDC) || defined(Z_HAVE_STDARG_H)
+#    define Z_ARG(args)  args
+#  else
+#    define Z_ARG(args)  ()
+#  endif
+#endif
+
+/* The following definitions for FAR are needed only for MSDOS mixed
+ * model programming (small or medium model with some far allocations).
+ * This was tested only with MSC; for other MSDOS compilers you may have
+ * to define NO_MEMCPY in zutil.h.  If you don't need the mixed model,
+ * just define FAR to be empty.
+ */
+#ifdef SYS16BIT
+#  if defined(M_I86SM) || defined(M_I86MM)
+     /* MSC small or medium model */
+#    define SMALL_MEDIUM
+#    ifdef _MSC_VER
+#      define FAR _far
+#    else
+#      define FAR far
+#    endif
+#  endif
+#  if (defined(__SMALL__) || defined(__MEDIUM__))
+     /* Turbo C small or medium model */
+#    define SMALL_MEDIUM
+#    ifdef __BORLANDC__
+#      define FAR _far
+#    else
+#      define FAR far
+#    endif
+#  endif
+#endif
+
+#if defined(WINDOWS) || defined(WIN32)
+   /* If building or using zlib as a DLL, define ZLIB_DLL.
+    * This is not mandatory, but it offers a little performance increase.
+    */
+#  ifdef ZLIB_DLL
+#    if defined(WIN32) && (!defined(__BORLANDC__) || (__BORLANDC__ >= 0x500))
+#      ifdef ZLIB_INTERNAL
+#        define ZEXTERN extern __declspec(dllexport)
+#      else
+#        define ZEXTERN extern __declspec(dllimport)
+#      endif
+#    endif
+#  endif  /* ZLIB_DLL */
+   /* If building or using zlib with the WINAPI/WINAPIV calling convention,
+    * define ZLIB_WINAPI.
+    * Caution: the standard ZLIB1.DLL is NOT compiled using ZLIB_WINAPI.
+    */
+#  ifdef ZLIB_WINAPI
+#    ifdef FAR
+#      undef FAR
+#    endif
+#    include <windows.h>
+     /* No need for _export, use ZLIB.DEF instead. */
+     /* For complete Windows compatibility, use WINAPI, not __stdcall. */
+#    define ZEXPORT WINAPI
+#    ifdef WIN32
+#      define ZEXPORTVA WINAPIV
+#    else
+#      define ZEXPORTVA FAR CDECL
+#    endif
+#  endif
+#endif
+
+#if defined (__BEOS__)
+#  ifdef ZLIB_DLL
+#    ifdef ZLIB_INTERNAL
+#      define ZEXPORT   __declspec(dllexport)
+#      define ZEXPORTVA __declspec(dllexport)
+#    else
+#      define ZEXPORT   __declspec(dllimport)
+#      define ZEXPORTVA __declspec(dllimport)
+#    endif
+#  endif
+#endif
+
+#ifndef ZEXTERN
+#  define ZEXTERN extern
+#endif
+#ifndef ZEXPORT
+#  define ZEXPORT
+#endif
+#ifndef ZEXPORTVA
+#  define ZEXPORTVA
+#endif
+
+#ifndef FAR
+#  define FAR
+#endif
+
+#if !defined(__MACTYPES__)
+typedef unsigned char  Byte;  /* 8 bits */
+#endif
+typedef unsigned int   uInt;  /* 16 bits or more */
+typedef unsigned long  uLong; /* 32 bits or more */
+
+#ifdef SMALL_MEDIUM
+   /* Borland C/C++ and some old MSC versions ignore FAR inside typedef */
+#  define Bytef Byte FAR
+#else
+   typedef Byte  FAR Bytef;
+#endif
+typedef char  FAR charf;
+typedef int   FAR intf;
+typedef uInt  FAR uIntf;
+typedef uLong FAR uLongf;
+
+#ifdef STDC
+   typedef void const *voidpc;
+   typedef void FAR   *voidpf;
+   typedef void       *voidp;
+#else
+   typedef Byte const *voidpc;
+   typedef Byte FAR   *voidpf;
+   typedef Byte       *voidp;
+#endif
+
+#if !defined(Z_U4) && !defined(Z_SOLO) && defined(STDC)
+#  include <limits.h>
+#  if (UINT_MAX == 0xffffffffUL)
+#    define Z_U4 unsigned
+#  elif (ULONG_MAX == 0xffffffffUL)
+#    define Z_U4 unsigned long
+#  elif (USHRT_MAX == 0xffffffffUL)
+#    define Z_U4 unsigned short
+#  endif
+#endif
+
+#ifdef Z_U4
+   typedef Z_U4 z_crc_t;
+#else
+   typedef unsigned long z_crc_t;
+#endif
+
+#if 1    /* was set to #if 1 by ./configure */
+#  define Z_HAVE_UNISTD_H
+#endif
+
+#if 1    /* was set to #if 1 by ./configure */
+#  define Z_HAVE_STDARG_H
+#endif
+
+#ifdef STDC
+#  ifndef Z_SOLO
+#    include <sys/types.h>      /* for off_t */
+#  endif
+#endif
+
+#if defined(STDC) || defined(Z_HAVE_STDARG_H)
+#  ifndef Z_SOLO
+#    include <stdarg.h>         /* for va_list */
+#  endif
+#endif
+
+#ifdef _WIN32
+#  ifndef Z_SOLO
+#    include <stddef.h>         /* for wchar_t */
+#  endif
+#endif
+
+/* a little trick to accommodate both "#define _LARGEFILE64_SOURCE" and
+ * "#define _LARGEFILE64_SOURCE 1" as requesting 64-bit operations, (even
+ * though the former does not conform to the LFS document), but considering
+ * both "#undef _LARGEFILE64_SOURCE" and "#define _LARGEFILE64_SOURCE 0" as
+ * equivalently requesting no 64-bit operations
+ */
+#if defined(_LARGEFILE64_SOURCE) && -_LARGEFILE64_SOURCE - -1 == 1
+#  undef _LARGEFILE64_SOURCE
+#endif
+
+#if defined(__WATCOMC__) && !defined(Z_HAVE_UNISTD_H)
+#  define Z_HAVE_UNISTD_H
+#endif
+#ifndef Z_SOLO
+#  if defined(Z_HAVE_UNISTD_H) || defined(_LARGEFILE64_SOURCE)
+#    include <unistd.h>         /* for SEEK_*, off_t, and _LFS64_LARGEFILE */
+#    ifdef VMS
+#      include <unixio.h>       /* for off_t */
+#    endif
+#    ifndef z_off_t
+#      define z_off_t off_t
+#    endif
+#  endif
+#endif
+
+#if defined(_LFS64_LARGEFILE) && _LFS64_LARGEFILE-0
+#  define Z_LFS64
+#endif
+
+#if defined(_LARGEFILE64_SOURCE) && defined(Z_LFS64)
+#  define Z_LARGE64
+#endif
+
+#if defined(_FILE_OFFSET_BITS) && _FILE_OFFSET_BITS-0 == 64 && defined(Z_LFS64)
+#  define Z_WANT64
+#endif
+
+#if !defined(SEEK_SET) && !defined(Z_SOLO)
+#  define SEEK_SET        0       /* Seek from beginning of file.  */
+#  define SEEK_CUR        1       /* Seek from current position.  */
+#  define SEEK_END        2       /* Set file pointer to EOF plus "offset" */
+#endif
+
+#ifndef z_off_t
+#  define z_off_t long
+#endif
+
+#if !defined(_WIN32) && defined(Z_LARGE64)
+#  define z_off64_t off64_t
+#else
+#  if defined(_WIN32) && !defined(__GNUC__) && !defined(Z_SOLO)
+#    define z_off64_t __int64
+#  else
+#    define z_off64_t z_off_t
+#  endif
+#endif
+
+/* MVS linker does not support external names larger than 8 bytes */
+#if defined(__MVS__)
+  #pragma map(deflateInit_,"DEIN")
+  #pragma map(deflateInit2_,"DEIN2")
+  #pragma map(deflateEnd,"DEEND")
+  #pragma map(deflateBound,"DEBND")
+  #pragma map(inflateInit_,"ININ")
+  #pragma map(inflateInit2_,"ININ2")
+  #pragma map(inflateEnd,"INEND")
+  #pragma map(inflateSync,"INSY")
+  #pragma map(inflateSetDictionary,"INSEDI")
+  #pragma map(compressBound,"CMBND")
+  #pragma map(inflate_table,"INTABL")
+  #pragma map(inflate_fast,"INFA")
+  #pragma map(inflate_copyright,"INCOPY")
+#endif
+
+#endif /* ZCONF_H */
diff --git a/frontend/switch/zlib.h b/frontend/switch/zlib.h
new file mode 100644
index 00000000..3e0c7672
--- /dev/null
+++ b/frontend/switch/zlib.h
@@ -0,0 +1,1768 @@
+/* zlib.h -- interface of the 'zlib' general purpose compression library
+  version 1.2.8, April 28th, 2013
+
+  Copyright (C) 1995-2013 Jean-loup Gailly and Mark Adler
+
+  This software is provided 'as-is', without any express or implied
+  warranty.  In no event will the authors be held liable for any damages
+  arising from the use of this software.
+
+  Permission is granted to anyone to use this software for any purpose,
+  including commercial applications, and to alter it and redistribute it
+  freely, subject to the following restrictions:
+
+  1. The origin of this software must not be misrepresented; you must not
+     claim that you wrote the original software. If you use this software
+     in a product, an acknowledgment in the product documentation would be
+     appreciated but is not required.
+  2. Altered source versions must be plainly marked as such, and must not be
+     misrepresented as being the original software.
+  3. This notice may not be removed or altered from any source distribution.
+
+  Jean-loup Gailly        Mark Adler
+  jloup@gzip.org          madler@alumni.caltech.edu
+
+
+  The data format used by the zlib library is described by RFCs (Request for
+  Comments) 1950 to 1952 in the files http://tools.ietf.org/html/rfc1950
+  (zlib format), rfc1951 (deflate format) and rfc1952 (gzip format).
+*/
+
+#ifndef ZLIB_H
+#define ZLIB_H
+
+#include "zconf.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#define ZLIB_VERSION "1.2.8"
+#define ZLIB_VERNUM 0x1280
+#define ZLIB_VER_MAJOR 1
+#define ZLIB_VER_MINOR 2
+#define ZLIB_VER_REVISION 8
+#define ZLIB_VER_SUBREVISION 0
+
+/*
+    The 'zlib' compression library provides in-memory compression and
+  decompression functions, including integrity checks of the uncompressed data.
+  This version of the library supports only one compression method (deflation)
+  but other algorithms will be added later and will have the same stream
+  interface.
+
+    Compression can be done in a single step if the buffers are large enough,
+  or can be done by repeated calls of the compression function.  In the latter
+  case, the application must provide more input and/or consume the output
+  (providing more output space) before each call.
+
+    The compressed data format used by default by the in-memory functions is
+  the zlib format, which is a zlib wrapper documented in RFC 1950, wrapped
+  around a deflate stream, which is itself documented in RFC 1951.
+
+    The library also supports reading and writing files in gzip (.gz) format
+  with an interface similar to that of stdio using the functions that start
+  with "gz".  The gzip format is different from the zlib format.  gzip is a
+  gzip wrapper, documented in RFC 1952, wrapped around a deflate stream.
+
+    This library can optionally read and write gzip streams in memory as well.
+
+    The zlib format was designed to be compact and fast for use in memory
+  and on communications channels.  The gzip format was designed for single-
+  file compression on file systems, has a larger header than zlib to maintain
+  directory information, and uses a different, slower check method than zlib.
+
+    The library does not install any signal handler.  The decoder checks
+  the consistency of the compressed data, so the library should never crash
+  even in case of corrupted input.
+*/
+
+typedef voidpf (*alloc_func) OF((voidpf opaque, uInt items, uInt size));
+typedef void   (*free_func)  OF((voidpf opaque, voidpf address));
+
+struct internal_state;
+
+typedef struct z_stream_s {
+    z_const Bytef *next_in;     /* next input byte */
+    uInt     avail_in;  /* number of bytes available at next_in */
+    uLong    total_in;  /* total number of input bytes read so far */
+
+    Bytef    *next_out; /* next output byte should be put there */
+    uInt     avail_out; /* remaining free space at next_out */
+    uLong    total_out; /* total number of bytes output so far */
+
+    z_const char *msg;  /* last error message, NULL if no error */
+    struct internal_state FAR *state; /* not visible by applications */
+
+    alloc_func zalloc;  /* used to allocate the internal state */
+    free_func  zfree;   /* used to free the internal state */
+    voidpf     opaque;  /* private data object passed to zalloc and zfree */
+
+    int     data_type;  /* best guess about the data type: binary or text */
+    uLong   adler;      /* adler32 value of the uncompressed data */
+    uLong   reserved;   /* reserved for future use */
+} z_stream;
+
+typedef z_stream FAR *z_streamp;
+
+/*
+     gzip header information passed to and from zlib routines.  See RFC 1952
+  for more details on the meanings of these fields.
+*/
+typedef struct gz_header_s {
+    int     text;       /* true if compressed data believed to be text */
+    uLong   time;       /* modification time */
+    int     xflags;     /* extra flags (not used when writing a gzip file) */
+    int     os;         /* operating system */
+    Bytef   *extra;     /* pointer to extra field or Z_NULL if none */
+    uInt    extra_len;  /* extra field length (valid if extra != Z_NULL) */
+    uInt    extra_max;  /* space at extra (only when reading header) */
+    Bytef   *name;      /* pointer to zero-terminated file name or Z_NULL */
+    uInt    name_max;   /* space at name (only when reading header) */
+    Bytef   *comment;   /* pointer to zero-terminated comment or Z_NULL */
+    uInt    comm_max;   /* space at comment (only when reading header) */
+    int     hcrc;       /* true if there was or will be a header crc */
+    int     done;       /* true when done reading gzip header (not used
+                           when writing a gzip file) */
+} gz_header;
+
+typedef gz_header FAR *gz_headerp;
+
+/*
+     The application must update next_in and avail_in when avail_in has dropped
+   to zero.  It must update next_out and avail_out when avail_out has dropped
+   to zero.  The application must initialize zalloc, zfree and opaque before
+   calling the init function.  All other fields are set by the compression
+   library and must not be updated by the application.
+
+     The opaque value provided by the application will be passed as the first
+   parameter for calls of zalloc and zfree.  This can be useful for custom
+   memory management.  The compression library attaches no meaning to the
+   opaque value.
+
+     zalloc must return Z_NULL if there is not enough memory for the object.
+   If zlib is used in a multi-threaded application, zalloc and zfree must be
+   thread safe.
+
+     On 16-bit systems, the functions zalloc and zfree must be able to allocate
+   exactly 65536 bytes, but will not be required to allocate more than this if
+   the symbol MAXSEG_64K is defined (see zconf.h).  WARNING: On MSDOS, pointers
+   returned by zalloc for objects of exactly 65536 bytes *must* have their
+   offset normalized to zero.  The default allocation function provided by this
+   library ensures this (see zutil.c).  To reduce memory requirements and avoid
+   any allocation of 64K objects, at the expense of compression ratio, compile
+   the library with -DMAX_WBITS=14 (see zconf.h).
+
+     The fields total_in and total_out can be used for statistics or progress
+   reports.  After compression, total_in holds the total size of the
+   uncompressed data and may be saved for use in the decompressor (particularly
+   if the decompressor wants to decompress everything in a single step).
+*/
+
+                        /* constants */
+
+#define Z_NO_FLUSH      0
+#define Z_PARTIAL_FLUSH 1
+#define Z_SYNC_FLUSH    2
+#define Z_FULL_FLUSH    3
+#define Z_FINISH        4
+#define Z_BLOCK         5
+#define Z_TREES         6
+/* Allowed flush values; see deflate() and inflate() below for details */
+
+#define Z_OK            0
+#define Z_STREAM_END    1
+#define Z_NEED_DICT     2
+#define Z_ERRNO        (-1)
+#define Z_STREAM_ERROR (-2)
+#define Z_DATA_ERROR   (-3)
+#define Z_MEM_ERROR    (-4)
+#define Z_BUF_ERROR    (-5)
+#define Z_VERSION_ERROR (-6)
+/* Return codes for the compression/decompression functions. Negative values
+ * are errors, positive values are used for special but normal events.
+ */
+
+#define Z_NO_COMPRESSION         0
+#define Z_BEST_SPEED             1
+#define Z_BEST_COMPRESSION       9
+#define Z_DEFAULT_COMPRESSION  (-1)
+/* compression levels */
+
+#define Z_FILTERED            1
+#define Z_HUFFMAN_ONLY        2
+#define Z_RLE                 3
+#define Z_FIXED               4
+#define Z_DEFAULT_STRATEGY    0
+/* compression strategy; see deflateInit2() below for details */
+
+#define Z_BINARY   0
+#define Z_TEXT     1
+#define Z_ASCII    Z_TEXT   /* for compatibility with 1.2.2 and earlier */
+#define Z_UNKNOWN  2
+/* Possible values of the data_type field (though see inflate()) */
+
+#define Z_DEFLATED   8
+/* The deflate compression method (the only one supported in this version) */
+
+#define Z_NULL  0  /* for initializing zalloc, zfree, opaque */
+
+#define zlib_version zlibVersion()
+/* for compatibility with versions < 1.0.2 */
+
+
+                        /* basic functions */
+
+ZEXTERN const char * ZEXPORT zlibVersion OF((void));
+/* The application can compare zlibVersion and ZLIB_VERSION for consistency.
+   If the first character differs, the library code actually used is not
+   compatible with the zlib.h header file used by the application.  This check
+   is automatically made by deflateInit and inflateInit.
+ */
+
+/*
+ZEXTERN int ZEXPORT deflateInit OF((z_streamp strm, int level));
+
+     Initializes the internal stream state for compression.  The fields
+   zalloc, zfree and opaque must be initialized before by the caller.  If
+   zalloc and zfree are set to Z_NULL, deflateInit updates them to use default
+   allocation functions.
+
+     The compression level must be Z_DEFAULT_COMPRESSION, or between 0 and 9:
+   1 gives best speed, 9 gives best compression, 0 gives no compression at all
+   (the input data is simply copied a block at a time).  Z_DEFAULT_COMPRESSION
+   requests a default compromise between speed and compression (currently
+   equivalent to level 6).
+
+     deflateInit returns Z_OK if success, Z_MEM_ERROR if there was not enough
+   memory, Z_STREAM_ERROR if level is not a valid compression level, or
+   Z_VERSION_ERROR if the zlib library version (zlib_version) is incompatible
+   with the version assumed by the caller (ZLIB_VERSION).  msg is set to null
+   if there is no error message.  deflateInit does not perform any compression:
+   this will be done by deflate().
+*/
+
+
+ZEXTERN int ZEXPORT deflate OF((z_streamp strm, int flush));
+/*
+    deflate compresses as much data as possible, and stops when the input
+  buffer becomes empty or the output buffer becomes full.  It may introduce
+  some output latency (reading input without producing any output) except when
+  forced to flush.
+
+    The detailed semantics are as follows.  deflate performs one or both of the
+  following actions:
+
+  - Compress more input starting at next_in and update next_in and avail_in
+    accordingly.  If not all input can be processed (because there is not
+    enough room in the output buffer), next_in and avail_in are updated and
+    processing will resume at this point for the next call of deflate().
+
+  - Provide more output starting at next_out and update next_out and avail_out
+    accordingly.  This action is forced if the parameter flush is non zero.
+    Forcing flush frequently degrades the compression ratio, so this parameter
+    should be set only when necessary (in interactive applications).  Some
+    output may be provided even if flush is not set.
+
+    Before the call of deflate(), the application should ensure that at least
+  one of the actions is possible, by providing more input and/or consuming more
+  output, and updating avail_in or avail_out accordingly; avail_out should
+  never be zero before the call.  The application can consume the compressed
+  output when it wants, for example when the output buffer is full (avail_out
+  == 0), or after each call of deflate().  If deflate returns Z_OK and with
+  zero avail_out, it must be called again after making room in the output
+  buffer because there might be more output pending.
+
+    Normally the parameter flush is set to Z_NO_FLUSH, which allows deflate to
+  decide how much data to accumulate before producing output, in order to
+  maximize compression.
+
+    If the parameter flush is set to Z_SYNC_FLUSH, all pending output is
+  flushed to the output buffer and the output is aligned on a byte boundary, so
+  that the decompressor can get all input data available so far.  (In
+  particular avail_in is zero after the call if enough output space has been
+  provided before the call.) Flushing may degrade compression for some
+  compression algorithms and so it should be used only when necessary.  This
+  completes the current deflate block and follows it with an empty stored block
+  that is three bits plus filler bits to the next byte, followed by four bytes
+  (00 00 ff ff).
+
+    If flush is set to Z_PARTIAL_FLUSH, all pending output is flushed to the
+  output buffer, but the output is not aligned to a byte boundary.  All of the
+  input data so far will be available to the decompressor, as for Z_SYNC_FLUSH.
+  This completes the current deflate block and follows it with an empty fixed
+  codes block that is 10 bits long.  This assures that enough bytes are output
+  in order for the decompressor to finish the block before the empty fixed code
+  block.
+
+    If flush is set to Z_BLOCK, a deflate block is completed and emitted, as
+  for Z_SYNC_FLUSH, but the output is not aligned on a byte boundary, and up to
+  seven bits of the current block are held to be written as the next byte after
+  the next deflate block is completed.  In this case, the decompressor may not
+  be provided enough bits at this point in order to complete decompression of
+  the data provided so far to the compressor.  It may need to wait for the next
+  block to be emitted.  This is for advanced applications that need to control
+  the emission of deflate blocks.
+
+    If flush is set to Z_FULL_FLUSH, all output is flushed as with
+  Z_SYNC_FLUSH, and the compression state is reset so that decompression can
+  restart from this point if previous compressed data has been damaged or if
+  random access is desired.  Using Z_FULL_FLUSH too often can seriously degrade
+  compression.
+
+    If deflate returns with avail_out == 0, this function must be called again
+  with the same value of the flush parameter and more output space (updated
+  avail_out), until the flush is complete (deflate returns with non-zero
+  avail_out).  In the case of a Z_FULL_FLUSH or Z_SYNC_FLUSH, make sure that
+  avail_out is greater than six to avoid repeated flush markers due to
+  avail_out == 0 on return.
+
+    If the parameter flush is set to Z_FINISH, pending input is processed,
+  pending output is flushed and deflate returns with Z_STREAM_END if there was
+  enough output space; if deflate returns with Z_OK, this function must be
+  called again with Z_FINISH and more output space (updated avail_out) but no
+  more input data, until it returns with Z_STREAM_END or an error.  After
+  deflate has returned Z_STREAM_END, the only possible operations on the stream
+  are deflateReset or deflateEnd.
+
+    Z_FINISH can be used immediately after deflateInit if all the compression
+  is to be done in a single step.  In this case, avail_out must be at least the
+  value returned by deflateBound (see below).  Then deflate is guaranteed to
+  return Z_STREAM_END.  If not enough output space is provided, deflate will
+  not return Z_STREAM_END, and it must be called again as described above.
+
+    deflate() sets strm->adler to the adler32 checksum of all input read
+  so far (that is, total_in bytes).
+
+    deflate() may update strm->data_type if it can make a good guess about
+  the input data type (Z_BINARY or Z_TEXT).  In doubt, the data is considered
+  binary.  This field is only for information purposes and does not affect the
+  compression algorithm in any manner.
+
+    deflate() returns Z_OK if some progress has been made (more input
+  processed or more output produced), Z_STREAM_END if all input has been
+  consumed and all output has been produced (only when flush is set to
+  Z_FINISH), Z_STREAM_ERROR if the stream state was inconsistent (for example
+  if next_in or next_out was Z_NULL), Z_BUF_ERROR if no progress is possible
+  (for example avail_in or avail_out was zero).  Note that Z_BUF_ERROR is not
+  fatal, and deflate() can be called again with more input and more output
+  space to continue compressing.
+*/
+
+
+ZEXTERN int ZEXPORT deflateEnd OF((z_streamp strm));
+/*
+     All dynamically allocated data structures for this stream are freed.
+   This function discards any unprocessed input and does not flush any pending
+   output.
+
+     deflateEnd returns Z_OK if success, Z_STREAM_ERROR if the
+   stream state was inconsistent, Z_DATA_ERROR if the stream was freed
+   prematurely (some input or output was discarded).  In the error case, msg
+   may be set but then points to a static string (which must not be
+   deallocated).
+*/
+
+
+/*
+ZEXTERN int ZEXPORT inflateInit OF((z_streamp strm));
+
+     Initializes the internal stream state for decompression.  The fields
+   next_in, avail_in, zalloc, zfree and opaque must be initialized before by
+   the caller.  If next_in is not Z_NULL and avail_in is large enough (the
+   exact value depends on the compression method), inflateInit determines the
+   compression method from the zlib header and allocates all data structures
+   accordingly; otherwise the allocation will be deferred to the first call of
+   inflate.  If zalloc and zfree are set to Z_NULL, inflateInit updates them to
+   use default allocation functions.
+
+     inflateInit returns Z_OK if success, Z_MEM_ERROR if there was not enough
+   memory, Z_VERSION_ERROR if the zlib library version is incompatible with the
+   version assumed by the caller, or Z_STREAM_ERROR if the parameters are
+   invalid, such as a null pointer to the structure.  msg is set to null if
+   there is no error message.  inflateInit does not perform any decompression
+   apart from possibly reading the zlib header if present: actual decompression
+   will be done by inflate().  (So next_in and avail_in may be modified, but
+   next_out and avail_out are unused and unchanged.) The current implementation
+   of inflateInit() does not process any header information -- that is deferred
+   until inflate() is called.
+*/
+
+
+ZEXTERN int ZEXPORT inflate OF((z_streamp strm, int flush));
+/*
+    inflate decompresses as much data as possible, and stops when the input
+  buffer becomes empty or the output buffer becomes full.  It may introduce
+  some output latency (reading input without producing any output) except when
+  forced to flush.
+
+  The detailed semantics are as follows.  inflate performs one or both of the
+  following actions:
+
+  - Decompress more input starting at next_in and update next_in and avail_in
+    accordingly.  If not all input can be processed (because there is not
+    enough room in the output buffer), next_in is updated and processing will
+    resume at this point for the next call of inflate().
+
+  - Provide more output starting at next_out and update next_out and avail_out
+    accordingly.  inflate() provides as much output as possible, until there is
+    no more input data or no more space in the output buffer (see below about
+    the flush parameter).
+
+    Before the call of inflate(), the application should ensure that at least
+  one of the actions is possible, by providing more input and/or consuming more
+  output, and updating the next_* and avail_* values accordingly.  The
+  application can consume the uncompressed output when it wants, for example
+  when the output buffer is full (avail_out == 0), or after each call of
+  inflate().  If inflate returns Z_OK and with zero avail_out, it must be
+  called again after making room in the output buffer because there might be
+  more output pending.
+
+    The flush parameter of inflate() can be Z_NO_FLUSH, Z_SYNC_FLUSH, Z_FINISH,
+  Z_BLOCK, or Z_TREES.  Z_SYNC_FLUSH requests that inflate() flush as much
+  output as possible to the output buffer.  Z_BLOCK requests that inflate()
+  stop if and when it gets to the next deflate block boundary.  When decoding
+  the zlib or gzip format, this will cause inflate() to return immediately
+  after the header and before the first block.  When doing a raw inflate,
+  inflate() will go ahead and process the first block, and will return when it
+  gets to the end of that block, or when it runs out of data.
+
+    The Z_BLOCK option assists in appending to or combining deflate streams.
+  Also to assist in this, on return inflate() will set strm->data_type to the
+  number of unused bits in the last byte taken from strm->next_in, plus 64 if
+  inflate() is currently decoding the last block in the deflate stream, plus
+  128 if inflate() returned immediately after decoding an end-of-block code or
+  decoding the complete header up to just before the first byte of the deflate
+  stream.  The end-of-block will not be indicated until all of the uncompressed
+  data from that block has been written to strm->next_out.  The number of
+  unused bits may in general be greater than seven, except when bit 7 of
+  data_type is set, in which case the number of unused bits will be less than
+  eight.  data_type is set as noted here every time inflate() returns for all
+  flush options, and so can be used to determine the amount of currently
+  consumed input in bits.
+
+    The Z_TREES option behaves as Z_BLOCK does, but it also returns when the
+  end of each deflate block header is reached, before any actual data in that
+  block is decoded.  This allows the caller to determine the length of the
+  deflate block header for later use in random access within a deflate block.
+  256 is added to the value of strm->data_type when inflate() returns
+  immediately after reaching the end of the deflate block header.
+
+    inflate() should normally be called until it returns Z_STREAM_END or an
+  error.  However if all decompression is to be performed in a single step (a
+  single call of inflate), the parameter flush should be set to Z_FINISH.  In
+  this case all pending input is processed and all pending output is flushed;
+  avail_out must be large enough to hold all of the uncompressed data for the
+  operation to complete.  (The size of the uncompressed data may have been
+  saved by the compressor for this purpose.) The use of Z_FINISH is not
+  required to perform an inflation in one step.  However it may be used to
+  inform inflate that a faster approach can be used for the single inflate()
+  call.  Z_FINISH also informs inflate to not maintain a sliding window if the
+  stream completes, which reduces inflate's memory footprint.  If the stream
+  does not complete, either because not all of the stream is provided or not
+  enough output space is provided, then a sliding window will be allocated and
+  inflate() can be called again to continue the operation as if Z_NO_FLUSH had
+  been used.
+
+     In this implementation, inflate() always flushes as much output as
+  possible to the output buffer, and always uses the faster approach on the
+  first call.  So the effects of the flush parameter in this implementation are
+  on the return value of inflate() as noted below, when inflate() returns early
+  when Z_BLOCK or Z_TREES is used, and when inflate() avoids the allocation of
+  memory for a sliding window when Z_FINISH is used.
+
+     If a preset dictionary is needed after this call (see inflateSetDictionary
+  below), inflate sets strm->adler to the Adler-32 checksum of the dictionary
+  chosen by the compressor and returns Z_NEED_DICT; otherwise it sets
+  strm->adler to the Adler-32 checksum of all output produced so far (that is,
+  total_out bytes) and returns Z_OK, Z_STREAM_END or an error code as described
+  below.  At the end of the stream, inflate() checks that its computed adler32
+  checksum is equal to that saved by the compressor and returns Z_STREAM_END
+  only if the checksum is correct.
+
+    inflate() can decompress and check either zlib-wrapped or gzip-wrapped
+  deflate data.  The header type is detected automatically, if requested when
+  initializing with inflateInit2().  Any information contained in the gzip
+  header is not retained, so applications that need that information should
+  instead use raw inflate, see inflateInit2() below, or inflateBack() and
+  perform their own processing of the gzip header and trailer.  When processing
+  gzip-wrapped deflate data, strm->adler32 is set to the CRC-32 of the output
+  producted so far.  The CRC-32 is checked against the gzip trailer.
+
+    inflate() returns Z_OK if some progress has been made (more input processed
+  or more output produced), Z_STREAM_END if the end of the compressed data has
+  been reached and all uncompressed output has been produced, Z_NEED_DICT if a
+  preset dictionary is needed at this point, Z_DATA_ERROR if the input data was
+  corrupted (input stream not conforming to the zlib format or incorrect check
+  value), Z_STREAM_ERROR if the stream structure was inconsistent (for example
+  next_in or next_out was Z_NULL), Z_MEM_ERROR if there was not enough memory,
+  Z_BUF_ERROR if no progress is possible or if there was not enough room in the
+  output buffer when Z_FINISH is used.  Note that Z_BUF_ERROR is not fatal, and
+  inflate() can be called again with more input and more output space to
+  continue decompressing.  If Z_DATA_ERROR is returned, the application may
+  then call inflateSync() to look for a good compression block if a partial
+  recovery of the data is desired.
+*/
+
+
+ZEXTERN int ZEXPORT inflateEnd OF((z_streamp strm));
+/*
+     All dynamically allocated data structures for this stream are freed.
+   This function discards any unprocessed input and does not flush any pending
+   output.
+
+     inflateEnd returns Z_OK if success, Z_STREAM_ERROR if the stream state
+   was inconsistent.  In the error case, msg may be set but then points to a
+   static string (which must not be deallocated).
+*/
+
+
+                        /* Advanced functions */
+
+/*
+    The following functions are needed only in some special applications.
+*/
+
+/*
+ZEXTERN int ZEXPORT deflateInit2 OF((z_streamp strm,
+                                     int  level,
+                                     int  method,
+                                     int  windowBits,
+                                     int  memLevel,
+                                     int  strategy));
+
+     This is another version of deflateInit with more compression options.  The
+   fields next_in, zalloc, zfree and opaque must be initialized before by the
+   caller.
+
+     The method parameter is the compression method.  It must be Z_DEFLATED in
+   this version of the library.
+
+     The windowBits parameter is the base two logarithm of the window size
+   (the size of the history buffer).  It should be in the range 8..15 for this
+   version of the library.  Larger values of this parameter result in better
+   compression at the expense of memory usage.  The default value is 15 if
+   deflateInit is used instead.
+
+     windowBits can also be -8..-15 for raw deflate.  In this case, -windowBits
+   determines the window size.  deflate() will then generate raw deflate data
+   with no zlib header or trailer, and will not compute an adler32 check value.
+
+     windowBits can also be greater than 15 for optional gzip encoding.  Add
+   16 to windowBits to write a simple gzip header and trailer around the
+   compressed data instead of a zlib wrapper.  The gzip header will have no
+   file name, no extra data, no comment, no modification time (set to zero), no
+   header crc, and the operating system will be set to 255 (unknown).  If a
+   gzip stream is being written, strm->adler is a crc32 instead of an adler32.
+
+     The memLevel parameter specifies how much memory should be allocated
+   for the internal compression state.  memLevel=1 uses minimum memory but is
+   slow and reduces compression ratio; memLevel=9 uses maximum memory for
+   optimal speed.  The default value is 8.  See zconf.h for total memory usage
+   as a function of windowBits and memLevel.
+
+     The strategy parameter is used to tune the compression algorithm.  Use the
+   value Z_DEFAULT_STRATEGY for normal data, Z_FILTERED for data produced by a
+   filter (or predictor), Z_HUFFMAN_ONLY to force Huffman encoding only (no
+   string match), or Z_RLE to limit match distances to one (run-length
+   encoding).  Filtered data consists mostly of small values with a somewhat
+   random distribution.  In this case, the compression algorithm is tuned to
+   compress them better.  The effect of Z_FILTERED is to force more Huffman
+   coding and less string matching; it is somewhat intermediate between
+   Z_DEFAULT_STRATEGY and Z_HUFFMAN_ONLY.  Z_RLE is designed to be almost as
+   fast as Z_HUFFMAN_ONLY, but give better compression for PNG image data.  The
+   strategy parameter only affects the compression ratio but not the
+   correctness of the compressed output even if it is not set appropriately.
+   Z_FIXED prevents the use of dynamic Huffman codes, allowing for a simpler
+   decoder for special applications.
+
+     deflateInit2 returns Z_OK if success, Z_MEM_ERROR if there was not enough
+   memory, Z_STREAM_ERROR if any parameter is invalid (such as an invalid
+   method), or Z_VERSION_ERROR if the zlib library version (zlib_version) is
+   incompatible with the version assumed by the caller (ZLIB_VERSION).  msg is
+   set to null if there is no error message.  deflateInit2 does not perform any
+   compression: this will be done by deflate().
+*/
+
+ZEXTERN int ZEXPORT deflateSetDictionary OF((z_streamp strm,
+                                             const Bytef *dictionary,
+                                             uInt  dictLength));
+/*
+     Initializes the compression dictionary from the given byte sequence
+   without producing any compressed output.  When using the zlib format, this
+   function must be called immediately after deflateInit, deflateInit2 or
+   deflateReset, and before any call of deflate.  When doing raw deflate, this
+   function must be called either before any call of deflate, or immediately
+   after the completion of a deflate block, i.e. after all input has been
+   consumed and all output has been delivered when using any of the flush
+   options Z_BLOCK, Z_PARTIAL_FLUSH, Z_SYNC_FLUSH, or Z_FULL_FLUSH.  The
+   compressor and decompressor must use exactly the same dictionary (see
+   inflateSetDictionary).
+
+     The dictionary should consist of strings (byte sequences) that are likely
+   to be encountered later in the data to be compressed, with the most commonly
+   used strings preferably put towards the end of the dictionary.  Using a
+   dictionary is most useful when the data to be compressed is short and can be
+   predicted with good accuracy; the data can then be compressed better than
+   with the default empty dictionary.
+
+     Depending on the size of the compression data structures selected by
+   deflateInit or deflateInit2, a part of the dictionary may in effect be
+   discarded, for example if the dictionary is larger than the window size
+   provided in deflateInit or deflateInit2.  Thus the strings most likely to be
+   useful should be put at the end of the dictionary, not at the front.  In
+   addition, the current implementation of deflate will use at most the window
+   size minus 262 bytes of the provided dictionary.
+
+     Upon return of this function, strm->adler is set to the adler32 value
+   of the dictionary; the decompressor may later use this value to determine
+   which dictionary has been used by the compressor.  (The adler32 value
+   applies to the whole dictionary even if only a subset of the dictionary is
+   actually used by the compressor.) If a raw deflate was requested, then the
+   adler32 value is not computed and strm->adler is not set.
+
+     deflateSetDictionary returns Z_OK if success, or Z_STREAM_ERROR if a
+   parameter is invalid (e.g.  dictionary being Z_NULL) or the stream state is
+   inconsistent (for example if deflate has already been called for this stream
+   or if not at a block boundary for raw deflate).  deflateSetDictionary does
+   not perform any compression: this will be done by deflate().
+*/
+
+ZEXTERN int ZEXPORT deflateCopy OF((z_streamp dest,
+                                    z_streamp source));
+/*
+     Sets the destination stream as a complete copy of the source stream.
+
+     This function can be useful when several compression strategies will be
+   tried, for example when there are several ways of pre-processing the input
+   data with a filter.  The streams that will be discarded should then be freed
+   by calling deflateEnd.  Note that deflateCopy duplicates the internal
+   compression state which can be quite large, so this strategy is slow and can
+   consume lots of memory.
+
+     deflateCopy returns Z_OK if success, Z_MEM_ERROR if there was not
+   enough memory, Z_STREAM_ERROR if the source stream state was inconsistent
+   (such as zalloc being Z_NULL).  msg is left unchanged in both source and
+   destination.
+*/
+
+ZEXTERN int ZEXPORT deflateReset OF((z_streamp strm));
+/*
+     This function is equivalent to deflateEnd followed by deflateInit,
+   but does not free and reallocate all the internal compression state.  The
+   stream will keep the same compression level and any other attributes that
+   may have been set by deflateInit2.
+
+     deflateReset returns Z_OK if success, or Z_STREAM_ERROR if the source
+   stream state was inconsistent (such as zalloc or state being Z_NULL).
+*/
+
+ZEXTERN int ZEXPORT deflateParams OF((z_streamp strm,
+                                      int level,
+                                      int strategy));
+/*
+     Dynamically update the compression level and compression strategy.  The
+   interpretation of level and strategy is as in deflateInit2.  This can be
+   used to switch between compression and straight copy of the input data, or
+   to switch to a different kind of input data requiring a different strategy.
+   If the compression level is changed, the input available so far is
+   compressed with the old level (and may be flushed); the new level will take
+   effect only at the next call of deflate().
+
+     Before the call of deflateParams, the stream state must be set as for
+   a call of deflate(), since the currently available input may have to be
+   compressed and flushed.  In particular, strm->avail_out must be non-zero.
+
+     deflateParams returns Z_OK if success, Z_STREAM_ERROR if the source
+   stream state was inconsistent or if a parameter was invalid, Z_BUF_ERROR if
+   strm->avail_out was zero.
+*/
+
+ZEXTERN int ZEXPORT deflateTune OF((z_streamp strm,
+                                    int good_length,
+                                    int max_lazy,
+                                    int nice_length,
+                                    int max_chain));
+/*
+     Fine tune deflate's internal compression parameters.  This should only be
+   used by someone who understands the algorithm used by zlib's deflate for
+   searching for the best matching string, and even then only by the most
+   fanatic optimizer trying to squeeze out the last compressed bit for their
+   specific input data.  Read the deflate.c source code for the meaning of the
+   max_lazy, good_length, nice_length, and max_chain parameters.
+
+     deflateTune() can be called after deflateInit() or deflateInit2(), and
+   returns Z_OK on success, or Z_STREAM_ERROR for an invalid deflate stream.
+ */
+
+ZEXTERN uLong ZEXPORT deflateBound OF((z_streamp strm,
+                                       uLong sourceLen));
+/*
+     deflateBound() returns an upper bound on the compressed size after
+   deflation of sourceLen bytes.  It must be called after deflateInit() or
+   deflateInit2(), and after deflateSetHeader(), if used.  This would be used
+   to allocate an output buffer for deflation in a single pass, and so would be
+   called before deflate().  If that first deflate() call is provided the
+   sourceLen input bytes, an output buffer allocated to the size returned by
+   deflateBound(), and the flush value Z_FINISH, then deflate() is guaranteed
+   to return Z_STREAM_END.  Note that it is possible for the compressed size to
+   be larger than the value returned by deflateBound() if flush options other
+   than Z_FINISH or Z_NO_FLUSH are used.
+*/
+
+ZEXTERN int ZEXPORT deflatePending OF((z_streamp strm,
+                                       unsigned *pending,
+                                       int *bits));
+/*
+     deflatePending() returns the number of bytes and bits of output that have
+   been generated, but not yet provided in the available output.  The bytes not
+   provided would be due to the available output space having being consumed.
+   The number of bits of output not provided are between 0 and 7, where they
+   await more bits to join them in order to fill out a full byte.  If pending
+   or bits are Z_NULL, then those values are not set.
+
+     deflatePending returns Z_OK if success, or Z_STREAM_ERROR if the source
+   stream state was inconsistent.
+ */
+
+ZEXTERN int ZEXPORT deflatePrime OF((z_streamp strm,
+                                     int bits,
+                                     int value));
+/*
+     deflatePrime() inserts bits in the deflate output stream.  The intent
+   is that this function is used to start off the deflate output with the bits
+   leftover from a previous deflate stream when appending to it.  As such, this
+   function can only be used for raw deflate, and must be used before the first
+   deflate() call after a deflateInit2() or deflateReset().  bits must be less
+   than or equal to 16, and that many of the least significant bits of value
+   will be inserted in the output.
+
+     deflatePrime returns Z_OK if success, Z_BUF_ERROR if there was not enough
+   room in the internal buffer to insert the bits, or Z_STREAM_ERROR if the
+   source stream state was inconsistent.
+*/
+
+ZEXTERN int ZEXPORT deflateSetHeader OF((z_streamp strm,
+                                         gz_headerp head));
+/*
+     deflateSetHeader() provides gzip header information for when a gzip
+   stream is requested by deflateInit2().  deflateSetHeader() may be called
+   after deflateInit2() or deflateReset() and before the first call of
+   deflate().  The text, time, os, extra field, name, and comment information
+   in the provided gz_header structure are written to the gzip header (xflag is
+   ignored -- the extra flags are set according to the compression level).  The
+   caller must assure that, if not Z_NULL, name and comment are terminated with
+   a zero byte, and that if extra is not Z_NULL, that extra_len bytes are
+   available there.  If hcrc is true, a gzip header crc is included.  Note that
+   the current versions of the command-line version of gzip (up through version
+   1.3.x) do not support header crc's, and will report that it is a "multi-part
+   gzip file" and give up.
+
+     If deflateSetHeader is not used, the default gzip header has text false,
+   the time set to zero, and os set to 255, with no extra, name, or comment
+   fields.  The gzip header is returned to the default state by deflateReset().
+
+     deflateSetHeader returns Z_OK if success, or Z_STREAM_ERROR if the source
+   stream state was inconsistent.
+*/
+
+/*
+ZEXTERN int ZEXPORT inflateInit2 OF((z_streamp strm,
+                                     int  windowBits));
+
+     This is another version of inflateInit with an extra parameter.  The
+   fields next_in, avail_in, zalloc, zfree and opaque must be initialized
+   before by the caller.
+
+     The windowBits parameter is the base two logarithm of the maximum window
+   size (the size of the history buffer).  It should be in the range 8..15 for
+   this version of the library.  The default value is 15 if inflateInit is used
+   instead.  windowBits must be greater than or equal to the windowBits value
+   provided to deflateInit2() while compressing, or it must be equal to 15 if
+   deflateInit2() was not used.  If a compressed stream with a larger window
+   size is given as input, inflate() will return with the error code
+   Z_DATA_ERROR instead of trying to allocate a larger window.
+
+     windowBits can also be zero to request that inflate use the window size in
+   the zlib header of the compressed stream.
+
+     windowBits can also be -8..-15 for raw inflate.  In this case, -windowBits
+   determines the window size.  inflate() will then process raw deflate data,
+   not looking for a zlib or gzip header, not generating a check value, and not
+   looking for any check values for comparison at the end of the stream.  This
+   is for use with other formats that use the deflate compressed data format
+   such as zip.  Those formats provide their own check values.  If a custom
+   format is developed using the raw deflate format for compressed data, it is
+   recommended that a check value such as an adler32 or a crc32 be applied to
+   the uncompressed data as is done in the zlib, gzip, and zip formats.  For
+   most applications, the zlib format should be used as is.  Note that comments
+   above on the use in deflateInit2() applies to the magnitude of windowBits.
+
+     windowBits can also be greater than 15 for optional gzip decoding.  Add
+   32 to windowBits to enable zlib and gzip decoding with automatic header
+   detection, or add 16 to decode only the gzip format (the zlib format will
+   return a Z_DATA_ERROR).  If a gzip stream is being decoded, strm->adler is a
+   crc32 instead of an adler32.
+
+     inflateInit2 returns Z_OK if success, Z_MEM_ERROR if there was not enough
+   memory, Z_VERSION_ERROR if the zlib library version is incompatible with the
+   version assumed by the caller, or Z_STREAM_ERROR if the parameters are
+   invalid, such as a null pointer to the structure.  msg is set to null if
+   there is no error message.  inflateInit2 does not perform any decompression
+   apart from possibly reading the zlib header if present: actual decompression
+   will be done by inflate().  (So next_in and avail_in may be modified, but
+   next_out and avail_out are unused and unchanged.) The current implementation
+   of inflateInit2() does not process any header information -- that is
+   deferred until inflate() is called.
+*/
+
+ZEXTERN int ZEXPORT inflateSetDictionary OF((z_streamp strm,
+                                             const Bytef *dictionary,
+                                             uInt  dictLength));
+/*
+     Initializes the decompression dictionary from the given uncompressed byte
+   sequence.  This function must be called immediately after a call of inflate,
+   if that call returned Z_NEED_DICT.  The dictionary chosen by the compressor
+   can be determined from the adler32 value returned by that call of inflate.
+   The compressor and decompressor must use exactly the same dictionary (see
+   deflateSetDictionary).  For raw inflate, this function can be called at any
+   time to set the dictionary.  If the provided dictionary is smaller than the
+   window and there is already data in the window, then the provided dictionary
+   will amend what's there.  The application must insure that the dictionary
+   that was used for compression is provided.
+
+     inflateSetDictionary returns Z_OK if success, Z_STREAM_ERROR if a
+   parameter is invalid (e.g.  dictionary being Z_NULL) or the stream state is
+   inconsistent, Z_DATA_ERROR if the given dictionary doesn't match the
+   expected one (incorrect adler32 value).  inflateSetDictionary does not
+   perform any decompression: this will be done by subsequent calls of
+   inflate().
+*/
+
+ZEXTERN int ZEXPORT inflateGetDictionary OF((z_streamp strm,
+                                             Bytef *dictionary,
+                                             uInt  *dictLength));
+/*
+     Returns the sliding dictionary being maintained by inflate.  dictLength is
+   set to the number of bytes in the dictionary, and that many bytes are copied
+   to dictionary.  dictionary must have enough space, where 32768 bytes is
+   always enough.  If inflateGetDictionary() is called with dictionary equal to
+   Z_NULL, then only the dictionary length is returned, and nothing is copied.
+   Similary, if dictLength is Z_NULL, then it is not set.
+
+     inflateGetDictionary returns Z_OK on success, or Z_STREAM_ERROR if the
+   stream state is inconsistent.
+*/
+
+ZEXTERN int ZEXPORT inflateSync OF((z_streamp strm));
+/*
+     Skips invalid compressed data until a possible full flush point (see above
+   for the description of deflate with Z_FULL_FLUSH) can be found, or until all
+   available input is skipped.  No output is provided.
+
+     inflateSync searches for a 00 00 FF FF pattern in the compressed data.
+   All full flush points have this pattern, but not all occurrences of this
+   pattern are full flush points.
+
+     inflateSync returns Z_OK if a possible full flush point has been found,
+   Z_BUF_ERROR if no more input was provided, Z_DATA_ERROR if no flush point
+   has been found, or Z_STREAM_ERROR if the stream structure was inconsistent.
+   In the success case, the application may save the current current value of
+   total_in which indicates where valid compressed data was found.  In the
+   error case, the application may repeatedly call inflateSync, providing more
+   input each time, until success or end of the input data.
+*/
+
+ZEXTERN int ZEXPORT inflateCopy OF((z_streamp dest,
+                                    z_streamp source));
+/*
+     Sets the destination stream as a complete copy of the source stream.
+
+     This function can be useful when randomly accessing a large stream.  The
+   first pass through the stream can periodically record the inflate state,
+   allowing restarting inflate at those points when randomly accessing the
+   stream.
+
+     inflateCopy returns Z_OK if success, Z_MEM_ERROR if there was not
+   enough memory, Z_STREAM_ERROR if the source stream state was inconsistent
+   (such as zalloc being Z_NULL).  msg is left unchanged in both source and
+   destination.
+*/
+
+ZEXTERN int ZEXPORT inflateReset OF((z_streamp strm));
+/*
+     This function is equivalent to inflateEnd followed by inflateInit,
+   but does not free and reallocate all the internal decompression state.  The
+   stream will keep attributes that may have been set by inflateInit2.
+
+     inflateReset returns Z_OK if success, or Z_STREAM_ERROR if the source
+   stream state was inconsistent (such as zalloc or state being Z_NULL).
+*/
+
+ZEXTERN int ZEXPORT inflateReset2 OF((z_streamp strm,
+                                      int windowBits));
+/*
+     This function is the same as inflateReset, but it also permits changing
+   the wrap and window size requests.  The windowBits parameter is interpreted
+   the same as it is for inflateInit2.
+
+     inflateReset2 returns Z_OK if success, or Z_STREAM_ERROR if the source
+   stream state was inconsistent (such as zalloc or state being Z_NULL), or if
+   the windowBits parameter is invalid.
+*/
+
+ZEXTERN int ZEXPORT inflatePrime OF((z_streamp strm,
+                                     int bits,
+                                     int value));
+/*
+     This function inserts bits in the inflate input stream.  The intent is
+   that this function is used to start inflating at a bit position in the
+   middle of a byte.  The provided bits will be used before any bytes are used
+   from next_in.  This function should only be used with raw inflate, and
+   should be used before the first inflate() call after inflateInit2() or
+   inflateReset().  bits must be less than or equal to 16, and that many of the
+   least significant bits of value will be inserted in the input.
+
+     If bits is negative, then the input stream bit buffer is emptied.  Then
+   inflatePrime() can be called again to put bits in the buffer.  This is used
+   to clear out bits leftover after feeding inflate a block description prior
+   to feeding inflate codes.
+
+     inflatePrime returns Z_OK if success, or Z_STREAM_ERROR if the source
+   stream state was inconsistent.
+*/
+
+ZEXTERN long ZEXPORT inflateMark OF((z_streamp strm));
+/*
+     This function returns two values, one in the lower 16 bits of the return
+   value, and the other in the remaining upper bits, obtained by shifting the
+   return value down 16 bits.  If the upper value is -1 and the lower value is
+   zero, then inflate() is currently decoding information outside of a block.
+   If the upper value is -1 and the lower value is non-zero, then inflate is in
+   the middle of a stored block, with the lower value equaling the number of
+   bytes from the input remaining to copy.  If the upper value is not -1, then
+   it is the number of bits back from the current bit position in the input of
+   the code (literal or length/distance pair) currently being processed.  In
+   that case the lower value is the number of bytes already emitted for that
+   code.
+
+     A code is being processed if inflate is waiting for more input to complete
+   decoding of the code, or if it has completed decoding but is waiting for
+   more output space to write the literal or match data.
+
+     inflateMark() is used to mark locations in the input data for random
+   access, which may be at bit positions, and to note those cases where the
+   output of a code may span boundaries of random access blocks.  The current
+   location in the input stream can be determined from avail_in and data_type
+   as noted in the description for the Z_BLOCK flush parameter for inflate.
+
+     inflateMark returns the value noted above or -1 << 16 if the provided
+   source stream state was inconsistent.
+*/
+
+ZEXTERN int ZEXPORT inflateGetHeader OF((z_streamp strm,
+                                         gz_headerp head));
+/*
+     inflateGetHeader() requests that gzip header information be stored in the
+   provided gz_header structure.  inflateGetHeader() may be called after
+   inflateInit2() or inflateReset(), and before the first call of inflate().
+   As inflate() processes the gzip stream, head->done is zero until the header
+   is completed, at which time head->done is set to one.  If a zlib stream is
+   being decoded, then head->done is set to -1 to indicate that there will be
+   no gzip header information forthcoming.  Note that Z_BLOCK or Z_TREES can be
+   used to force inflate() to return immediately after header processing is
+   complete and before any actual data is decompressed.
+
+     The text, time, xflags, and os fields are filled in with the gzip header
+   contents.  hcrc is set to true if there is a header CRC.  (The header CRC
+   was valid if done is set to one.) If extra is not Z_NULL, then extra_max
+   contains the maximum number of bytes to write to extra.  Once done is true,
+   extra_len contains the actual extra field length, and extra contains the
+   extra field, or that field truncated if extra_max is less than extra_len.
+   If name is not Z_NULL, then up to name_max characters are written there,
+   terminated with a zero unless the length is greater than name_max.  If
+   comment is not Z_NULL, then up to comm_max characters are written there,
+   terminated with a zero unless the length is greater than comm_max.  When any
+   of extra, name, or comment are not Z_NULL and the respective field is not
+   present in the header, then that field is set to Z_NULL to signal its
+   absence.  This allows the use of deflateSetHeader() with the returned
+   structure to duplicate the header.  However if those fields are set to
+   allocated memory, then the application will need to save those pointers
+   elsewhere so that they can be eventually freed.
+
+     If inflateGetHeader is not used, then the header information is simply
+   discarded.  The header is always checked for validity, including the header
+   CRC if present.  inflateReset() will reset the process to discard the header
+   information.  The application would need to call inflateGetHeader() again to
+   retrieve the header from the next gzip stream.
+
+     inflateGetHeader returns Z_OK if success, or Z_STREAM_ERROR if the source
+   stream state was inconsistent.
+*/
+
+/*
+ZEXTERN int ZEXPORT inflateBackInit OF((z_streamp strm, int windowBits,
+                                        unsigned char FAR *window));
+
+     Initialize the internal stream state for decompression using inflateBack()
+   calls.  The fields zalloc, zfree and opaque in strm must be initialized
+   before the call.  If zalloc and zfree are Z_NULL, then the default library-
+   derived memory allocation routines are used.  windowBits is the base two
+   logarithm of the window size, in the range 8..15.  window is a caller
+   supplied buffer of that size.  Except for special applications where it is
+   assured that deflate was used with small window sizes, windowBits must be 15
+   and a 32K byte window must be supplied to be able to decompress general
+   deflate streams.
+
+     See inflateBack() for the usage of these routines.
+
+     inflateBackInit will return Z_OK on success, Z_STREAM_ERROR if any of
+   the parameters are invalid, Z_MEM_ERROR if the internal state could not be
+   allocated, or Z_VERSION_ERROR if the version of the library does not match
+   the version of the header file.
+*/
+
+typedef unsigned (*in_func) OF((void FAR *,
+                                z_const unsigned char FAR * FAR *));
+typedef int (*out_func) OF((void FAR *, unsigned char FAR *, unsigned));
+
+ZEXTERN int ZEXPORT inflateBack OF((z_streamp strm,
+                                    in_func in, void FAR *in_desc,
+                                    out_func out, void FAR *out_desc));
+/*
+     inflateBack() does a raw inflate with a single call using a call-back
+   interface for input and output.  This is potentially more efficient than
+   inflate() for file i/o applications, in that it avoids copying between the
+   output and the sliding window by simply making the window itself the output
+   buffer.  inflate() can be faster on modern CPUs when used with large
+   buffers.  inflateBack() trusts the application to not change the output
+   buffer passed by the output function, at least until inflateBack() returns.
+
+     inflateBackInit() must be called first to allocate the internal state
+   and to initialize the state with the user-provided window buffer.
+   inflateBack() may then be used multiple times to inflate a complete, raw
+   deflate stream with each call.  inflateBackEnd() is then called to free the
+   allocated state.
+
+     A raw deflate stream is one with no zlib or gzip header or trailer.
+   This routine would normally be used in a utility that reads zip or gzip
+   files and writes out uncompressed files.  The utility would decode the
+   header and process the trailer on its own, hence this routine expects only
+   the raw deflate stream to decompress.  This is different from the normal
+   behavior of inflate(), which expects either a zlib or gzip header and
+   trailer around the deflate stream.
+
+     inflateBack() uses two subroutines supplied by the caller that are then
+   called by inflateBack() for input and output.  inflateBack() calls those
+   routines until it reads a complete deflate stream and writes out all of the
+   uncompressed data, or until it encounters an error.  The function's
+   parameters and return types are defined above in the in_func and out_func
+   typedefs.  inflateBack() will call in(in_desc, &buf) which should return the
+   number of bytes of provided input, and a pointer to that input in buf.  If
+   there is no input available, in() must return zero--buf is ignored in that
+   case--and inflateBack() will return a buffer error.  inflateBack() will call
+   out(out_desc, buf, len) to write the uncompressed data buf[0..len-1].  out()
+   should return zero on success, or non-zero on failure.  If out() returns
+   non-zero, inflateBack() will return with an error.  Neither in() nor out()
+   are permitted to change the contents of the window provided to
+   inflateBackInit(), which is also the buffer that out() uses to write from.
+   The length written by out() will be at most the window size.  Any non-zero
+   amount of input may be provided by in().
+
+     For convenience, inflateBack() can be provided input on the first call by
+   setting strm->next_in and strm->avail_in.  If that input is exhausted, then
+   in() will be called.  Therefore strm->next_in must be initialized before
+   calling inflateBack().  If strm->next_in is Z_NULL, then in() will be called
+   immediately for input.  If strm->next_in is not Z_NULL, then strm->avail_in
+   must also be initialized, and then if strm->avail_in is not zero, input will
+   initially be taken from strm->next_in[0 ..  strm->avail_in - 1].
+
+     The in_desc and out_desc parameters of inflateBack() is passed as the
+   first parameter of in() and out() respectively when they are called.  These
+   descriptors can be optionally used to pass any information that the caller-
+   supplied in() and out() functions need to do their job.
+
+     On return, inflateBack() will set strm->next_in and strm->avail_in to
+   pass back any unused input that was provided by the last in() call.  The
+   return values of inflateBack() can be Z_STREAM_END on success, Z_BUF_ERROR
+   if in() or out() returned an error, Z_DATA_ERROR if there was a format error
+   in the deflate stream (in which case strm->msg is set to indicate the nature
+   of the error), or Z_STREAM_ERROR if the stream was not properly initialized.
+   In the case of Z_BUF_ERROR, an input or output error can be distinguished
+   using strm->next_in which will be Z_NULL only if in() returned an error.  If
+   strm->next_in is not Z_NULL, then the Z_BUF_ERROR was due to out() returning
+   non-zero.  (in() will always be called before out(), so strm->next_in is
+   assured to be defined if out() returns non-zero.) Note that inflateBack()
+   cannot return Z_OK.
+*/
+
+ZEXTERN int ZEXPORT inflateBackEnd OF((z_streamp strm));
+/*
+     All memory allocated by inflateBackInit() is freed.
+
+     inflateBackEnd() returns Z_OK on success, or Z_STREAM_ERROR if the stream
+   state was inconsistent.
+*/
+
+ZEXTERN uLong ZEXPORT zlibCompileFlags OF((void));
+/* Return flags indicating compile-time options.
+
+    Type sizes, two bits each, 00 = 16 bits, 01 = 32, 10 = 64, 11 = other:
+     1.0: size of uInt
+     3.2: size of uLong
+     5.4: size of voidpf (pointer)
+     7.6: size of z_off_t
+
+    Compiler, assembler, and debug options:
+     8: DEBUG
+     9: ASMV or ASMINF -- use ASM code
+     10: ZLIB_WINAPI -- exported functions use the WINAPI calling convention
+     11: 0 (reserved)
+
+    One-time table building (smaller code, but not thread-safe if true):
+     12: BUILDFIXED -- build static block decoding tables when needed
+     13: DYNAMIC_CRC_TABLE -- build CRC calculation tables when needed
+     14,15: 0 (reserved)
+
+    Library content (indicates missing functionality):
+     16: NO_GZCOMPRESS -- gz* functions cannot compress (to avoid linking
+                          deflate code when not needed)
+     17: NO_GZIP -- deflate can't write gzip streams, and inflate can't detect
+                    and decode gzip streams (to avoid linking crc code)
+     18-19: 0 (reserved)
+
+    Operation variations (changes in library functionality):
+     20: PKZIP_BUG_WORKAROUND -- slightly more permissive inflate
+     21: FASTEST -- deflate algorithm with only one, lowest compression level
+     22,23: 0 (reserved)
+
+    The sprintf variant used by gzprintf (zero is best):
+     24: 0 = vs*, 1 = s* -- 1 means limited to 20 arguments after the format
+     25: 0 = *nprintf, 1 = *printf -- 1 means gzprintf() not secure!
+     26: 0 = returns value, 1 = void -- 1 means inferred string length returned
+
+    Remainder:
+     27-31: 0 (reserved)
+ */
+
+#ifndef Z_SOLO
+
+                        /* utility functions */
+
+/*
+     The following utility functions are implemented on top of the basic
+   stream-oriented functions.  To simplify the interface, some default options
+   are assumed (compression level and memory usage, standard memory allocation
+   functions).  The source code of these utility functions can be modified if
+   you need special options.
+*/
+
+ZEXTERN int ZEXPORT compress OF((Bytef *dest,   uLongf *destLen,
+                                 const Bytef *source, uLong sourceLen));
+/*
+     Compresses the source buffer into the destination buffer.  sourceLen is
+   the byte length of the source buffer.  Upon entry, destLen is the total size
+   of the destination buffer, which must be at least the value returned by
+   compressBound(sourceLen).  Upon exit, destLen is the actual size of the
+   compressed buffer.
+
+     compress returns Z_OK if success, Z_MEM_ERROR if there was not
+   enough memory, Z_BUF_ERROR if there was not enough room in the output
+   buffer.
+*/
+
+ZEXTERN int ZEXPORT compress2 OF((Bytef *dest,   uLongf *destLen,
+                                  const Bytef *source, uLong sourceLen,
+                                  int level));
+/*
+     Compresses the source buffer into the destination buffer.  The level
+   parameter has the same meaning as in deflateInit.  sourceLen is the byte
+   length of the source buffer.  Upon entry, destLen is the total size of the
+   destination buffer, which must be at least the value returned by
+   compressBound(sourceLen).  Upon exit, destLen is the actual size of the
+   compressed buffer.
+
+     compress2 returns Z_OK if success, Z_MEM_ERROR if there was not enough
+   memory, Z_BUF_ERROR if there was not enough room in the output buffer,
+   Z_STREAM_ERROR if the level parameter is invalid.
+*/
+
+ZEXTERN uLong ZEXPORT compressBound OF((uLong sourceLen));
+/*
+     compressBound() returns an upper bound on the compressed size after
+   compress() or compress2() on sourceLen bytes.  It would be used before a
+   compress() or compress2() call to allocate the destination buffer.
+*/
+
+ZEXTERN int ZEXPORT uncompress OF((Bytef *dest,   uLongf *destLen,
+                                   const Bytef *source, uLong sourceLen));
+/*
+     Decompresses the source buffer into the destination buffer.  sourceLen is
+   the byte length of the source buffer.  Upon entry, destLen is the total size
+   of the destination buffer, which must be large enough to hold the entire
+   uncompressed data.  (The size of the uncompressed data must have been saved
+   previously by the compressor and transmitted to the decompressor by some
+   mechanism outside the scope of this compression library.) Upon exit, destLen
+   is the actual size of the uncompressed buffer.
+
+     uncompress returns Z_OK if success, Z_MEM_ERROR if there was not
+   enough memory, Z_BUF_ERROR if there was not enough room in the output
+   buffer, or Z_DATA_ERROR if the input data was corrupted or incomplete.  In
+   the case where there is not enough room, uncompress() will fill the output
+   buffer with the uncompressed data up to that point.
+*/
+
+                        /* gzip file access functions */
+
+/*
+     This library supports reading and writing files in gzip (.gz) format with
+   an interface similar to that of stdio, using the functions that start with
+   "gz".  The gzip format is different from the zlib format.  gzip is a gzip
+   wrapper, documented in RFC 1952, wrapped around a deflate stream.
+*/
+
+typedef struct gzFile_s *gzFile;    /* semi-opaque gzip file descriptor */
+
+/*
+ZEXTERN gzFile ZEXPORT gzopen OF((const char *path, const char *mode));
+
+     Opens a gzip (.gz) file for reading or writing.  The mode parameter is as
+   in fopen ("rb" or "wb") but can also include a compression level ("wb9") or
+   a strategy: 'f' for filtered data as in "wb6f", 'h' for Huffman-only
+   compression as in "wb1h", 'R' for run-length encoding as in "wb1R", or 'F'
+   for fixed code compression as in "wb9F".  (See the description of
+   deflateInit2 for more information about the strategy parameter.)  'T' will
+   request transparent writing or appending with no compression and not using
+   the gzip format.
+
+     "a" can be used instead of "w" to request that the gzip stream that will
+   be written be appended to the file.  "+" will result in an error, since
+   reading and writing to the same gzip file is not supported.  The addition of
+   "x" when writing will create the file exclusively, which fails if the file
+   already exists.  On systems that support it, the addition of "e" when
+   reading or writing will set the flag to close the file on an execve() call.
+
+     These functions, as well as gzip, will read and decode a sequence of gzip
+   streams in a file.  The append function of gzopen() can be used to create
+   such a file.  (Also see gzflush() for another way to do this.)  When
+   appending, gzopen does not test whether the file begins with a gzip stream,
+   nor does it look for the end of the gzip streams to begin appending.  gzopen
+   will simply append a gzip stream to the existing file.
+
+     gzopen can be used to read a file which is not in gzip format; in this
+   case gzread will directly read from the file without decompression.  When
+   reading, this will be detected automatically by looking for the magic two-
+   byte gzip header.
+
+     gzopen returns NULL if the file could not be opened, if there was
+   insufficient memory to allocate the gzFile state, or if an invalid mode was
+   specified (an 'r', 'w', or 'a' was not provided, or '+' was provided).
+   errno can be checked to determine if the reason gzopen failed was that the
+   file could not be opened.
+*/
+
+ZEXTERN gzFile ZEXPORT gzdopen OF((int fd, const char *mode));
+/*
+     gzdopen associates a gzFile with the file descriptor fd.  File descriptors
+   are obtained from calls like open, dup, creat, pipe or fileno (if the file
+   has been previously opened with fopen).  The mode parameter is as in gzopen.
+
+     The next call of gzclose on the returned gzFile will also close the file
+   descriptor fd, just like fclose(fdopen(fd, mode)) closes the file descriptor
+   fd.  If you want to keep fd open, use fd = dup(fd_keep); gz = gzdopen(fd,
+   mode);.  The duplicated descriptor should be saved to avoid a leak, since
+   gzdopen does not close fd if it fails.  If you are using fileno() to get the
+   file descriptor from a FILE *, then you will have to use dup() to avoid
+   double-close()ing the file descriptor.  Both gzclose() and fclose() will
+   close the associated file descriptor, so they need to have different file
+   descriptors.
+
+     gzdopen returns NULL if there was insufficient memory to allocate the
+   gzFile state, if an invalid mode was specified (an 'r', 'w', or 'a' was not
+   provided, or '+' was provided), or if fd is -1.  The file descriptor is not
+   used until the next gz* read, write, seek, or close operation, so gzdopen
+   will not detect if fd is invalid (unless fd is -1).
+*/
+
+ZEXTERN int ZEXPORT gzbuffer OF((gzFile file, unsigned size));
+/*
+     Set the internal buffer size used by this library's functions.  The
+   default buffer size is 8192 bytes.  This function must be called after
+   gzopen() or gzdopen(), and before any other calls that read or write the
+   file.  The buffer memory allocation is always deferred to the first read or
+   write.  Two buffers are allocated, either both of the specified size when
+   writing, or one of the specified size and the other twice that size when
+   reading.  A larger buffer size of, for example, 64K or 128K bytes will
+   noticeably increase the speed of decompression (reading).
+
+     The new buffer size also affects the maximum length for gzprintf().
+
+     gzbuffer() returns 0 on success, or -1 on failure, such as being called
+   too late.
+*/
+
+ZEXTERN int ZEXPORT gzsetparams OF((gzFile file, int level, int strategy));
+/*
+     Dynamically update the compression level or strategy.  See the description
+   of deflateInit2 for the meaning of these parameters.
+
+     gzsetparams returns Z_OK if success, or Z_STREAM_ERROR if the file was not
+   opened for writing.
+*/
+
+ZEXTERN int ZEXPORT gzread OF((gzFile file, voidp buf, unsigned len));
+/*
+     Reads the given number of uncompressed bytes from the compressed file.  If
+   the input file is not in gzip format, gzread copies the given number of
+   bytes into the buffer directly from the file.
+
+     After reaching the end of a gzip stream in the input, gzread will continue
+   to read, looking for another gzip stream.  Any number of gzip streams may be
+   concatenated in the input file, and will all be decompressed by gzread().
+   If something other than a gzip stream is encountered after a gzip stream,
+   that remaining trailing garbage is ignored (and no error is returned).
+
+     gzread can be used to read a gzip file that is being concurrently written.
+   Upon reaching the end of the input, gzread will return with the available
+   data.  If the error code returned by gzerror is Z_OK or Z_BUF_ERROR, then
+   gzclearerr can be used to clear the end of file indicator in order to permit
+   gzread to be tried again.  Z_OK indicates that a gzip stream was completed
+   on the last gzread.  Z_BUF_ERROR indicates that the input file ended in the
+   middle of a gzip stream.  Note that gzread does not return -1 in the event
+   of an incomplete gzip stream.  This error is deferred until gzclose(), which
+   will return Z_BUF_ERROR if the last gzread ended in the middle of a gzip
+   stream.  Alternatively, gzerror can be used before gzclose to detect this
+   case.
+
+     gzread returns the number of uncompressed bytes actually read, less than
+   len for end of file, or -1 for error.
+*/
+
+ZEXTERN int ZEXPORT gzwrite OF((gzFile file,
+                                voidpc buf, unsigned len));
+/*
+     Writes the given number of uncompressed bytes into the compressed file.
+   gzwrite returns the number of uncompressed bytes written or 0 in case of
+   error.
+*/
+
+ZEXTERN int ZEXPORTVA gzprintf Z_ARG((gzFile file, const char *format, ...));
+/*
+     Converts, formats, and writes the arguments to the compressed file under
+   control of the format string, as in fprintf.  gzprintf returns the number of
+   uncompressed bytes actually written, or 0 in case of error.  The number of
+   uncompressed bytes written is limited to 8191, or one less than the buffer
+   size given to gzbuffer().  The caller should assure that this limit is not
+   exceeded.  If it is exceeded, then gzprintf() will return an error (0) with
+   nothing written.  In this case, there may also be a buffer overflow with
+   unpredictable consequences, which is possible only if zlib was compiled with
+   the insecure functions sprintf() or vsprintf() because the secure snprintf()
+   or vsnprintf() functions were not available.  This can be determined using
+   zlibCompileFlags().
+*/
+
+ZEXTERN int ZEXPORT gzputs OF((gzFile file, const char *s));
+/*
+     Writes the given null-terminated string to the compressed file, excluding
+   the terminating null character.
+
+     gzputs returns the number of characters written, or -1 in case of error.
+*/
+
+ZEXTERN char * ZEXPORT gzgets OF((gzFile file, char *buf, int len));
+/*
+     Reads bytes from the compressed file until len-1 characters are read, or a
+   newline character is read and transferred to buf, or an end-of-file
+   condition is encountered.  If any characters are read or if len == 1, the
+   string is terminated with a null character.  If no characters are read due
+   to an end-of-file or len < 1, then the buffer is left untouched.
+
+     gzgets returns buf which is a null-terminated string, or it returns NULL
+   for end-of-file or in case of error.  If there was an error, the contents at
+   buf are indeterminate.
+*/
+
+ZEXTERN int ZEXPORT gzputc OF((gzFile file, int c));
+/*
+     Writes c, converted to an unsigned char, into the compressed file.  gzputc
+   returns the value that was written, or -1 in case of error.
+*/
+
+ZEXTERN int ZEXPORT gzgetc OF((gzFile file));
+/*
+     Reads one byte from the compressed file.  gzgetc returns this byte or -1
+   in case of end of file or error.  This is implemented as a macro for speed.
+   As such, it does not do all of the checking the other functions do.  I.e.
+   it does not check to see if file is NULL, nor whether the structure file
+   points to has been clobbered or not.
+*/
+
+ZEXTERN int ZEXPORT gzungetc OF((int c, gzFile file));
+/*
+     Push one character back onto the stream to be read as the first character
+   on the next read.  At least one character of push-back is allowed.
+   gzungetc() returns the character pushed, or -1 on failure.  gzungetc() will
+   fail if c is -1, and may fail if a character has been pushed but not read
+   yet.  If gzungetc is used immediately after gzopen or gzdopen, at least the
+   output buffer size of pushed characters is allowed.  (See gzbuffer above.)
+   The pushed character will be discarded if the stream is repositioned with
+   gzseek() or gzrewind().
+*/
+
+ZEXTERN int ZEXPORT gzflush OF((gzFile file, int flush));
+/*
+     Flushes all pending output into the compressed file.  The parameter flush
+   is as in the deflate() function.  The return value is the zlib error number
+   (see function gzerror below).  gzflush is only permitted when writing.
+
+     If the flush parameter is Z_FINISH, the remaining data is written and the
+   gzip stream is completed in the output.  If gzwrite() is called again, a new
+   gzip stream will be started in the output.  gzread() is able to read such
+   concatented gzip streams.
+
+     gzflush should be called only when strictly necessary because it will
+   degrade compression if called too often.
+*/
+
+/*
+ZEXTERN z_off_t ZEXPORT gzseek OF((gzFile file,
+                                   z_off_t offset, int whence));
+
+     Sets the starting position for the next gzread or gzwrite on the given
+   compressed file.  The offset represents a number of bytes in the
+   uncompressed data stream.  The whence parameter is defined as in lseek(2);
+   the value SEEK_END is not supported.
+
+     If the file is opened for reading, this function is emulated but can be
+   extremely slow.  If the file is opened for writing, only forward seeks are
+   supported; gzseek then compresses a sequence of zeroes up to the new
+   starting position.
+
+     gzseek returns the resulting offset location as measured in bytes from
+   the beginning of the uncompressed stream, or -1 in case of error, in
+   particular if the file is opened for writing and the new starting position
+   would be before the current position.
+*/
+
+ZEXTERN int ZEXPORT    gzrewind OF((gzFile file));
+/*
+     Rewinds the given file. This function is supported only for reading.
+
+     gzrewind(file) is equivalent to (int)gzseek(file, 0L, SEEK_SET)
+*/
+
+/*
+ZEXTERN z_off_t ZEXPORT    gztell OF((gzFile file));
+
+     Returns the starting position for the next gzread or gzwrite on the given
+   compressed file.  This position represents a number of bytes in the
+   uncompressed data stream, and is zero when starting, even if appending or
+   reading a gzip stream from the middle of a file using gzdopen().
+
+     gztell(file) is equivalent to gzseek(file, 0L, SEEK_CUR)
+*/
+
+/*
+ZEXTERN z_off_t ZEXPORT gzoffset OF((gzFile file));
+
+     Returns the current offset in the file being read or written.  This offset
+   includes the count of bytes that precede the gzip stream, for example when
+   appending or when using gzdopen() for reading.  When reading, the offset
+   does not include as yet unused buffered input.  This information can be used
+   for a progress indicator.  On error, gzoffset() returns -1.
+*/
+
+ZEXTERN int ZEXPORT gzeof OF((gzFile file));
+/*
+     Returns true (1) if the end-of-file indicator has been set while reading,
+   false (0) otherwise.  Note that the end-of-file indicator is set only if the
+   read tried to go past the end of the input, but came up short.  Therefore,
+   just like feof(), gzeof() may return false even if there is no more data to
+   read, in the event that the last read request was for the exact number of
+   bytes remaining in the input file.  This will happen if the input file size
+   is an exact multiple of the buffer size.
+
+     If gzeof() returns true, then the read functions will return no more data,
+   unless the end-of-file indicator is reset by gzclearerr() and the input file
+   has grown since the previous end of file was detected.
+*/
+
+ZEXTERN int ZEXPORT gzdirect OF((gzFile file));
+/*
+     Returns true (1) if file is being copied directly while reading, or false
+   (0) if file is a gzip stream being decompressed.
+
+     If the input file is empty, gzdirect() will return true, since the input
+   does not contain a gzip stream.
+
+     If gzdirect() is used immediately after gzopen() or gzdopen() it will
+   cause buffers to be allocated to allow reading the file to determine if it
+   is a gzip file.  Therefore if gzbuffer() is used, it should be called before
+   gzdirect().
+
+     When writing, gzdirect() returns true (1) if transparent writing was
+   requested ("wT" for the gzopen() mode), or false (0) otherwise.  (Note:
+   gzdirect() is not needed when writing.  Transparent writing must be
+   explicitly requested, so the application already knows the answer.  When
+   linking statically, using gzdirect() will include all of the zlib code for
+   gzip file reading and decompression, which may not be desired.)
+*/
+
+ZEXTERN int ZEXPORT    gzclose OF((gzFile file));
+/*
+     Flushes all pending output if necessary, closes the compressed file and
+   deallocates the (de)compression state.  Note that once file is closed, you
+   cannot call gzerror with file, since its structures have been deallocated.
+   gzclose must not be called more than once on the same file, just as free
+   must not be called more than once on the same allocation.
+
+     gzclose will return Z_STREAM_ERROR if file is not valid, Z_ERRNO on a
+   file operation error, Z_MEM_ERROR if out of memory, Z_BUF_ERROR if the
+   last read ended in the middle of a gzip stream, or Z_OK on success.
+*/
+
+ZEXTERN int ZEXPORT gzclose_r OF((gzFile file));
+ZEXTERN int ZEXPORT gzclose_w OF((gzFile file));
+/*
+     Same as gzclose(), but gzclose_r() is only for use when reading, and
+   gzclose_w() is only for use when writing or appending.  The advantage to
+   using these instead of gzclose() is that they avoid linking in zlib
+   compression or decompression code that is not used when only reading or only
+   writing respectively.  If gzclose() is used, then both compression and
+   decompression code will be included the application when linking to a static
+   zlib library.
+*/
+
+ZEXTERN const char * ZEXPORT gzerror OF((gzFile file, int *errnum));
+/*
+     Returns the error message for the last error which occurred on the given
+   compressed file.  errnum is set to zlib error number.  If an error occurred
+   in the file system and not in the compression library, errnum is set to
+   Z_ERRNO and the application may consult errno to get the exact error code.
+
+     The application must not modify the returned string.  Future calls to
+   this function may invalidate the previously returned string.  If file is
+   closed, then the string previously returned by gzerror will no longer be
+   available.
+
+     gzerror() should be used to distinguish errors from end-of-file for those
+   functions above that do not distinguish those cases in their return values.
+*/
+
+ZEXTERN void ZEXPORT gzclearerr OF((gzFile file));
+/*
+     Clears the error and end-of-file flags for file.  This is analogous to the
+   clearerr() function in stdio.  This is useful for continuing to read a gzip
+   file that is being written concurrently.
+*/
+
+#endif /* !Z_SOLO */
+
+                        /* checksum functions */
+
+/*
+     These functions are not related to compression but are exported
+   anyway because they might be useful in applications using the compression
+   library.
+*/
+
+ZEXTERN uLong ZEXPORT adler32 OF((uLong adler, const Bytef *buf, uInt len));
+/*
+     Update a running Adler-32 checksum with the bytes buf[0..len-1] and
+   return the updated checksum.  If buf is Z_NULL, this function returns the
+   required initial value for the checksum.
+
+     An Adler-32 checksum is almost as reliable as a CRC32 but can be computed
+   much faster.
+
+   Usage example:
+
+     uLong adler = adler32(0L, Z_NULL, 0);
+
+     while (read_buffer(buffer, length) != EOF) {
+       adler = adler32(adler, buffer, length);
+     }
+     if (adler != original_adler) error();
+*/
+
+/*
+ZEXTERN uLong ZEXPORT adler32_combine OF((uLong adler1, uLong adler2,
+                                          z_off_t len2));
+
+     Combine two Adler-32 checksums into one.  For two sequences of bytes, seq1
+   and seq2 with lengths len1 and len2, Adler-32 checksums were calculated for
+   each, adler1 and adler2.  adler32_combine() returns the Adler-32 checksum of
+   seq1 and seq2 concatenated, requiring only adler1, adler2, and len2.  Note
+   that the z_off_t type (like off_t) is a signed integer.  If len2 is
+   negative, the result has no meaning or utility.
+*/
+
+ZEXTERN uLong ZEXPORT crc32   OF((uLong crc, const Bytef *buf, uInt len));
+/*
+     Update a running CRC-32 with the bytes buf[0..len-1] and return the
+   updated CRC-32.  If buf is Z_NULL, this function returns the required
+   initial value for the crc.  Pre- and post-conditioning (one's complement) is
+   performed within this function so it shouldn't be done by the application.
+
+   Usage example:
+
+     uLong crc = crc32(0L, Z_NULL, 0);
+
+     while (read_buffer(buffer, length) != EOF) {
+       crc = crc32(crc, buffer, length);
+     }
+     if (crc != original_crc) error();
+*/
+
+/*
+ZEXTERN uLong ZEXPORT crc32_combine OF((uLong crc1, uLong crc2, z_off_t len2));
+
+     Combine two CRC-32 check values into one.  For two sequences of bytes,
+   seq1 and seq2 with lengths len1 and len2, CRC-32 check values were
+   calculated for each, crc1 and crc2.  crc32_combine() returns the CRC-32
+   check value of seq1 and seq2 concatenated, requiring only crc1, crc2, and
+   len2.
+*/
+
+
+                        /* various hacks, don't look :) */
+
+/* deflateInit and inflateInit are macros to allow checking the zlib version
+ * and the compiler's view of z_stream:
+ */
+ZEXTERN int ZEXPORT deflateInit_ OF((z_streamp strm, int level,
+                                     const char *version, int stream_size));
+ZEXTERN int ZEXPORT inflateInit_ OF((z_streamp strm,
+                                     const char *version, int stream_size));
+ZEXTERN int ZEXPORT deflateInit2_ OF((z_streamp strm, int  level, int  method,
+                                      int windowBits, int memLevel,
+                                      int strategy, const char *version,
+                                      int stream_size));
+ZEXTERN int ZEXPORT inflateInit2_ OF((z_streamp strm, int  windowBits,
+                                      const char *version, int stream_size));
+ZEXTERN int ZEXPORT inflateBackInit_ OF((z_streamp strm, int windowBits,
+                                         unsigned char FAR *window,
+                                         const char *version,
+                                         int stream_size));
+#define deflateInit(strm, level) \
+        deflateInit_((strm), (level), ZLIB_VERSION, (int)sizeof(z_stream))
+#define inflateInit(strm) \
+        inflateInit_((strm), ZLIB_VERSION, (int)sizeof(z_stream))
+#define deflateInit2(strm, level, method, windowBits, memLevel, strategy) \
+        deflateInit2_((strm),(level),(method),(windowBits),(memLevel),\
+                      (strategy), ZLIB_VERSION, (int)sizeof(z_stream))
+#define inflateInit2(strm, windowBits) \
+        inflateInit2_((strm), (windowBits), ZLIB_VERSION, \
+                      (int)sizeof(z_stream))
+#define inflateBackInit(strm, windowBits, window) \
+        inflateBackInit_((strm), (windowBits), (window), \
+                      ZLIB_VERSION, (int)sizeof(z_stream))
+
+#ifndef Z_SOLO
+
+/* gzgetc() macro and its supporting function and exposed data structure.  Note
+ * that the real internal state is much larger than the exposed structure.
+ * This abbreviated structure exposes just enough for the gzgetc() macro.  The
+ * user should not mess with these exposed elements, since their names or
+ * behavior could change in the future, perhaps even capriciously.  They can
+ * only be used by the gzgetc() macro.  You have been warned.
+ */
+struct gzFile_s {
+    unsigned have;
+    unsigned char *next;
+    z_off64_t pos;
+};
+ZEXTERN int ZEXPORT gzgetc_ OF((gzFile file));  /* backward compatibility */
+#ifdef Z_PREFIX_SET
+#  undef z_gzgetc
+#  define z_gzgetc(g) \
+          ((g)->have ? ((g)->have--, (g)->pos++, *((g)->next)++) : gzgetc(g))
+#else
+#  define gzgetc(g) \
+          ((g)->have ? ((g)->have--, (g)->pos++, *((g)->next)++) : gzgetc(g))
+#endif
+
+/* provide 64-bit offset functions if _LARGEFILE64_SOURCE defined, and/or
+ * change the regular functions to 64 bits if _FILE_OFFSET_BITS is 64 (if
+ * both are true, the application gets the *64 functions, and the regular
+ * functions are changed to 64 bits) -- in case these are set on systems
+ * without large file support, _LFS64_LARGEFILE must also be true
+ */
+#ifdef Z_LARGE64
+   ZEXTERN gzFile ZEXPORT gzopen64 OF((const char *, const char *));
+   ZEXTERN z_off64_t ZEXPORT gzseek64 OF((gzFile, z_off64_t, int));
+   ZEXTERN z_off64_t ZEXPORT gztell64 OF((gzFile));
+   ZEXTERN z_off64_t ZEXPORT gzoffset64 OF((gzFile));
+   ZEXTERN uLong ZEXPORT adler32_combine64 OF((uLong, uLong, z_off64_t));
+   ZEXTERN uLong ZEXPORT crc32_combine64 OF((uLong, uLong, z_off64_t));
+#endif
+
+#if !defined(ZLIB_INTERNAL) && defined(Z_WANT64)
+#  ifdef Z_PREFIX_SET
+#    define z_gzopen z_gzopen64
+#    define z_gzseek z_gzseek64
+#    define z_gztell z_gztell64
+#    define z_gzoffset z_gzoffset64
+#    define z_adler32_combine z_adler32_combine64
+#    define z_crc32_combine z_crc32_combine64
+#  else
+#    define gzopen gzopen64
+#    define gzseek gzseek64
+#    define gztell gztell64
+#    define gzoffset gzoffset64
+#    define adler32_combine adler32_combine64
+#    define crc32_combine crc32_combine64
+#  endif
+#  ifndef Z_LARGE64
+     ZEXTERN gzFile ZEXPORT gzopen64 OF((const char *, const char *));
+     ZEXTERN z_off_t ZEXPORT gzseek64 OF((gzFile, z_off_t, int));
+     ZEXTERN z_off_t ZEXPORT gztell64 OF((gzFile));
+     ZEXTERN z_off_t ZEXPORT gzoffset64 OF((gzFile));
+     ZEXTERN uLong ZEXPORT adler32_combine64 OF((uLong, uLong, z_off_t));
+     ZEXTERN uLong ZEXPORT crc32_combine64 OF((uLong, uLong, z_off_t));
+#  endif
+#else
+   ZEXTERN gzFile ZEXPORT gzopen OF((const char *, const char *));
+   ZEXTERN z_off_t ZEXPORT gzseek OF((gzFile, z_off_t, int));
+   ZEXTERN z_off_t ZEXPORT gztell OF((gzFile));
+   ZEXTERN z_off_t ZEXPORT gzoffset OF((gzFile));
+   ZEXTERN uLong ZEXPORT adler32_combine OF((uLong, uLong, z_off_t));
+   ZEXTERN uLong ZEXPORT crc32_combine OF((uLong, uLong, z_off_t));
+#endif
+
+#else /* Z_SOLO */
+
+   ZEXTERN uLong ZEXPORT adler32_combine OF((uLong, uLong, z_off_t));
+   ZEXTERN uLong ZEXPORT crc32_combine OF((uLong, uLong, z_off_t));
+
+#endif /* !Z_SOLO */
+
+/* hack for buggy compilers */
+#if !defined(ZUTIL_H) && !defined(NO_DUMMY_DECL)
+    struct internal_state {int dummy;};
+#endif
+
+/* undocumented functions */
+ZEXTERN const char   * ZEXPORT zError           OF((int));
+ZEXTERN int            ZEXPORT inflateSyncPoint OF((z_streamp));
+ZEXTERN const z_crc_t FAR * ZEXPORT get_crc_table    OF((void));
+ZEXTERN int            ZEXPORT inflateUndermine OF((z_streamp, int));
+ZEXTERN int            ZEXPORT inflateResetKeep OF((z_streamp));
+ZEXTERN int            ZEXPORT deflateResetKeep OF((z_streamp));
+#if defined(_WIN32) && !defined(Z_SOLO)
+ZEXTERN gzFile         ZEXPORT gzopen_w OF((const wchar_t *path,
+                                            const char *mode));
+#endif
+#if defined(STDC) || defined(Z_HAVE_STDARG_H)
+#  ifndef Z_SOLO
+ZEXTERN int            ZEXPORTVA gzvprintf Z_ARG((gzFile file,
+                                                  const char *format,
+                                                  va_list va));
+#  endif
+#endif
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* ZLIB_H */
diff --git a/libpcsxcore/mdec.c b/libpcsxcore/mdec.c
index d6c7ab68..49375545 100644
--- a/libpcsxcore/mdec.c
+++ b/libpcsxcore/mdec.c
@@ -32,7 +32,7 @@
  * 320x240x16@60Hz => 9.216 MB/s
  * so 2.0 to 4.0 should be fine.
  */
-#define MDEC_BIAS 2
+#define MDEC_BIAS 6
 
 #define DSIZE			8
 #define DSIZE2			(DSIZE * DSIZE)
diff --git a/libpcsxcore/new_dynarec/backends/psx/emu_if.c b/libpcsxcore/new_dynarec/backends/psx/emu_if.c
index 2a090a0b..ee836213 100644
--- a/libpcsxcore/new_dynarec/backends/psx/emu_if.c
+++ b/libpcsxcore/new_dynarec/backends/psx/emu_if.c
@@ -19,10 +19,6 @@
 
 #include "../../../gte.h"
 
-#define FLAGLESS
-#include "../../../gte.h"
-#undef  FLAGLESS
-
 #define ARRAY_SIZE(x) (sizeof(x) / sizeof(x[0]))
 
 //#define evprintf printf
@@ -198,6 +194,7 @@ void new_dyna_freeze(void *f, int mode)
 /* GTE stuff */
 void *gte_handlers[64];
 
+#ifdef FLAGLESS
 void *gte_handlers_nf[64] = {
 	NULL      , gteRTPS_nf , NULL       , NULL      , NULL     , NULL       , gteNCLIP_nf, NULL      , // 00
 	NULL      , NULL       , NULL       , NULL      , gteOP_nf , NULL       , NULL       , NULL      , // 08
@@ -208,6 +205,18 @@ void *gte_handlers_nf[64] = {
 	gteRTPT_nf, NULL       , NULL       , NULL      , NULL     , NULL       , NULL       , NULL      , // 30
 	NULL      , NULL       , NULL       , NULL      , NULL     , gteGPF_nf  , gteGPL_nf  , gteNCCT_nf, // 38
 };
+#else
+void *gte_handlers_nf[64] = {
+	NULL      , gteRTPS , NULL       , NULL      , NULL     , NULL       , gteNCLIP, NULL      , // 00
+	NULL      , NULL       , NULL       , NULL      , gteOP , NULL       , NULL       , NULL      , // 08
+	gteDPCS, gteINTPL, gteMVMVA, gteNCDS, gteCDP, NULL       , gteNCDT , NULL      , // 10
+	NULL      , NULL       , NULL       , gteNCCS, gteCC , NULL       , gteNCS  , NULL      , // 18
+	gteNCT , NULL       , NULL       , NULL      , NULL     , NULL       , NULL       , NULL      , // 20
+	gteSQR , gteDCPL , gteDPCT , NULL      , NULL     , gteAVSZ3, gteAVSZ4, NULL      , // 28 
+	gteRTPT, NULL       , NULL       , NULL      , NULL     , NULL       , NULL       , NULL      , // 30
+	NULL      , NULL       , NULL       , NULL      , NULL     , gteGPF  , gteGPL  , gteNCCT, // 38
+};
+#endif
 
 const char *gte_regnames[64] = {
 	NULL  , "RTPS" , NULL   , NULL  , NULL , NULL   , "NCLIP", NULL  , // 00
diff --git a/libpcsxcore/psxbios.c b/libpcsxcore/psxbios.c
index a6846017..ac530e02 100644
--- a/libpcsxcore/psxbios.c
+++ b/libpcsxcore/psxbios.c
@@ -248,7 +248,7 @@ static char *pad_buf1 = NULL, *pad_buf2 = NULL;
 static int pad_buf1len, pad_buf2len;
 
 static u32 regs[35];
-static EvCB *Event;
+static EvCB *_Event;
 static EvCB *HwEV; // 0xf0
 static EvCB *EvEV; // 0xf1
 static EvCB *RcEV; // 0xf2
@@ -259,7 +259,7 @@ static u32 *heap_addr = NULL;
 static u32 *heap_end = NULL;
 static u32 SysIntRP[8];
 static int CardState = -1;
-static TCB Thread[8];
+static TCB _Thread[8];
 static int CurThread = 0;
 static FileDesc FDesc[32];
 static u32 card_active_chan = 0;
@@ -291,12 +291,12 @@ static inline void softCall2(u32 pc) {
 }
 
 static inline void DeliverEvent(u32 ev, u32 spec) {
-	if (Event[ev][spec].status != EvStACTIVE) return;
+	if (_Event[ev][spec].status != EvStACTIVE) return;
 
-//	Event[ev][spec].status = EvStALREADY;
-	if (Event[ev][spec].mode == EvMdINTR) {
-		softCall2(Event[ev][spec].fhandler);
-	} else Event[ev][spec].status = EvStALREADY;
+//	_Event[ev][spec].status = EvStALREADY;
+	if (_Event[ev][spec].mode == EvMdINTR) {
+		softCall2(_Event[ev][spec].fhandler);
+	} else _Event[ev][spec].status = EvStALREADY;
 }
 
 static inline void SaveRegs() {
@@ -1389,14 +1389,14 @@ void psxBios_ResetRCnt() { // 06
 }
 
 
-/* gets ev for use with Event */
+/* gets ev for use with _Event */
 #define GetEv() \
 	ev = (a0 >> 24) & 0xf; \
 	if (ev == 0xf) ev = 0x5; \
 	ev*= 32; \
 	ev+= a0&0x1f;
 
-/* gets spec for use with Event */
+/* gets spec for use with _Event */
 #define GetSpec() \
 	spec = 0; \
 	switch (a1) { \
@@ -1434,9 +1434,9 @@ void psxBios_OpenEvent() { // 08
 	PSXBIOS_LOG("psxBios_%s %x,%x (class:%x, spec:%x, mode:%x, func:%x)\n", biosB0n[0x08], ev, spec, a0, a1, a2, a3);
 #endif
 
-	Event[ev][spec].status = EvStWAIT;
-	Event[ev][spec].mode = a2;
-	Event[ev][spec].fhandler = a3;
+	_Event[ev][spec].status = EvStWAIT;
+	_Event[ev][spec].mode = a2;
+	_Event[ev][spec].fhandler = a3;
 
 	v0 = ev | (spec << 8);
 	pc0 = ra;
@@ -1452,7 +1452,7 @@ void psxBios_CloseEvent() { // 09
 	PSXBIOS_LOG("psxBios_%s %x,%x\n", biosB0n[0x09], ev, spec);
 #endif
 
-	Event[ev][spec].status = EvStUNUSED;
+	_Event[ev][spec].status = EvStUNUSED;
 
 	v0 = 1; pc0 = ra;
 }
@@ -1467,7 +1467,7 @@ void psxBios_WaitEvent() { // 0a
 	PSXBIOS_LOG("psxBios_%s %x,%x\n", biosB0n[0x0a], ev, spec);
 #endif
 
-	Event[ev][spec].status = EvStACTIVE;
+	_Event[ev][spec].status = EvStACTIVE;
 
 	v0 = 1; pc0 = ra;
 }
@@ -1478,8 +1478,8 @@ void psxBios_TestEvent() { // 0b
 	ev   = a0 & 0xff;
 	spec = (a0 >> 8) & 0xff;
 
-	if (Event[ev][spec].status == EvStALREADY) {
-		Event[ev][spec].status = EvStACTIVE; v0 = 1;
+	if (_Event[ev][spec].status == EvStALREADY) {
+		_Event[ev][spec].status = EvStACTIVE; v0 = 1;
 	} else v0 = 0;
 
 #ifdef PSXBIOS_LOG
@@ -1499,7 +1499,7 @@ void psxBios_EnableEvent() { // 0c
 	PSXBIOS_LOG("psxBios_%s %x,%x\n", biosB0n[0x0c], ev, spec);
 #endif
 
-	Event[ev][spec].status = EvStACTIVE;
+	_Event[ev][spec].status = EvStACTIVE;
 
 	v0 = 1; pc0 = ra;
 }
@@ -1514,7 +1514,7 @@ void psxBios_DisableEvent() { // 0d
 	PSXBIOS_LOG("psxBios_%s %x,%x\n", biosB0n[0x0d], ev, spec);
 #endif
 
-	Event[ev][spec].status = EvStWAIT;
+	_Event[ev][spec].status = EvStWAIT;
 
 	v0 = 1; pc0 = ra;
 }
@@ -1527,22 +1527,22 @@ void psxBios_OpenTh() { // 0e
 	int th;
 
 	for (th=1; th<8; th++)
-		if (Thread[th].status == 0) break;
+		if (_Thread[th].status == 0) break;
 
 #ifdef PSXBIOS_LOG
 	PSXBIOS_LOG("psxBios_%s: %x\n", biosB0n[0x0e], th);
 #endif
 
-	Thread[th].status = 1;
-	Thread[th].func    = a0;
-	Thread[th].reg[29] = a1;
-	Thread[th].reg[28] = a2;
+	_Thread[th].status = 1;
+	_Thread[th].func    = a0;
+	_Thread[th].reg[29] = a1;
+	_Thread[th].reg[28] = a2;
 
 	v0 = th; pc0 = ra;
 }
 
 /*
- *	int CloseTh(long thread);
+ *	int CloseTh(long _Thread);
  */
 
 void psxBios_CloseTh() { // 0f
@@ -1552,10 +1552,10 @@ void psxBios_CloseTh() { // 0f
 	PSXBIOS_LOG("psxBios_%s: %x\n", biosB0n[0x0f], th);
 #endif
 
-	if (Thread[th].status == 0) {
+	if (_Thread[th].status == 0) {
 		v0 = 0;
 	} else {
-		Thread[th].status = 0;
+		_Thread[th].status = 0;
 		v0 = 1;
 	}
 
@@ -1563,7 +1563,7 @@ void psxBios_CloseTh() { // 0f
 }
 
 /*
- *	int ChangeTh(long thread);
+ *	int ChangeTh(long _Thread);
  */
 
 void psxBios_ChangeTh() { // 10
@@ -1573,22 +1573,22 @@ void psxBios_ChangeTh() { // 10
 //	PSXBIOS_LOG("psxBios_%s: %x\n", biosB0n[0x10], th);
 #endif
 
-	if (Thread[th].status == 0 || CurThread == th) {
+	if (_Thread[th].status == 0 || CurThread == th) {
 		v0 = 0;
 
 		pc0 = ra;
 	} else {
 		v0 = 1;
 
-		if (Thread[CurThread].status == 2) {
-			Thread[CurThread].status = 1;
-			Thread[CurThread].func = ra;
-			memcpy(Thread[CurThread].reg, psxRegs.GPR.r, 32*4);
+		if (_Thread[CurThread].status == 2) {
+			_Thread[CurThread].status = 1;
+			_Thread[CurThread].func = ra;
+			memcpy(_Thread[CurThread].reg, psxRegs.GPR.r, 32*4);
 		}
 
-		memcpy(psxRegs.GPR.r, Thread[th].reg, 32*4);
-		pc0 = Thread[th].func;
-		Thread[th].status = 2;
+		memcpy(psxRegs.GPR.r, _Thread[th].reg, 32*4);
+		pc0 = _Thread[th].func;
+		_Thread[th].status = 2;
 		CurThread = th;
 	}
 }
@@ -1684,9 +1684,9 @@ void psxBios_UnDeliverEvent() { // 0x20
 	PSXBIOS_LOG("psxBios_%s %x,%x\n", biosB0n[0x20], ev, spec);
 #endif
 
-	if (Event[ev][spec].status == EvStALREADY &&
-		Event[ev][spec].mode == EvMdNOINTR)
-		Event[ev][spec].status = EvStACTIVE;
+	if (_Event[ev][spec].status == EvStALREADY &&
+		_Event[ev][spec].mode == EvMdNOINTR)
+		_Event[ev][spec].status = EvStACTIVE;
 
 	pc0 = ra;
 }
@@ -1951,7 +1951,7 @@ void psxBios_firstfile() { // 42
 		}
 	}
 
-	// firstfile() calls _card_read() internally, so deliver it's event
+	// firstfile() calls _card_read() internally, so deliver it's _Event
 	DeliverEvent(0x11, 0x2);
 
 	pc0 = ra;
@@ -2636,14 +2636,14 @@ void psxBiosInit() {
 /**/
 	base = 0x1000;
 	size = sizeof(EvCB) * 32;
-	Event = (void *)&psxR[base]; base += size * 6;
-	memset(Event, 0, size * 6);
-	HwEV = Event;
-	EvEV = Event + 32;
-	RcEV = Event + 32 * 2;
-	UeEV = Event + 32 * 3;
-	SwEV = Event + 32 * 4;
-	ThEV = Event + 32 * 5;
+	_Event = (void *)&psxR[base]; base += size * 6;
+	memset(_Event, 0, size * 6);
+	HwEV = _Event;
+	EvEV = _Event + 32;
+	RcEV = _Event + 32 * 2;
+	UeEV = _Event + 32 * 3;
+	SwEV = _Event + 32 * 4;
+	ThEV = _Event + 32 * 5;
 
 	ptr = (u32 *)&psxM[0x0874]; // b0 table
 	ptr[0] = SWAPu32(0x4c54 - 0x884);
@@ -2652,8 +2652,8 @@ void psxBiosInit() {
 	ptr[6] = SWAPu32(0xc80);
 
 	memset(SysIntRP, 0, sizeof(SysIntRP));
-	memset(Thread, 0, sizeof(Thread));
-	Thread[0].status = 2; // main thread
+	memset(_Thread, 0, sizeof(_Thread));
+	_Thread[0].status = 2; // main _Thread
 
 	jmp_int = NULL;
 	pad_buf = NULL;
@@ -2929,7 +2929,7 @@ void psxBiosFreeze(int Mode) {
 	bfreezes(regs);
 	bfreezes(SysIntRP);
 	bfreezel(&CardState);
-	bfreezes(Thread);
+	bfreezes(_Thread);
 	bfreezel(&CurThread);
 	bfreezes(FDesc);
 	bfreezel(&card_active_chan);
diff --git a/libpcsxcore/psxcommon.h b/libpcsxcore/psxcommon.h
index a7dd6aea..19c8d771 100644
--- a/libpcsxcore/psxcommon.h
+++ b/libpcsxcore/psxcommon.h
@@ -40,7 +40,9 @@ extern "C" {
 #include <math.h>
 #include <time.h>
 #include <ctype.h>
+#ifndef __SWITCH__
 #include <sys/types.h>
+#endif
 #include <assert.h>
 
 // Define types
diff --git a/plugins/gpu_unai/README_senquack.txt b/plugins/gpu_unai/README_senquack.txt
new file mode 100644
index 00000000..cda17fca
--- /dev/null
+++ b/plugins/gpu_unai/README_senquack.txt
@@ -0,0 +1,956 @@
+//NOTE: You can find the set of original Unai poly routines (disabled now)
+// at the bottom end of this file.
+
+//senquack - Original Unai GPU poly routines have been replaced with new
+// ones based on DrHell routines. The original routines suffered from
+// shifted rows, causing many quads to have their first triangle drawn
+// correctly, but the second triangle would randomly have pixels shifted
+// either left or right or entire rows not drawn at all. Furthermore,
+// some times entire triangles seemed to be either missing or only
+// partially drawn (most clearly seen in sky/road textures in NFS3,
+// clock tower in beginning of Castlevania SOTN). Pixel gaps were
+// prevalent.
+//
+// Since DrHell GPU didn't seem to exhibit these artifacts at all, I adapted
+// its routines to GPU Unai (Unai was probably already originally based on it).
+// DrHell uses 22.10 fixed point instead of Unai's 16.16, so gpu_fixedpoint.h
+// required modification as well as gpu_inner.h (where gpuPolySpanFn driver
+// functions are).
+//
+// Originally, I tried to patch up original Unai routines and got as far
+// as fixing the shifted rows, but still had other problem of triangles rendered
+// wrong (black triangular gaps in NFS3 sky, clock tower in Castlevania SOTN).
+// I eventually gave up. Even after rewriting/adapting the routines,
+// however, I still had some random pixel droupouts, specifically in
+// NFS3 sky texture. I discovered that gpu_inner.h gpuPolySpanFn function
+// was taking optimizations to an extreme and packing u/v texture coords
+// into one 32-bit word, reducing their accuracy. Only once they were
+// handled in full-accuracy individual words was that problem fixed.
+//
+// NOTE: I also added support for doing divisions using the FPU, either
+//  with normal division or multiplication-by-reciprocal.
+//  To use float division, GPU_UNAI_USE_FLOATMATH should be defined.
+//  To use float mult-by-reciprocal, GPU_UNAI_USE_FLOAT_DIV_MULTINV
+//   can be specified (GPU_UNAI_USE_FLOATMATH must also be specified)
+//  To use inaccurate fixed-point mult-by-reciprocal, define
+//   GPU_UNAI_USE_INT_DIV_MULTINV. This is the default on older
+//   ARM devices like Wiz/Caanoo that have neither integer division
+//   in hardware or an FPU. It results in some pixel dropouts,
+//   texture glitches, but less than the original GPU UNAI code.
+//
+//  If nothing is specified, integer division will be used.
+//
+// NOTE 2: Even with MIPS32R2 having FPU recip.s instruction, and it is
+//  used when this platform is detected, I found it not to give any
+//  noticeable speedup over normal float division (in fact seemed a tiny
+//  tiny bit slower). I also found float division to not provide any
+//  noticeable speedups versus integer division on MISP32R2 platform.
+//  Granted, the differences were all around .5 FPS or less.
+//
+// TODO:
+// * See if anything can be done about remaining pixel gaps in Gran
+//   Turismo car models, track.
+// * Find better way of passing parameters to gpuPolySpanFn functions than
+//   through original Unai method of using global variables u4,v4,du4 etc.
+// * Come up with some newer way of drawing rows of pixels than by calling
+//   gpuPolySpanFn through function pointer. For every row, at least on
+//   MIPS platforms, many registers are having to be pushed/popped from stack
+//   on each call, which is strange since MIPS has so many registers.
+// * MIPS MXU/ASM optimized gpuPolySpanFn ?
+
+//////////////////////////////////////////////////////////////////////////
+//senquack - Disabled original Unai poly routines left here for reference:
+// ( from gpu_raster_polygon.h )
+//////////////////////////////////////////////////////////////////////////
+#define GPU_TESTRANGE3() \
+{ \
+	if(x0<0) { if((x1-x0)>CHKMAX_X) return; if((x2-x0)>CHKMAX_X) return; } \
+	if(x1<0) { if((x0-x1)>CHKMAX_X) return; if((x2-x1)>CHKMAX_X) return; } \
+	if(x2<0) { if((x0-x2)>CHKMAX_X) return; if((x1-x2)>CHKMAX_X) return; } \
+	if(y0<0) { if((y1-y0)>CHKMAX_Y) return; if((y2-y0)>CHKMAX_Y) return; } \
+	if(y1<0) { if((y0-y1)>CHKMAX_Y) return; if((y2-y1)>CHKMAX_Y) return; } \
+	if(y2<0) { if((y0-y2)>CHKMAX_Y) return; if((y1-y2)>CHKMAX_Y) return; } \
+}
+
+/*----------------------------------------------------------------------
+F3
+----------------------------------------------------------------------*/
+
+void gpuDrawF3(const PP gpuPolySpanDriver)
+{
+	const int li=linesInterlace;
+	const int pi=(progressInterlace?(linesInterlace+1):0);
+	const int pif=(progressInterlace?(progressInterlace_flag?(linesInterlace+1):0):1);
+	s32 temp;
+	s32 xa, xb, xmin, xmax;
+	s32 ya, yb, ymin, ymax;
+	s32 x0, x1, x2, x3, dx3=0, x4, dx4=0, dx;
+	s32 y0, y1, y2;
+
+	x0 = GPU_EXPANDSIGN(PacketBuffer.S2[2]);
+	y0 = GPU_EXPANDSIGN(PacketBuffer.S2[3]);
+	x1 = GPU_EXPANDSIGN(PacketBuffer.S2[4]);
+	y1 = GPU_EXPANDSIGN(PacketBuffer.S2[5]);
+	x2 = GPU_EXPANDSIGN(PacketBuffer.S2[6]);
+	y2 = GPU_EXPANDSIGN(PacketBuffer.S2[7]);
+
+	GPU_TESTRANGE3();
+	
+	x0 += DrawingOffset[0];   x1 += DrawingOffset[0];   x2 += DrawingOffset[0];
+	y0 += DrawingOffset[1];   y1 += DrawingOffset[1];   y2 += DrawingOffset[1];
+
+	xmin = DrawingArea[0];  xmax = DrawingArea[2];
+	ymin = DrawingArea[1];  ymax = DrawingArea[3];
+
+	{
+		int rx0 = Max2(xmin,Min3(x0,x1,x2));
+		int ry0 = Max2(ymin,Min3(y0,y1,y2));
+		int rx1 = Min2(xmax,Max3(x0,x1,x2));
+		int ry1 = Min2(ymax,Max3(y0,y1,y2));
+		if( rx0>=rx1 || ry0>=ry1) return;
+	}
+	
+	PixelData = GPU_RGB16(PacketBuffer.U4[0]);
+
+	if (y0 >= y1)
+	{
+		if( y0!=y1 || x0>x1 )
+		{
+			GPU_SWAP(x0, x1, temp);
+			GPU_SWAP(y0, y1, temp);
+		}
+	}
+	if (y1 >= y2)
+	{
+		if( y1!=y2 || x1>x2 )
+		{
+			GPU_SWAP(x1, x2, temp);
+			GPU_SWAP(y1, y2, temp);
+		}
+	}
+	if (y0 >= y1)
+	{
+		if( y0!=y1 || x0>x1 )
+		{
+			GPU_SWAP(x0, x1, temp);
+			GPU_SWAP(y0, y1, temp);
+		}
+	}
+
+	ya = y2 - y0;
+	yb = y2 - y1;
+	dx =(x2 - x1) * ya - (x2 - x0) * yb;
+
+	for (s32 loop0 = 2; loop0; --loop0)
+	{
+		if (loop0 == 2)
+		{
+			ya = y0;
+			yb = y1;
+			x3 = i2x(x0);
+			x4 = y0!=y1 ? x3 : i2x(x1);
+			if (dx < 0)
+			{
+				dx3 = xLoDivx((x2 - x0), (y2 - y0));
+				dx4 = xLoDivx((x1 - x0), (y1 - y0));
+			}
+			else
+			{
+				dx3 = xLoDivx((x1 - x0), (y1 - y0));
+				dx4 = xLoDivx((x2 - x0), (y2 - y0));
+			}
+		}
+		else
+		{
+			ya = y1;
+			yb = y2;
+			if (dx < 0)
+			{
+				x4  = i2x(x1);
+				x3  = i2x(x0) + (dx3 * (y1 - y0));
+				dx4 = xLoDivx((x2 - x1), (y2 - y1));
+			}
+			else
+			{
+				x3  = i2x(x1);
+				x4  = i2x(x0) + (dx4 * (y1 - y0));
+				dx3 = xLoDivx((x2 - x1), (y2 - y1));
+			}
+		}
+
+		temp = ymin - ya;
+		if (temp > 0)
+		{
+			ya  = ymin;
+			x3 += dx3*temp;
+			x4 += dx4*temp;
+		}
+		if (yb > ymax) yb = ymax;
+		if (ya>=yb) continue;
+
+		x3+= fixed_HALF;
+		x4+= fixed_HALF;
+
+		u16* PixelBase  = &((u16*)GPU_FrameBuffer)[FRAME_OFFSET(0, ya)];
+		
+		for(;ya<yb;++ya, PixelBase += FRAME_WIDTH, x3+=dx3, x4+=dx4)
+		{
+			if (ya&li) continue;
+			if ((ya&pi)==pif) continue;
+			xa = x2i(x3);
+			xb = x2i(x4);
+			if( (xa>xmax) || (xb<xmin) ) continue;
+			if(xa < xmin) xa = xmin;
+			if(xb > xmax) xb = xmax;
+			xb-=xa;
+			if(xb>0) gpuPolySpanDriver(PixelBase + xa,xb);
+		}
+	}
+}
+
+/*----------------------------------------------------------------------
+FT3
+----------------------------------------------------------------------*/
+
+void gpuDrawFT3(const PP gpuPolySpanDriver)
+{
+	const int li=linesInterlace;
+	const int pi=(progressInterlace?(linesInterlace+1):0);
+	const int pif=(progressInterlace?(progressInterlace_flag?(linesInterlace+1):0):1);
+	s32 temp;
+	s32 xa, xb, xmin, xmax;
+	s32 ya, yb, ymin, ymax;
+	s32 x0, x1, x2, x3, dx3=0, x4, dx4=0, dx;
+	s32 y0, y1, y2;
+	s32 u0, u1, u2, u3, du3=0;
+	s32 v0, v1, v2, v3, dv3=0;
+
+	x0 = GPU_EXPANDSIGN(PacketBuffer.S2[2] );
+	y0 = GPU_EXPANDSIGN(PacketBuffer.S2[3] );
+	x1 = GPU_EXPANDSIGN(PacketBuffer.S2[6] );
+	y1 = GPU_EXPANDSIGN(PacketBuffer.S2[7] );
+	x2 = GPU_EXPANDSIGN(PacketBuffer.S2[10]);
+	y2 = GPU_EXPANDSIGN(PacketBuffer.S2[11]);
+
+	GPU_TESTRANGE3();
+	
+	x0 += DrawingOffset[0];   x1 += DrawingOffset[0];   x2 += DrawingOffset[0];
+	y0 += DrawingOffset[1];   y1 += DrawingOffset[1];   y2 += DrawingOffset[1];
+
+	xmin = DrawingArea[0];  xmax = DrawingArea[2];
+	ymin = DrawingArea[1];  ymax = DrawingArea[3];
+
+	{
+		int rx0 = Max2(xmin,Min3(x0,x1,x2));
+		int ry0 = Max2(ymin,Min3(y0,y1,y2));
+		int rx1 = Min2(xmax,Max3(x0,x1,x2));
+		int ry1 = Min2(ymax,Max3(y0,y1,y2));
+		if( rx0>=rx1 || ry0>=ry1) return;
+	}
+	
+	u0 = PacketBuffer.U1[8];  v0 = PacketBuffer.U1[9];
+	u1 = PacketBuffer.U1[16]; v1 = PacketBuffer.U1[17];
+	u2 = PacketBuffer.U1[24]; v2 = PacketBuffer.U1[25];
+
+	r4 = s32(PacketBuffer.U1[0]);
+	g4 = s32(PacketBuffer.U1[1]);
+	b4 = s32(PacketBuffer.U1[2]);
+	dr4 = dg4 = db4 = 0;
+
+	if (y0 >= y1)
+	{
+		if( y0!=y1 || x0>x1 )
+		{
+			GPU_SWAP(x0, x1, temp);
+			GPU_SWAP(y0, y1, temp);
+			GPU_SWAP(u0, u1, temp);
+			GPU_SWAP(v0, v1, temp);
+		}
+	}
+	if (y1 >= y2)
+	{
+		if( y1!=y2 || x1>x2 )
+		{
+			GPU_SWAP(x1, x2, temp);
+			GPU_SWAP(y1, y2, temp);
+			GPU_SWAP(u1, u2, temp);
+			GPU_SWAP(v1, v2, temp);
+		}
+	}
+	if (y0 >= y1)
+	{
+		if( y0!=y1 || x0>x1 )
+		{
+			GPU_SWAP(x0, x1, temp);
+			GPU_SWAP(y0, y1, temp);
+			GPU_SWAP(u0, u1, temp);
+			GPU_SWAP(v0, v1, temp);
+		}
+	}
+
+	ya  = y2 - y0;
+	yb  = y2 - y1;
+	dx  = (x2 - x1) * ya - (x2 - x0) * yb;
+	du4 = (u2 - u1) * ya - (u2 - u0) * yb;
+	dv4 = (v2 - v1) * ya - (v2 - v0) * yb;
+
+	s32 iF,iS;
+	xInv( dx, iF, iS);
+	du4 = xInvMulx( du4, iF, iS);
+	dv4 = xInvMulx( dv4, iF, iS);
+	tInc = ((u32)(du4<<7)&0x7fff0000) | ((u32)(dv4>>9)&0x00007fff);
+	tMsk = (TextureWindow[2]<<23) | (TextureWindow[3]<<7) | 0x00ff00ff;
+
+	for (s32 loop0 = 2; loop0; --loop0)
+	{
+		if (loop0 == 2)
+		{
+			ya = y0;
+			yb = y1;
+			u3 = i2x(u0);
+			v3 = i2x(v0);
+			x3 = i2x(x0);
+			x4 = y0!=y1 ? x3 : i2x(x1);
+			if (dx < 0)
+			{
+				xInv( (y2 - y0), iF, iS);
+				dx3 = xInvMulx( (x2 - x0), iF, iS);
+				du3 = xInvMulx( (u2 - u0), iF, iS);
+				dv3 = xInvMulx( (v2 - v0), iF, iS);
+				dx4 = xLoDivx ( (x1 - x0), (y1 - y0));
+			}
+			else
+			{
+				xInv( (y1 - y0), iF, iS);
+				dx3 = xInvMulx( (x1 - x0), iF, iS);
+				du3 = xInvMulx( (u1 - u0), iF, iS);
+				dv3 = xInvMulx( (v1 - v0), iF, iS);
+				dx4 = xLoDivx ( (x2 - x0), (y2 - y0));
+			}
+		}
+		else
+		{
+			ya = y1;
+			yb = y2;
+			if (dx < 0)
+			{
+				temp = y1 - y0;
+				u3 = i2x(u0) + (du3 * temp);
+				v3 = i2x(v0) + (dv3 * temp);
+				x3 = i2x(x0) + (dx3 * temp);
+				x4 = i2x(x1);
+				dx4 = xLoDivx((x2 - x1), (y2 - y1));
+			}
+			else
+			{
+				u3 = i2x(u1);
+				v3 = i2x(v1);
+				x3 = i2x(x1);
+				x4 = i2x(x0) + (dx4 * (y1 - y0));
+				xInv( (y2 - y1), iF, iS);
+				dx3 = xInvMulx( (x2 - x1), iF, iS);
+				du3 = xInvMulx( (u2 - u1), iF, iS);
+				dv3 = xInvMulx( (v2 - v1), iF, iS);
+			}
+		}
+
+		temp = ymin - ya;
+		if (temp > 0)
+		{
+			ya  = ymin;
+			x3 += dx3*temp;
+			x4 += dx4*temp;
+			u3 += du3*temp;
+			v3 += dv3*temp;
+		}
+		if (yb > ymax) yb = ymax;
+		if (ya>=yb) continue;
+
+		x3+= fixed_HALF;
+		x4+= fixed_HALF;
+		u3+= fixed_HALF;
+		v4+= fixed_HALF;
+
+		u16* PixelBase  = &((u16*)GPU_FrameBuffer)[FRAME_OFFSET(0, ya)];
+
+		for(;ya<yb;++ya, PixelBase += FRAME_WIDTH, x3+=dx3, x4+=dx4, u3+=du3, v3+=dv3)
+		{
+			if (ya&li) continue;
+			if ((ya&pi)==pif) continue;
+			xa = x2i(x3);
+			xb = x2i(x4);
+			if( (xa>xmax) || (xb<xmin) ) continue;
+
+			temp = xmin - xa;
+			if(temp > 0)
+			{
+				xa  = xmin;
+				u4 = u3 + du4*temp;
+				v4 = v3 + dv4*temp;
+			}
+			else
+			{
+				u4 = u3;
+				v4 = v3;
+			}
+			if(xb > xmax) xb = xmax;
+			xb-=xa;
+			if(xb>0) gpuPolySpanDriver(PixelBase + xa,xb);
+		}
+	}
+}
+
+/*----------------------------------------------------------------------
+G3
+----------------------------------------------------------------------*/
+
+void gpuDrawG3(const PP gpuPolySpanDriver)
+{
+	const int li=linesInterlace;
+	const int pi=(progressInterlace?(linesInterlace+1):0);
+	const int pif=(progressInterlace?(progressInterlace_flag?(linesInterlace+1):0):1);
+	s32 temp;
+	s32 xa, xb, xmin, xmax;
+	s32 ya, yb, ymin, ymax;
+	s32 x0, x1, x2, x3, dx3=0, x4, dx4=0, dx;
+	s32 y0, y1, y2;
+	s32 r0, r1, r2, r3, dr3=0;
+	s32 g0, g1, g2, g3, dg3=0;
+	s32 b0, b1, b2, b3, db3=0;
+
+	x0 = GPU_EXPANDSIGN(PacketBuffer.S2[2] );
+	y0 = GPU_EXPANDSIGN(PacketBuffer.S2[3] );
+	x1 = GPU_EXPANDSIGN(PacketBuffer.S2[6] );
+	y1 = GPU_EXPANDSIGN(PacketBuffer.S2[7] );
+	x2 = GPU_EXPANDSIGN(PacketBuffer.S2[10]);
+	y2 = GPU_EXPANDSIGN(PacketBuffer.S2[11]);
+
+	GPU_TESTRANGE3();
+	
+	x0 += DrawingOffset[0];   x1 += DrawingOffset[0];   x2 += DrawingOffset[0];
+	y0 += DrawingOffset[1];   y1 += DrawingOffset[1];   y2 += DrawingOffset[1];
+
+	xmin = DrawingArea[0];  xmax = DrawingArea[2];
+	ymin = DrawingArea[1];  ymax = DrawingArea[3];
+
+	{
+		int rx0 = Max2(xmin,Min3(x0,x1,x2));
+		int ry0 = Max2(ymin,Min3(y0,y1,y2));
+		int rx1 = Min2(xmax,Max3(x0,x1,x2));
+		int ry1 = Min2(ymax,Max3(y0,y1,y2));
+		if( rx0>=rx1 || ry0>=ry1) return;
+	}
+	
+	r0 = PacketBuffer.U1[0];	g0 = PacketBuffer.U1[1];	b0 = PacketBuffer.U1[2];
+	r1 = PacketBuffer.U1[8];	g1 = PacketBuffer.U1[9];	b1 = PacketBuffer.U1[10];
+	r2 = PacketBuffer.U1[16];	g2 = PacketBuffer.U1[17];	b2 = PacketBuffer.U1[18];
+
+	if (y0 >= y1)
+	{
+		if( y0!=y1 || x0>x1 )
+		{
+			GPU_SWAP(x0, x1, temp);		GPU_SWAP(y0, y1, temp);
+			GPU_SWAP(r0, r1, temp);		GPU_SWAP(g0, g1, temp);		GPU_SWAP(b0, b1, temp);
+		}
+	}
+	if (y1 >= y2)
+	{
+		if( y1!=y2 || x1>x2 )
+		{
+			GPU_SWAP(x1, x2, temp);		GPU_SWAP(y1, y2, temp);
+			GPU_SWAP(r1, r2, temp);		GPU_SWAP(g1, g2, temp);   GPU_SWAP(b1, b2, temp);
+		}
+	}
+	if (y0 >= y1)
+	{
+		if( y0!=y1 || x0>x1 )
+		{
+			GPU_SWAP(x0, x1, temp);		GPU_SWAP(y0, y1, temp);
+			GPU_SWAP(r0, r1, temp);   GPU_SWAP(g0, g1, temp);		GPU_SWAP(b0, b1, temp);
+		}
+	}
+
+	ya  = y2 - y0;
+	yb  = y2 - y1;
+	dx  = (x2 - x1) * ya - (x2 - x0) * yb;
+	dr4 = (r2 - r1) * ya - (r2 - r0) * yb;
+	dg4 = (g2 - g1) * ya - (g2 - g0) * yb;
+	db4 = (b2 - b1) * ya - (b2 - b0) * yb;
+
+	s32 iF,iS;
+	xInv(            dx, iF, iS);
+	dr4 = xInvMulx( dr4, iF, iS);
+	dg4 = xInvMulx( dg4, iF, iS);
+	db4 = xInvMulx( db4, iF, iS);
+	u32 dr = (u32)(dr4<< 8)&(0xffffffff<<21);   if(dr4<0) dr+= 1<<21;
+	u32 dg = (u32)(dg4>> 3)&(0xffffffff<<10);   if(dg4<0) dg+= 1<<10;
+	u32 db = (u32)(db4>>14)&(0xffffffff    );   if(db4<0) db+= 1<< 0;
+	lInc = db + dg + dr;
+
+	for (s32 loop0 = 2; loop0; --loop0)
+	{
+		if (loop0 == 2)
+		{
+			ya = y0;
+			yb = y1;
+			r3 = i2x(r0);
+			g3 = i2x(g0);
+			b3 = i2x(b0);
+			x3 = i2x(x0);
+			x4 = y0!=y1 ? x3 : i2x(x1);
+			if (dx < 0)
+			{
+				xInv(           (y2 - y0), iF, iS);
+				dx3 = xInvMulx( (x2 - x0), iF, iS);
+				dr3 = xInvMulx( (r2 - r0), iF, iS);
+				dg3 = xInvMulx( (g2 - g0), iF, iS);
+				db3 = xInvMulx( (b2 - b0), iF, iS);
+				dx4 = xLoDivx ( (x1 - x0), (y1 - y0));
+			}
+			else
+			{
+				xInv(           (y1 - y0), iF, iS);
+				dx3 = xInvMulx( (x1 - x0), iF, iS);
+				dr3 = xInvMulx( (r1 - r0), iF, iS);
+				dg3 = xInvMulx( (g1 - g0), iF, iS);
+				db3 = xInvMulx( (b1 - b0), iF, iS);
+				dx4 = xLoDivx ( (x2 - x0), (y2 - y0));
+			}
+		}
+		else
+		{
+			ya = y1;
+			yb = y2;
+			if (dx < 0)
+			{
+				temp = y1 - y0;
+				r3  = i2x(r0) + (dr3 * temp);
+				g3  = i2x(g0) + (dg3 * temp);
+				b3  = i2x(b0) + (db3 * temp);
+				x3  = i2x(x0) + (dx3 * temp);
+				x4  = i2x(x1);
+				dx4 = xLoDivx((x2 - x1), (y2 - y1));
+			}
+			else
+			{
+				r3 = i2x(r1);
+				g3 = i2x(g1);
+				b3 = i2x(b1);
+				x3 = i2x(x1);
+				x4 = i2x(x0) + (dx4 * (y1 - y0));
+
+				xInv(           (y2 - y1), iF, iS);
+				dx3 = xInvMulx( (x2 - x1), iF, iS);
+				dr3 = xInvMulx( (r2 - r1), iF, iS);
+				dg3 = xInvMulx( (g2 - g1), iF, iS);
+				db3 = xInvMulx( (b2 - b1), iF, iS);
+			}
+		}
+
+		temp = ymin - ya;
+		if (temp > 0)
+		{
+			ya  = ymin;
+			x3 += dx3*temp;   x4 += dx4*temp;
+			r3 += dr3*temp;   g3 += dg3*temp;   b3 += db3*temp;
+		}
+		if (yb > ymax) yb = ymax;
+		if (ya>=yb) continue;
+
+		x3+= fixed_HALF;  x4+= fixed_HALF;
+		r3+= fixed_HALF;  g3+= fixed_HALF;  b3+= fixed_HALF;
+
+		u16* PixelBase  = &((u16*)GPU_FrameBuffer)[FRAME_OFFSET(0, ya)];
+		
+		for(;ya<yb;++ya, PixelBase += FRAME_WIDTH, x3+=dx3, x4+=dx4, r3+=dr3, g3+=dg3, b3+=db3)
+		{
+			if (ya&li) continue;
+			if ((ya&pi)==pif) continue;
+			xa = x2i(x3);
+			xb = x2i(x4);
+			if( (xa>xmax) || (xb<xmin) ) continue;
+
+			temp = xmin - xa;
+			if(temp > 0)
+			{
+				xa  = xmin;
+				r4 = r3 + dr4*temp;   g4 = g3 + dg4*temp;   b4 = b3 + db4*temp;
+			}
+			else
+			{
+				r4 = r3;  g4 = g3;  b4 = b3;
+			}
+			if(xb > xmax) xb = xmax;
+			xb-=xa;
+			if(xb>0) gpuPolySpanDriver(PixelBase + xa,xb);
+		}
+	}
+}
+
+/*----------------------------------------------------------------------
+GT3
+----------------------------------------------------------------------*/
+
+void gpuDrawGT3(const PP gpuPolySpanDriver)
+{
+	const int li=linesInterlace;
+	const int pi=(progressInterlace?(linesInterlace+1):0);
+	const int pif=(progressInterlace?(progressInterlace_flag?(linesInterlace+1):0):1);
+	s32 temp;
+	s32 xa, xb, xmin, xmax;
+	s32 ya, yb, ymin, ymax;
+	s32 x0, x1, x2, x3, dx3=0, x4, dx4=0, dx;
+	s32 y0, y1, y2;
+	s32 u0, u1, u2, u3, du3=0;
+	s32 v0, v1, v2, v3, dv3=0;
+	s32 r0, r1, r2, r3, dr3=0;
+	s32 g0, g1, g2, g3, dg3=0;
+	s32 b0, b1, b2, b3, db3=0;
+
+	x0 = GPU_EXPANDSIGN(PacketBuffer.S2[2] );
+	y0 = GPU_EXPANDSIGN(PacketBuffer.S2[3] );
+	x1 = GPU_EXPANDSIGN(PacketBuffer.S2[8] );
+	y1 = GPU_EXPANDSIGN(PacketBuffer.S2[9] );
+	x2 = GPU_EXPANDSIGN(PacketBuffer.S2[14]);
+	y2 = GPU_EXPANDSIGN(PacketBuffer.S2[15]);
+
+	GPU_TESTRANGE3();
+	
+	x0 += DrawingOffset[0];   x1 += DrawingOffset[0];   x2 += DrawingOffset[0];
+	y0 += DrawingOffset[1];   y1 += DrawingOffset[1];   y2 += DrawingOffset[1];
+
+	xmin = DrawingArea[0];	xmax = DrawingArea[2];
+	ymin = DrawingArea[1];	ymax = DrawingArea[3];
+
+	{
+		int rx0 = Max2(xmin,Min3(x0,x1,x2));
+		int ry0 = Max2(ymin,Min3(y0,y1,y2));
+		int rx1 = Min2(xmax,Max3(x0,x1,x2));
+		int ry1 = Min2(ymax,Max3(y0,y1,y2));
+		if( rx0>=rx1 || ry0>=ry1) return;
+	}
+
+	r0 = PacketBuffer.U1[0];	g0 = PacketBuffer.U1[1];	b0 = PacketBuffer.U1[2];
+	u0 = PacketBuffer.U1[8];	v0 = PacketBuffer.U1[9];
+	r1 = PacketBuffer.U1[12];	g1 = PacketBuffer.U1[13];	b1 = PacketBuffer.U1[14];
+	u1 = PacketBuffer.U1[20];	v1 = PacketBuffer.U1[21];
+	r2 = PacketBuffer.U1[24];	g2 = PacketBuffer.U1[25];	b2 = PacketBuffer.U1[26];
+	u2 = PacketBuffer.U1[32];	v2 = PacketBuffer.U1[33];
+
+	if (y0 >= y1)
+	{
+		if( y0!=y1 || x0>x1 )
+		{
+			GPU_SWAP(x0, x1, temp);		GPU_SWAP(y0, y1, temp);
+			GPU_SWAP(u0, u1, temp);		GPU_SWAP(v0, v1, temp);
+			GPU_SWAP(r0, r1, temp);		GPU_SWAP(g0, g1, temp);   GPU_SWAP(b0, b1, temp);
+		}
+	}
+	if (y1 >= y2)
+	{
+		if( y1!=y2 || x1>x2 )
+		{
+			GPU_SWAP(x1, x2, temp);		GPU_SWAP(y1, y2, temp);
+			GPU_SWAP(u1, u2, temp);		GPU_SWAP(v1, v2, temp);
+			GPU_SWAP(r1, r2, temp);   GPU_SWAP(g1, g2, temp);		GPU_SWAP(b1, b2, temp);
+		}
+	}
+	if (y0 >= y1)
+	{
+		if( y0!=y1 || x0>x1 )
+		{
+			GPU_SWAP(x0, x1, temp);		GPU_SWAP(y0, y1, temp);
+			GPU_SWAP(u0, u1, temp);		GPU_SWAP(v0, v1, temp);
+			GPU_SWAP(r0, r1, temp);		GPU_SWAP(g0, g1, temp);		GPU_SWAP(b0, b1, temp);
+		}
+	}
+
+	ya  = y2 - y0;
+	yb  = y2 - y1;
+	dx  = (x2 - x1) * ya - (x2 - x0) * yb;
+	du4 = (u2 - u1) * ya - (u2 - u0) * yb;
+	dv4 = (v2 - v1) * ya - (v2 - v0) * yb;
+	dr4 = (r2 - r1) * ya - (r2 - r0) * yb;
+	dg4 = (g2 - g1) * ya - (g2 - g0) * yb;
+	db4 = (b2 - b1) * ya - (b2 - b0) * yb;
+
+	s32 iF,iS;
+
+	xInv(            dx, iF, iS);
+	du4 = xInvMulx( du4, iF, iS);
+	dv4 = xInvMulx( dv4, iF, iS);
+	dr4 = xInvMulx( dr4, iF, iS);
+	dg4 = xInvMulx( dg4, iF, iS);
+	db4 = xInvMulx( db4, iF, iS);
+	u32 dr = (u32)(dr4<< 8)&(0xffffffff<<21);   if(dr4<0) dr+= 1<<21;
+	u32 dg = (u32)(dg4>> 3)&(0xffffffff<<10);   if(dg4<0) dg+= 1<<10;
+	u32 db = (u32)(db4>>14)&(0xffffffff    );   if(db4<0) db+= 1<< 0;
+	lInc = db + dg + dr;
+	tInc = ((u32)(du4<<7)&0x7fff0000) | ((u32)(dv4>>9)&0x00007fff);
+	tMsk = (TextureWindow[2]<<23) | (TextureWindow[3]<<7) | 0x00ff00ff;
+
+	for (s32 loop0 = 2; loop0; --loop0)
+	{
+		if (loop0 == 2)
+		{
+			ya = y0;
+			yb = y1;
+			u3 = i2x(u0);
+			v3 = i2x(v0);
+			r3 = i2x(r0);
+			g3 = i2x(g0);
+			b3 = i2x(b0);
+			x3 = i2x(x0);
+			x4 = y0!=y1 ? x3 : i2x(x1);
+			if (dx < 0)
+			{
+				xInv(           (y2 - y0), iF, iS);
+				dx3 = xInvMulx( (x2 - x0), iF, iS);
+				du3 = xInvMulx( (u2 - u0), iF, iS);
+				dv3 = xInvMulx( (v2 - v0), iF, iS);
+				dr3 = xInvMulx( (r2 - r0), iF, iS);
+				dg3 = xInvMulx( (g2 - g0), iF, iS);
+				db3 = xInvMulx( (b2 - b0), iF, iS);
+				dx4 = xLoDivx ( (x1 - x0), (y1 - y0));
+			}
+			else
+			{
+				xInv(           (y1 - y0), iF, iS);
+				dx3 = xInvMulx( (x1 - x0), iF, iS);
+				du3 = xInvMulx( (u1 - u0), iF, iS);
+				dv3 = xInvMulx( (v1 - v0), iF, iS);
+				dr3 = xInvMulx( (r1 - r0), iF, iS);
+				dg3 = xInvMulx( (g1 - g0), iF, iS);
+				db3 = xInvMulx( (b1 - b0), iF, iS);
+				dx4 = xLoDivx ( (x2 - x0), (y2 - y0));
+			}
+		}
+		else
+		{
+			ya = y1;
+			yb = y2;
+			if (dx < 0)
+			{
+				temp = y1 - y0;
+				u3  = i2x(u0) + (du3 * temp);
+				v3  = i2x(v0) + (dv3 * temp);
+				r3  = i2x(r0) + (dr3 * temp);
+				g3  = i2x(g0) + (dg3 * temp);
+				b3  = i2x(b0) + (db3 * temp);
+				x3  = i2x(x0) + (dx3 * temp);
+				x4  = i2x(x1);
+				dx4 = xLoDivx((x2 - x1), (y2 - y1));
+			}
+			else
+			{
+				u3 = i2x(u1);
+				v3 = i2x(v1);
+				r3 = i2x(r1);
+				g3 = i2x(g1);
+				b3 = i2x(b1);
+				x3 = i2x(x1);
+				x4 = i2x(x0) + (dx4 * (y1 - y0));
+
+				xInv(           (y2 - y1), iF, iS);
+				dx3 = xInvMulx( (x2 - x1), iF, iS);
+				du3 = xInvMulx( (u2 - u1), iF, iS);
+				dv3 = xInvMulx( (v2 - v1), iF, iS);
+				dr3 = xInvMulx( (r2 - r1), iF, iS);
+				dg3 = xInvMulx( (g2 - g1), iF, iS);
+				db3 = xInvMulx( (b2 - b1), iF, iS);
+			}
+		}
+
+		temp = ymin - ya;
+		if (temp > 0)
+		{
+			ya  = ymin;
+			x3 += dx3*temp;   x4 += dx4*temp;
+			u3 += du3*temp;   v3 += dv3*temp;
+			r3 += dr3*temp;   g3 += dg3*temp;   b3 += db3*temp;
+		}
+		if (yb > ymax) yb = ymax;
+		if (ya>=yb) continue;
+
+		x3+= fixed_HALF;  x4+= fixed_HALF;
+		u3+= fixed_HALF;  v4+= fixed_HALF;
+		r3+= fixed_HALF;  g3+= fixed_HALF;  b3+= fixed_HALF;
+		u16* PixelBase  = &((u16*)GPU_FrameBuffer)[FRAME_OFFSET(0, ya)];
+		
+		for(;ya<yb;++ya, PixelBase += FRAME_WIDTH, x3+=dx3, x4+=dx4, u3+=du3, v3+=dv3, r3+=dr3, g3+=dg3,	b3+=db3)
+		{
+			if (ya&li) continue;
+			if ((ya&pi)==pif) continue;
+			xa = x2i(x3);
+			xb = x2i(x4);
+			if( (xa>xmax) || (xb<xmin))	continue;
+
+			temp = xmin - xa;
+			if(temp > 0)
+			{
+				xa  = xmin;
+				u4 = u3 + du4*temp;   v4 = v3 + dv4*temp;
+				r4 = r3 + dr4*temp;   g4 = g3 + dg4*temp;   b4 = b3 + db4*temp;
+			}
+			else
+			{
+				u4 = u3;  v4 = v3;
+				r4 = r3;  g4 = g3;  b4 = b3;
+			}
+			if(xb > xmax) xb = xmax;
+			xb-=xa;
+			if(xb>0) gpuPolySpanDriver(PixelBase + xa,xb);
+		}
+	}
+}
+
+
+//////////////////////////////////////////////////////////////////////////
+//senquack - Original Unai poly routines left here for reference:
+// ( from gpu_inner.h ) NOTE: this uses 16.16, not 22.10 fixed point
+//////////////////////////////////////////////////////////////////////////
+template<const int CF>
+INLINE void  gpuPolySpanFn(u16 *pDst, u32 count)
+{
+	if (!TM)
+	{	
+		// NO TEXTURE
+		if (!G)
+		{
+			// NO GOURAUD
+			u16 data;
+			if (L) { u32 lCol=((u32)(b4<< 2)&(0x03ff)) | ((u32)(g4<<13)&(0x07ff<<10)) | ((u32)(r4<<24)&(0x07ff<<21)); gpuLightingRGB(data,lCol); }
+			else data=PixelData;
+			if ((!M)&&(!B))
+			{
+				if (MB) { data = data | 0x8000; }
+				do { *pDst++ = data; } while (--count);
+			}
+			else if ((M)&&(!B))
+			{
+				if (MB) { data = data | 0x8000; }
+				do { if (!(*pDst&0x8000)) { *pDst = data; } pDst++; } while (--count);
+			}
+			else
+			{
+				u16 uSrc;
+				u16 uDst;
+				u32 uMsk; if (BM==0) uMsk=0x7BDE;
+				u32 bMsk; if (BI) bMsk=blit_mask;
+				do
+				{
+					// blit-mask
+					if (BI) { if((bMsk>>((((u32)pDst)>>1)&7))&1) goto endtile; }
+					//  masking
+					uDst = *pDst;
+					if(M) { if (uDst&0x8000) goto endtile;  }
+					uSrc = data;
+					//  blend
+					if (BM==0) gpuBlending00(uSrc, uDst);
+					if (BM==1) gpuBlending01(uSrc, uDst);
+					if (BM==2) gpuBlending02(uSrc, uDst);
+					if (BM==3) gpuBlending03(uSrc, uDst);
+					if (MB) { *pDst = uSrc | 0x8000; }
+					else    { *pDst = uSrc; }
+					endtile: pDst++;
+				}
+				while (--count);
+			}
+		}
+		else
+		{
+			// GOURAUD
+			u16 uDst;
+			u16 uSrc;
+			u32 linc=lInc;
+			u32 lCol=((u32)(b4>>14)&(0x03ff)) | ((u32)(g4>>3)&(0x07ff<<10)) | ((u32)(r4<<8)&(0x07ff<<21));
+			u32 uMsk; if ((B)&&(BM==0)) uMsk=0x7BDE;
+			u32 bMsk; if (BI) bMsk=blit_mask;
+			do
+			{
+				// blit-mask
+				if (BI) { if((bMsk>>((((u32)pDst)>>1)&7))&1) goto endgou; }
+				//  masking
+				if(M) { uDst = *pDst;  if (uDst&0x8000) goto endgou;  }
+				//  blend
+				if(B)
+				{
+					//  light
+					gpuLightingRGB(uSrc,lCol);
+					if(!M)    { uDst = *pDst; }
+					if (BM==0) gpuBlending00(uSrc, uDst);
+					if (BM==1) gpuBlending01(uSrc, uDst);
+					if (BM==2) gpuBlending02(uSrc, uDst);
+					if (BM==3) gpuBlending03(uSrc, uDst);
+				}
+				else
+				{
+					//  light
+					gpuLightingRGB(uSrc,lCol);
+				}
+				if (MB) { *pDst = uSrc | 0x8000; }
+				else    { *pDst = uSrc; }
+				endgou: pDst++; lCol=(lCol+linc);
+			}
+			while (--count);
+		}
+	}
+	else
+	{
+		// TEXTURE
+		u16 uDst;
+		u16 uSrc;
+		u32 linc; if (L&&G) linc=lInc;
+		u32 tinc=tInc;
+		u32 tmsk=tMsk;
+		u32 tCor = ((u32)( u4<<7)&0x7fff0000) | ((u32)( v4>>9)&0x00007fff); tCor&= tmsk;
+		const u16* _TBA=TBA;
+		const u16* _CBA; if (TM!=3) _CBA=CBA;
+		u32 lCol;
+		if(L && !G) { lCol = ((u32)(b4<< 2)&(0x03ff)) | ((u32)(g4<<13)&(0x07ff<<10)) | ((u32)(r4<<24)&(0x07ff<<21)); }
+		else if(L && G) { lCol = ((u32)(b4>>14)&(0x03ff)) | ((u32)(g4>>3)&(0x07ff<<10)) | ((u32)(r4<<8)&(0x07ff<<21)); 	}
+		u32 uMsk; if ((B)&&(BM==0)) uMsk=0x7BDE;
+		u32 bMsk; if (BI) bMsk=blit_mask;
+		do
+		{
+			// blit-mask
+			if (BI) { if((bMsk>>((((u32)pDst)>>1)&7))&1) goto endpoly; }
+			//  masking
+			if(M) { uDst = *pDst;  if (uDst&0x8000) goto endpoly;  }
+			//  texture
+			if (TM==1) { u32 tu=(tCor>>23); u32 tv=(tCor<<4)&(0xff<<11); u8 rgb=((u8*)_TBA)[tv+(tu>>1)]; uSrc=_CBA[(rgb>>((tu&1)<<2))&0xf]; if(!uSrc) goto endpoly; }
+			if (TM==2) { uSrc = _CBA[(((u8*)_TBA)[(tCor>>23)+((tCor<<4)&(0xff<<11))])]; if(!uSrc)  goto endpoly; }
+			if (TM==3) { uSrc = _TBA[(tCor>>23)+((tCor<<3)&(0xff<<10))]; if(!uSrc)  goto endpoly; }
+			//  blend
+			if(B)
+			{
+				if (uSrc&0x8000)
+				{
+					//  light
+					if(L) gpuLightingTXT(uSrc, lCol);
+					if(!M)    { uDst = *pDst; }
+					if (BM==0) gpuBlending00(uSrc, uDst);
+					if (BM==1) gpuBlending01(uSrc, uDst);
+					if (BM==2) gpuBlending02(uSrc, uDst);
+					if (BM==3) gpuBlending03(uSrc, uDst);
+				}
+				else
+				{
+					// light
+					if(L) gpuLightingTXT(uSrc, lCol);
+				}
+			}
+			else
+			{
+				//  light
+				if(L)  { gpuLightingTXT(uSrc, lCol); } else if(!MB) { uSrc&= 0x7fff; }
+			}
+			if (MB) { *pDst = uSrc | 0x8000; }
+			else    { *pDst = uSrc; }
+			endpoly: pDst++;
+			tCor=(tCor+tinc)&tmsk;
+			if (L&&G) lCol=(lCol+linc);
+		}
+		while (--count);
+	}
+}
diff --git a/plugins/gpu_unai/debug.h b/plugins/gpu_unai/debug.h
deleted file mode 100644
index e69de29b..00000000
diff --git a/plugins/gpu_unai/gpu.cpp b/plugins/gpu_unai/gpu.cpp
index 1552bed9..cac64a31 100644
--- a/plugins/gpu_unai/gpu.cpp
+++ b/plugins/gpu_unai/gpu.cpp
@@ -1,6 +1,7 @@
 /***************************************************************************
 *   Copyright (C) 2010 PCSX4ALL Team                                      *
 *   Copyright (C) 2010 Unai                                               *
+*   Copyright (C) 2016 Senquack (dansilsby <AT> gmail <DOT> com)          *
 *                                                                         *
 *   This program is free software; you can redistribute it and/or modify  *
 *   it under the terms of the GNU General Public License as published by  *
@@ -18,102 +19,44 @@
 *   51 Franklin Street, Fifth Floor, Boston, MA 02111-1307 USA.           *
 ***************************************************************************/
 
+#include <stddef.h>
+#include "plugins.h"
+#include "psxcommon.h"
 #include "port.h"
-#include "gpu.h"
-#include "profiler.h"
-#include "debug.h"
+#include "gpu_unai.h"
 
-int skipCount = 2; /* frame skip (0,1,2,3...) */
-int skCount = 0; /* internal frame skip */
-int linesInterlace = 0;  /* internal lines interlace */
-int linesInterlace_user = 0; /* Lines interlace */
+#define GPU_INLINE static inline __attribute__((always_inline))
 
-bool isSkip = false; /* skip frame (info coming from GPU) */
-bool wasSkip = false;
-bool skipFrame = false; /* skip frame (according to frame skip) */
-bool alt_fps = false; /* Alternative FPS algorithm */
-bool show_fps = false; /* Show FPS statistics */
+#define VIDEO_WIDTH 320
 
-bool isPAL = false; /* PAL video timing */
-bool progressInterlace_flag = false; /* Progressive interlace flag */
-bool progressInterlace = false; /* Progressive interlace option*/
-bool frameLimit = false; /* frames to wait */
-
-bool light = true; /* lighting */
-bool blend = true; /* blending */
-bool FrameToRead = false; /* load image in progress */
-bool FrameToWrite = false; /* store image in progress */
-bool fb_dirty = false;
-
-bool enableAbbeyHack = false; /* Abe's Odyssey hack */
-
-u8 BLEND_MODE;
-u8 TEXT_MODE;
-u8 Masking;
-
-u16 PixelMSB;
-u16 PixelData;
-
-///////////////////////////////////////////////////////////////////////////////
-//  GPU Global data
-///////////////////////////////////////////////////////////////////////////////
-
-///////////////////////////////////////////////////////////////////////////////
-//  Dma Transfers info
-s32		px,py;
-s32		x_end,y_end;
-u16*  pvram;
-
-u32 GP0;
-s32 PacketCount;
-s32 PacketIndex;
-
-///////////////////////////////////////////////////////////////////////////////
-//  Display status
-u32 DisplayArea   [6];
-
-///////////////////////////////////////////////////////////////////////////////
-//  Rasterizer status
-u32 TextureWindow [4];
-u32 DrawingArea   [4];
-u32 DrawingOffset [2];
+#ifdef TIME_IN_MSEC
+#define TPS 1000
+#else
+#define TPS 1000000
+#endif
 
-///////////////////////////////////////////////////////////////////////////////
-//  Rasterizer status
+#define IS_PAL (gpu_unai.GPU_GP1&(0x08<<17))
 
-u16* TBA;
-u16* CBA;
+//senquack - Original 512KB of guard space seems not to be enough, as Xenogears
+// accesses outside this range and crashes in town intro fight sequence.
+// Increased to 2MB total (double PSX VRAM) and Xenogears no longer
+// crashes, but some textures are still messed up. Also note that alignment min
+// is 16 bytes, needed for pixel-skipping rendering/blitting in high horiz res.
+// Extra 4KB is for guard room at beginning.
+// TODO: Determine cause of out-of-bounds write/reads. <-- Note: this is largely
+//  solved by adoption of PCSX Rearmed's 'gpulib' in gpulib_if.cpp, which
+//  replaces this file (gpu.cpp)
+//u16   GPU_FrameBuffer[(FRAME_BUFFER_SIZE+512*1024)/2] __attribute__((aligned(32)));
+static u16 GPU_FrameBuffer[(FRAME_BUFFER_SIZE*2 + 4096)/2] __attribute__((aligned(32)));
 
 ///////////////////////////////////////////////////////////////////////////////
-//  Inner Loops
-s32   u4, du4;
-s32   v4, dv4;
-s32   r4, dr4;
-s32   g4, dg4;
-s32   b4, db4;
-u32   lInc;
-u32   tInc, tMsk;
-
-GPUPacket PacketBuffer;
-// FRAME_BUFFER_SIZE is defined in bytes; 512K is guard memory for out of range reads
-u16   GPU_FrameBuffer[(FRAME_BUFFER_SIZE+512*1024)/2] __attribute__((aligned(2048)));
-u32   GPU_GP1;
+// GPU fixed point math
+#include "gpu_fixedpoint.h"
 
 ///////////////////////////////////////////////////////////////////////////////
-//  Inner loop driver instanciation file
+// Inner loop driver instantiation file
 #include "gpu_inner.h"
 
-///////////////////////////////////////////////////////////////////////////////
-//  GPU Raster Macros
-#define	GPU_RGB16(rgb)        ((((rgb)&0xF80000)>>9)|(((rgb)&0xF800)>>6)|(((rgb)&0xF8)>>3))
-
-#define GPU_EXPANDSIGN(x)  (((s32)(x)<<21)>>21)
-
-#define CHKMAX_X 1024
-#define CHKMAX_Y 512
-
-#define	GPU_SWAP(a,b,t)	{(t)=(a);(a)=(b);(b)=(t);}
-
 ///////////////////////////////////////////////////////////////////////////////
 // GPU internal image drawing functions
 #include "gpu_raster_image.h"
@@ -135,72 +78,88 @@ u32   GPU_GP1;
 #include "gpu_command.h"
 
 ///////////////////////////////////////////////////////////////////////////////
-INLINE void gpuReset(void)
+static void gpuReset(void)
 {
-	GPU_GP1 = 0x14802000;
-	TextureWindow[0] = 0;
-	TextureWindow[1] = 0;
-	TextureWindow[2] = 255;
-	TextureWindow[3] = 255;
-	DrawingArea[2] = 256;
-	DrawingArea[3] = 240;
-	DisplayArea[2] = 256;
-	DisplayArea[3] = 240;
-	DisplayArea[5] = 240;
+	memset((void*)&gpu_unai, 0, sizeof(gpu_unai));
+	gpu_unai.vram = (u16*)GPU_FrameBuffer + (4096/2); //4kb guard room in front
+	gpu_unai.GPU_GP1 = 0x14802000;
+	gpu_unai.DrawingArea[2] = 256;
+	gpu_unai.DrawingArea[3] = 240;
+	gpu_unai.DisplayArea[2] = 256;
+	gpu_unai.DisplayArea[3] = 240;
+	gpu_unai.DisplayArea[5] = 240;
+	gpu_unai.TextureWindow[0] = 0;
+	gpu_unai.TextureWindow[1] = 0;
+	gpu_unai.TextureWindow[2] = 255;
+	gpu_unai.TextureWindow[3] = 255;
+	//senquack - new vars must be updated whenever texture window is changed:
+	//           (used for polygon-drawing in gpu_inner.h, gpu_raster_polygon.h)
+	const u32 fb = FIXED_BITS;  // # of fractional fixed-pt bits of u4/v4
+	gpu_unai.u_msk = (((u32)gpu_unai.TextureWindow[2]) << fb) | ((1 << fb) - 1);
+	gpu_unai.v_msk = (((u32)gpu_unai.TextureWindow[3]) << fb) | ((1 << fb) - 1);
+
+	// Configuration options
+	gpu_unai.config = gpu_unai_config_ext;
+	gpu_unai.ilace_mask = gpu_unai.config.ilace_force;
+	gpu_unai.frameskip.skipCount = gpu_unai.config.frameskip_count;
+
+	SetupLightLUT();
+	SetupDitheringConstants();
 }
 
 ///////////////////////////////////////////////////////////////////////////////
-bool  GPU_init(void)
+long GPU_init(void)
 {
 	gpuReset();
-	
+
+#ifdef GPU_UNAI_USE_INT_DIV_MULTINV
 	// s_invTable
-	for(int i=1;i<=(1<<TABLE_BITS);++i)
+	for(unsigned int i=1;i<=(1<<TABLE_BITS);++i)
 	{
-		double v = 1.0 / double(i);
-		#ifdef GPU_TABLE_10_BITS
-		v *= double(0xffffffff>>1);
-		#else
-		v *= double(0x80000000);
-		#endif
-		s_invTable[i-1]=s32(v);
+		s_invTable[i-1]=0x7fffffff/i;
 	}
+#endif
+
+	gpu_unai.fb_dirty = true;
+	gpu_unai.dma.last_dma = NULL;
 	return (0);
 }
 
 ///////////////////////////////////////////////////////////////////////////////
-void  GPU_shutdown(void)
+long GPU_shutdown(void)
 {
+	return 0;
 }
 
 ///////////////////////////////////////////////////////////////////////////////
-long  GPU_freeze(unsigned int bWrite, GPUFreeze_t* p2)
+long GPU_freeze(u32 bWrite, GPUFreeze_t* p2)
 {
 	if (!p2) return (0);
-	if (p2->Version != 1) return (0);
+	if (p2->ulFreezeVersion != 1) return (0);
 
 	if (bWrite)
 	{
-		p2->GPU_gp1 = GPU_GP1;
-		memset(p2->Control, 0, sizeof(p2->Control));
+		p2->ulStatus = gpu_unai.GPU_GP1;
+		memset(p2->ulControl, 0, sizeof(p2->ulControl));
 		// save resolution and registers for P.E.Op.S. compatibility
-		p2->Control[3] = (3 << 24) | ((GPU_GP1 >> 23) & 1);
-		p2->Control[4] = (4 << 24) | ((GPU_GP1 >> 29) & 3);
-		p2->Control[5] = (5 << 24) | (DisplayArea[0] | (DisplayArea[1] << 10));
-		p2->Control[6] = (6 << 24) | (2560 << 12);
-		p2->Control[7] = (7 << 24) | (DisplayArea[4] | (DisplayArea[5] << 10));
-		p2->Control[8] = (8 << 24) | ((GPU_GP1 >> 17) & 0x3f) | ((GPU_GP1 >> 10) & 0x40);
-		memcpy(p2->FrameBuffer, (u16*)GPU_FrameBuffer, FRAME_BUFFER_SIZE);
+		p2->ulControl[3] = (3 << 24) | ((gpu_unai.GPU_GP1 >> 23) & 1);
+		p2->ulControl[4] = (4 << 24) | ((gpu_unai.GPU_GP1 >> 29) & 3);
+		p2->ulControl[5] = (5 << 24) | (gpu_unai.DisplayArea[0] | (gpu_unai.DisplayArea[1] << 10));
+		p2->ulControl[6] = (6 << 24) | (2560 << 12);
+		p2->ulControl[7] = (7 << 24) | (gpu_unai.DisplayArea[4] | (gpu_unai.DisplayArea[5] << 10));
+		p2->ulControl[8] = (8 << 24) | ((gpu_unai.GPU_GP1 >> 17) & 0x3f) | ((gpu_unai.GPU_GP1 >> 10) & 0x40);
+		memcpy((void*)p2->psxVRam, (void*)gpu_unai.vram, FRAME_BUFFER_SIZE);
 		return (1);
 	}
 	else
 	{
-		GPU_GP1 = p2->GPU_gp1;
-		memcpy((u16*)GPU_FrameBuffer, p2->FrameBuffer, FRAME_BUFFER_SIZE);
-		GPU_writeStatus((5 << 24) | p2->Control[5]);
-		GPU_writeStatus((7 << 24) | p2->Control[7]);
-		GPU_writeStatus((8 << 24) | p2->Control[8]);
-		gpuSetTexture(GPU_GP1);
+		extern void GPU_writeStatus(u32 data);
+		gpu_unai.GPU_GP1 = p2->ulStatus;
+		memcpy((void*)gpu_unai.vram, (void*)p2->psxVRam, FRAME_BUFFER_SIZE);
+		GPU_writeStatus((5 << 24) | p2->ulControl[5]);
+		GPU_writeStatus((7 << 24) | p2->ulControl[7]);
+		GPU_writeStatus((8 << 24) | p2->ulControl[8]);
+		gpuSetTexture(gpu_unai.GPU_GP1);
 		return (1);
 	}
 	return (0);
@@ -233,72 +192,69 @@ u8 PacketSize[256] =
 ///////////////////////////////////////////////////////////////////////////////
 INLINE void gpuSendPacket()
 {
-#ifdef DEBUG_ANALYSIS
-	dbg_anacnt_GPU_sendPacket++;
-#endif
-	gpuSendPacketFunction(PacketBuffer.U4[0]>>24);
+	gpuSendPacketFunction(gpu_unai.PacketBuffer.U4[0]>>24);
 }
 
 ///////////////////////////////////////////////////////////////////////////////
 INLINE void gpuCheckPacket(u32 uData)
 {
-	if (PacketCount)
+	if (gpu_unai.PacketCount)
 	{
-		PacketBuffer.U4[PacketIndex++] = uData;
-		--PacketCount;
+		gpu_unai.PacketBuffer.U4[gpu_unai.PacketIndex++] = uData;
+		--gpu_unai.PacketCount;
 	}
 	else
 	{
-		PacketBuffer.U4[0] = uData;
-		PacketCount = PacketSize[uData >> 24];
-		PacketIndex = 1;
+		gpu_unai.PacketBuffer.U4[0] = uData;
+		gpu_unai.PacketCount = PacketSize[uData >> 24];
+		gpu_unai.PacketIndex = 1;
 	}
-	if (!PacketCount) gpuSendPacket();
+	if (!gpu_unai.PacketCount) gpuSendPacket();
 }
 
 ///////////////////////////////////////////////////////////////////////////////
-void  GPU_writeDataMem(u32* dmaAddress, s32 dmaCount)
+void GPU_writeDataMem(u32* dmaAddress, int dmaCount)
 {
-#ifdef DEBUG_ANALYSIS
-	dbg_anacnt_GPU_writeDataMem++;
-#endif
-	pcsx4all_prof_pause(PCSX4ALL_PROF_CPU);
-	pcsx4all_prof_start_with_pause(PCSX4ALL_PROF_GPU,PCSX4ALL_PROF_HW_WRITE);
+	#ifdef ENABLE_GPU_LOG_SUPPORT
+		fprintf(stdout,"GPU_writeDataMem(%d)\n",dmaCount);
+	#endif
 	u32 data;
-	const u16 *VIDEO_END=(GPU_FrameBuffer+(FRAME_BUFFER_SIZE/2)-1);
-	GPU_GP1 &= ~0x14000000;
+	const u16 *VIDEO_END = (u16*)gpu_unai.vram+(FRAME_BUFFER_SIZE/2)-1;
+	gpu_unai.GPU_GP1 &= ~0x14000000;
 
 	while (dmaCount) 
 	{
-		if (FrameToWrite) 
+		if (gpu_unai.dma.FrameToWrite)
 		{
 			while (dmaCount)
 			{
 				dmaCount--;
 				data = *dmaAddress++;
-				if ((&pvram[px])>(VIDEO_END)) pvram-=512*1024;
-				pvram[px] = data;
-				if (++px>=x_end) 
+				if ((&gpu_unai.dma.pvram[gpu_unai.dma.px])>(VIDEO_END)) gpu_unai.dma.pvram-=512*1024;
+				gpu_unai.dma.pvram[gpu_unai.dma.px] = data;
+				if (++gpu_unai.dma.px >= gpu_unai.dma.x_end)
 				{
-					px = 0;
-					pvram += 1024;
-					if (++py>=y_end) 
+					gpu_unai.dma.px = 0;
+					gpu_unai.dma.pvram += 1024;
+					if (++gpu_unai.dma.py >= gpu_unai.dma.y_end)
 					{
-						FrameToWrite = false;
-						GPU_GP1 &= ~0x08000000;
+						gpu_unai.dma.FrameToWrite = false;
+						gpu_unai.GPU_GP1 &= ~0x08000000;
+						gpu_unai.fb_dirty = true;
 						break;
 					}
 				}
-				if ((&pvram[px])>(VIDEO_END)) pvram-=512*1024;
-				pvram[px] = data>>16;
-				if (++px>=x_end) 
+				if ((&gpu_unai.dma.pvram[gpu_unai.dma.px])>(VIDEO_END)) gpu_unai.dma.pvram-=512*1024;
+				gpu_unai.dma.pvram[gpu_unai.dma.px] = data>>16;
+				if (++gpu_unai.dma.px >= gpu_unai.dma.x_end)
 				{
-					px = 0;
-					pvram += 1024;
-					if (++py>=y_end) 
+					gpu_unai.dma.px = 0;
+					gpu_unai.dma.pvram += 1024;
+					if (++gpu_unai.dma.py >= gpu_unai.dma.y_end)
 					{
-						FrameToWrite = false;
-						GPU_GP1 &= ~0x08000000;
+						gpu_unai.dma.FrameToWrite = false;
+						gpu_unai.GPU_GP1 &= ~0x08000000;
+						gpu_unai.fb_dirty = true;
 						break;
 					}
 				}
@@ -312,95 +268,100 @@ void  GPU_writeDataMem(u32* dmaAddress, s32 dmaCount)
 		}
 	}
 
-	GPU_GP1 = (GPU_GP1 | 0x14000000) & ~0x60000000;
-	fb_dirty = true;
-	pcsx4all_prof_end_with_resume(PCSX4ALL_PROF_GPU,PCSX4ALL_PROF_HW_WRITE);
-	pcsx4all_prof_resume(PCSX4ALL_PROF_CPU);
+	gpu_unai.GPU_GP1 = (gpu_unai.GPU_GP1 | 0x14000000) & ~0x60000000;
 }
 
-u32 *lUsedAddr[3];
-INLINE int CheckForEndlessLoop(u32 *laddr)
+long GPU_dmaChain(u32 *rambase, u32 start_addr)
 {
-	if(laddr==lUsedAddr[1]) return 1;
-	if(laddr==lUsedAddr[2]) return 1;
+	#ifdef ENABLE_GPU_LOG_SUPPORT
+		fprintf(stdout,"GPU_dmaChain(0x%x)\n",start_addr);
+	#endif
 
-	if(laddr<lUsedAddr[0]) lUsedAddr[1]=laddr;
-	else                   lUsedAddr[2]=laddr;
-	lUsedAddr[0]=laddr;
-	return 0;
-}
-
-///////////////////////////////////////////////////////////////////////////////
-long GPU_dmaChain(u32* baseAddr, u32 dmaVAddr)
-{
-#ifdef DEBUG_ANALYSIS
-	dbg_anacnt_GPU_dmaChain++;
-#endif
-	pcsx4all_prof_start_with_pause(PCSX4ALL_PROF_GPU,PCSX4ALL_PROF_HW_WRITE);
-	u32 data, *address, count, offset;
-	unsigned int DMACommandCounter = 0;
+	u32 addr, *list;
+	u32 len, count;
 	long dma_words = 0;
 
-	GPU_GP1 &= ~0x14000000;
-	lUsedAddr[0]=lUsedAddr[1]=lUsedAddr[2]=(u32*)0x1fffff;
-	dmaVAddr &= 0x001FFFFF;
-	while (dmaVAddr != 0x1FFFFF)
+	if (gpu_unai.dma.last_dma) *gpu_unai.dma.last_dma |= 0x800000;
+	
+	gpu_unai.GPU_GP1 &= ~0x14000000;
+	
+	addr = start_addr & 0xffffff;
+	for (count = 0; addr != 0xffffff; count++)
 	{
-		address = (baseAddr + (dmaVAddr >> 2));
-		if(DMACommandCounter++ > 2000000) break;
-		if(CheckForEndlessLoop(address)) break;
-		data = *address++;
-		count = (data >> 24);
-		offset = data & 0x001FFFFF;
-		if (dmaVAddr != offset) dmaVAddr = offset;
-		else dmaVAddr = 0x1FFFFF;
-
-		if(count>0) GPU_writeDataMem(address,count);
-		dma_words += 1 + count;
+		list = rambase + (addr & 0x1fffff) / 4;
+		len = list[0] >> 24;
+		addr = list[0] & 0xffffff;
+
+		dma_words += 1 + len;
+
+		// add loop detection marker
+		list[0] |= 0x800000;
+
+		if (len) GPU_writeDataMem(list + 1, len);
+
+		if (addr & 0x800000)
+		{
+			#ifdef ENABLE_GPU_LOG_SUPPORT
+				fprintf(stdout,"GPU_dmaChain(LOOP)\n");
+			#endif
+			break;
+		}
 	}
-	GPU_GP1 = (GPU_GP1 | 0x14000000) & ~0x60000000;
-	pcsx4all_prof_end_with_resume(PCSX4ALL_PROF_GPU,PCSX4ALL_PROF_HW_WRITE);
+
+	// remove loop detection markers
+	addr = start_addr & 0x1fffff;
+	while (count-- > 0)
+	{
+		list = rambase + addr / 4;
+		addr = list[0] & 0x1fffff;
+		list[0] &= ~0x800000;
+	}
+	
+	if (gpu_unai.dma.last_dma) *gpu_unai.dma.last_dma &= ~0x800000;
+	gpu_unai.dma.last_dma = rambase + (start_addr & 0x1fffff) / 4;
+
+	gpu_unai.GPU_GP1 = (gpu_unai.GPU_GP1 | 0x14000000) & ~0x60000000;
 
 	return dma_words;
 }
 
 ///////////////////////////////////////////////////////////////////////////////
-void  GPU_writeData(u32 data)
+void GPU_writeData(u32 data)
 {
-	const u16 *VIDEO_END=(GPU_FrameBuffer+(FRAME_BUFFER_SIZE/2)-1);
-#ifdef DEBUG_ANALYSIS
-	dbg_anacnt_GPU_writeData++;
-#endif
-	pcsx4all_prof_pause(PCSX4ALL_PROF_CPU);
-	pcsx4all_prof_start_with_pause(PCSX4ALL_PROF_GPU,PCSX4ALL_PROF_HW_WRITE);
-	GPU_GP1 &= ~0x14000000;
+	const u16 *VIDEO_END = (u16*)gpu_unai.vram+(FRAME_BUFFER_SIZE/2)-1;
+	#ifdef ENABLE_GPU_LOG_SUPPORT
+		fprintf(stdout,"GPU_writeData()\n");
+	#endif
+	gpu_unai.GPU_GP1 &= ~0x14000000;
 
-	if (FrameToWrite)
+	if (gpu_unai.dma.FrameToWrite)
 	{
-		if ((&pvram[px])>(VIDEO_END)) pvram-=512*1024;
-		pvram[px]=(u16)data;
-		if (++px>=x_end)
+		if ((&gpu_unai.dma.pvram[gpu_unai.dma.px])>(VIDEO_END)) gpu_unai.dma.pvram-=512*1024;
+		gpu_unai.dma.pvram[gpu_unai.dma.px]=(u16)data;
+		if (++gpu_unai.dma.px >= gpu_unai.dma.x_end)
 		{
-			px = 0;
-			pvram += 1024;
-			if (++py>=y_end) 
+			gpu_unai.dma.px = 0;
+			gpu_unai.dma.pvram += 1024;
+			if (++gpu_unai.dma.py >= gpu_unai.dma.y_end)
 			{
-				FrameToWrite = false;
-				GPU_GP1 &= ~0x08000000;
+				gpu_unai.dma.FrameToWrite = false;
+				gpu_unai.GPU_GP1 &= ~0x08000000;
+				gpu_unai.fb_dirty = true;
 			}
 		}
-		if (FrameToWrite)
+		if (gpu_unai.dma.FrameToWrite)
 		{
-			if ((&pvram[px])>(VIDEO_END)) pvram-=512*1024;
-			pvram[px]=data>>16;
-			if (++px>=x_end)
+			if ((&gpu_unai.dma.pvram[gpu_unai.dma.px])>(VIDEO_END)) gpu_unai.dma.pvram-=512*1024;
+			gpu_unai.dma.pvram[gpu_unai.dma.px]=data>>16;
+			if (++gpu_unai.dma.px >= gpu_unai.dma.x_end)
 			{
-				px = 0;
-				pvram += 1024;
-				if (++py>=y_end) 
+				gpu_unai.dma.px = 0;
+				gpu_unai.dma.pvram += 1024;
+				if (++gpu_unai.dma.py >= gpu_unai.dma.y_end)
 				{
-					FrameToWrite = false;
-					GPU_GP1 &= ~0x08000000;
+					gpu_unai.dma.FrameToWrite = false;
+					gpu_unai.GPU_GP1 &= ~0x08000000;
+					gpu_unai.fb_dirty = true;
 				}
 			}
 		}
@@ -409,507 +370,463 @@ void  GPU_writeData(u32 data)
 	{
 		gpuCheckPacket(data);
 	}
-	GPU_GP1 |= 0x14000000;
-	fb_dirty = true;
-	pcsx4all_prof_end_with_resume(PCSX4ALL_PROF_GPU,PCSX4ALL_PROF_HW_WRITE);
-	pcsx4all_prof_resume(PCSX4ALL_PROF_CPU);
-
+	gpu_unai.GPU_GP1 |= 0x14000000;
 }
 
 
 ///////////////////////////////////////////////////////////////////////////////
-void  GPU_readDataMem(u32* dmaAddress, s32 dmaCount)
+void GPU_readDataMem(u32* dmaAddress, int dmaCount)
 {
-	const u16 *VIDEO_END=(GPU_FrameBuffer+(FRAME_BUFFER_SIZE/2)-1);
-#ifdef DEBUG_ANALYSIS
-	dbg_anacnt_GPU_readDataMem++;
-#endif
-	if(!FrameToRead) return;
+	const u16 *VIDEO_END = (u16*)gpu_unai.vram+(FRAME_BUFFER_SIZE/2)-1;
+	#ifdef ENABLE_GPU_LOG_SUPPORT
+		fprintf(stdout,"GPU_readDataMem(%d)\n",dmaCount);
+	#endif
+	if(!gpu_unai.dma.FrameToRead) return;
 
-	pcsx4all_prof_start_with_pause(PCSX4ALL_PROF_GPU,PCSX4ALL_PROF_HW_WRITE);
-	GPU_GP1 &= ~0x14000000;
+	gpu_unai.GPU_GP1 &= ~0x14000000;
 	do 
 	{
-		if ((&pvram[px])>(VIDEO_END)) pvram-=512*1024;
+		if ((&gpu_unai.dma.pvram[gpu_unai.dma.px])>(VIDEO_END)) gpu_unai.dma.pvram-=512*1024;
 		// lower 16 bit
-		u32 data = pvram[px];
+		//senquack - 64-bit fix (from notaz)
+		//u32 data = (unsigned long)gpu_unai.dma.pvram[gpu_unai.dma.px];
+		u32 data = (u32)gpu_unai.dma.pvram[gpu_unai.dma.px];
 
-		if (++px>=x_end) 
+		if (++gpu_unai.dma.px >= gpu_unai.dma.x_end)
 		{
-			px = 0;
-			pvram += 1024;
+			gpu_unai.dma.px = 0;
+			gpu_unai.dma.pvram += 1024;
 		}
 
-		if ((&pvram[px])>(VIDEO_END)) pvram-=512*1024;
+		if ((&gpu_unai.dma.pvram[gpu_unai.dma.px])>(VIDEO_END)) gpu_unai.dma.pvram-=512*1024;
 		// higher 16 bit (always, even if it's an odd width)
-		data |= (u32)(pvram[px])<<16;
+		//senquack - 64-bit fix (from notaz)
+		//data |= (unsigned long)(gpu_unai.dma.pvram[gpu_unai.dma.px])<<16;
+		data |= (u32)(gpu_unai.dma.pvram[gpu_unai.dma.px])<<16;
 		
 		*dmaAddress++ = data;
 
-		if (++px>=x_end) 
+		if (++gpu_unai.dma.px >= gpu_unai.dma.x_end)
 		{
-			px = 0;
-			pvram += 1024;
-			if (++py>=y_end) 
+			gpu_unai.dma.px = 0;
+			gpu_unai.dma.pvram += 1024;
+			if (++gpu_unai.dma.py >= gpu_unai.dma.y_end)
 			{
-				FrameToRead = false;
-				GPU_GP1 &= ~0x08000000;
+				gpu_unai.dma.FrameToRead = false;
+				gpu_unai.GPU_GP1 &= ~0x08000000;
 				break;
 			}
 		}
 	} while (--dmaCount);
 
-	GPU_GP1 = (GPU_GP1 | 0x14000000) & ~0x60000000;
-	pcsx4all_prof_end_with_resume(PCSX4ALL_PROF_GPU,PCSX4ALL_PROF_HW_WRITE);
+	gpu_unai.GPU_GP1 = (gpu_unai.GPU_GP1 | 0x14000000) & ~0x60000000;
 }
 
 
 
 ///////////////////////////////////////////////////////////////////////////////
-u32  GPU_readData(void)
+u32 GPU_readData(void)
 {
-	const u16 *VIDEO_END=(GPU_FrameBuffer+(FRAME_BUFFER_SIZE/2)-1);
-#ifdef DEBUG_ANALYSIS
-	dbg_anacnt_GPU_readData++;
-#endif
-	pcsx4all_prof_pause(PCSX4ALL_PROF_CPU);
-	pcsx4all_prof_start_with_pause(PCSX4ALL_PROF_GPU,PCSX4ALL_PROF_HW_READ);
-	GPU_GP1 &= ~0x14000000;
-	if (FrameToRead)
+	const u16 *VIDEO_END = (u16*)gpu_unai.vram+(FRAME_BUFFER_SIZE/2)-1;
+	#ifdef ENABLE_GPU_LOG_SUPPORT
+		fprintf(stdout,"GPU_readData()\n");
+	#endif
+	gpu_unai.GPU_GP1 &= ~0x14000000;
+	if (gpu_unai.dma.FrameToRead)
 	{
-		if ((&pvram[px])>(VIDEO_END)) pvram-=512*1024;
-		GP0 = pvram[px];
-		if (++px>=x_end)
+		if ((&gpu_unai.dma.pvram[gpu_unai.dma.px])>(VIDEO_END)) gpu_unai.dma.pvram-=512*1024;
+		gpu_unai.GPU_GP0 = gpu_unai.dma.pvram[gpu_unai.dma.px];
+		if (++gpu_unai.dma.px >= gpu_unai.dma.x_end)
 		{
-			px = 0;
-			pvram += 1024;
-			if (++py>=y_end) 
+			gpu_unai.dma.px = 0;
+			gpu_unai.dma.pvram += 1024;
+			if (++gpu_unai.dma.py >= gpu_unai.dma.y_end)
 			{
-				FrameToRead = false;
-				GPU_GP1 &= ~0x08000000;
+				gpu_unai.dma.FrameToRead = false;
+				gpu_unai.GPU_GP1 &= ~0x08000000;
 			}
 		}
-		if ((&pvram[px])>(VIDEO_END)) pvram-=512*1024;
-		GP0 |= pvram[px]<<16;
-		if (++px>=x_end)
+		if ((&gpu_unai.dma.pvram[gpu_unai.dma.px])>(VIDEO_END)) gpu_unai.dma.pvram-=512*1024;
+		gpu_unai.GPU_GP0 |= gpu_unai.dma.pvram[gpu_unai.dma.px]<<16;
+		if (++gpu_unai.dma.px >= gpu_unai.dma.x_end)
 		{
-			px = 0;
-			pvram +=1024;
-			if (++py>=y_end) 
+			gpu_unai.dma.px = 0;
+			gpu_unai.dma.pvram += 1024;
+			if (++gpu_unai.dma.py >= gpu_unai.dma.y_end)
 			{
-				FrameToRead = false;
-				GPU_GP1 &= ~0x08000000;
+				gpu_unai.dma.FrameToRead = false;
+				gpu_unai.GPU_GP1 &= ~0x08000000;
 			}
 		}
 
 	}
-	GPU_GP1 |= 0x14000000;
+	gpu_unai.GPU_GP1 |= 0x14000000;
 
-	pcsx4all_prof_end_with_resume(PCSX4ALL_PROF_GPU,PCSX4ALL_PROF_HW_READ);
-	pcsx4all_prof_resume(PCSX4ALL_PROF_CPU);
-	return (GP0);
+	return (gpu_unai.GPU_GP0);
 }
 
 ///////////////////////////////////////////////////////////////////////////////
-u32     GPU_readStatus(void)
+u32 GPU_readStatus(void)
 {
-#ifdef DEBUG_ANALYSIS
-	dbg_anacnt_GPU_readStatus++;
-#endif
-	return GPU_GP1;
+	return gpu_unai.GPU_GP1;
+}
+
+INLINE void GPU_NoSkip(void)
+{
+	#ifdef ENABLE_GPU_LOG_SUPPORT
+		fprintf(stdout,"GPU_NoSkip()\n");
+	#endif
+	gpu_unai.frameskip.wasSkip = gpu_unai.frameskip.isSkip;
+	if (gpu_unai.frameskip.isSkip)
+	{
+		gpu_unai.frameskip.isSkip = false;
+		gpu_unai.frameskip.skipGPU = false;
+	}
+	else
+	{
+		gpu_unai.frameskip.isSkip = gpu_unai.frameskip.skipFrame;
+		gpu_unai.frameskip.skipGPU = gpu_unai.frameskip.skipFrame;
+	}
 }
 
 ///////////////////////////////////////////////////////////////////////////////
 void  GPU_writeStatus(u32 data)
 {
-#ifdef DEBUG_ANALYSIS
-	dbg_anacnt_GPU_writeStatus++;
-#endif
-	pcsx4all_prof_pause(PCSX4ALL_PROF_CPU);
-	pcsx4all_prof_start_with_pause(PCSX4ALL_PROF_GPU,PCSX4ALL_PROF_HW_WRITE);
+	#ifdef ENABLE_GPU_LOG_SUPPORT
+		fprintf(stdout,"GPU_writeStatus(%d,%d)\n",data>>24,data & 0xff);
+	#endif
 	switch (data >> 24) {
 	case 0x00:
 		gpuReset();
 		break;
 	case 0x01:
-		GPU_GP1 &= ~0x08000000;
-		PacketCount = 0; FrameToRead = FrameToWrite = false;
+		gpu_unai.GPU_GP1 &= ~0x08000000;
+		gpu_unai.PacketCount = 0;
+		gpu_unai.dma.FrameToRead = gpu_unai.dma.FrameToWrite = false;
 		break;
 	case 0x02:
-		GPU_GP1 &= ~0x08000000;
-		PacketCount = 0; FrameToRead = FrameToWrite = false;
+		gpu_unai.GPU_GP1 &= ~0x08000000;
+		gpu_unai.PacketCount = 0;
+		gpu_unai.dma.FrameToRead = gpu_unai.dma.FrameToWrite = false;
 		break;
 	case 0x03:
-		GPU_GP1 = (GPU_GP1 & ~0x00800000) | ((data & 1) << 23);
+		gpu_unai.GPU_GP1 = (gpu_unai.GPU_GP1 & ~0x00800000) | ((data & 1) << 23);
 		break;
 	case 0x04:
-		if (data == 0x04000000)
-		PacketCount = 0;
-		GPU_GP1 = (GPU_GP1 & ~0x60000000) | ((data & 3) << 29);
+		if (data == 0x04000000)	gpu_unai.PacketCount = 0;
+		gpu_unai.GPU_GP1 = (gpu_unai.GPU_GP1 & ~0x60000000) | ((data & 3) << 29);
 		break;
 	case 0x05:
-		DisplayArea[0] = (data & 0x000003FF); //(short)(data & 0x3ff);
-		DisplayArea[1] = ((data & 0x0007FC00)>>10); //(data & 0x000FFC00) >> 10; //(short)((data>>10)&0x1ff);
-		fb_dirty = true;
-		wasSkip = isSkip;
-		if (isSkip)
-			isSkip = false;
-		else
-			isSkip = skipFrame;
+		// Start of Display Area in VRAM
+		gpu_unai.DisplayArea[0] = data & 0x3ff;         // X (0..1023)
+		gpu_unai.DisplayArea[1] = (data >> 10) & 0x1ff; // Y (0..511)
+		GPU_NoSkip();
+		break;
+	case 0x06:
+		// GP1(06h) - Horizontal Display range (on Screen)
+		// 0-11   X1 (260h+0)       ;12bit       ;\counted in 53.222400MHz units,
+		// 12-23  X2 (260h+320*8)   ;12bit       ;/relative to HSYNC
+
+		// senquack - gpu_unai completely ignores GP1(0x06) command and
+		// lacks even a place in DisplayArea[] array to store the values.
+		// It seems to have been concerned only with vertical display range
+		// and centering top/bottom. I will not add support here, and
+		// focus instead on the gpulib version (gpulib_if.cpp) which uses
+		// gpulib for its PS1->host framebuffer blitting.
 		break;
 	case 0x07:
-		DisplayArea[4] = data & 0x000003FF; //(short)(data & 0x3ff);
-		DisplayArea[5] = (data & 0x000FFC00) >> 10; //(short)((data>>10) & 0x3ff);
-		fb_dirty = true;
+		// GP1(07h) - Vertical Display range (on Screen)
+		// 0-9   Y1 (NTSC=88h-(224/2), (PAL=A3h-(264/2))  ;\scanline numbers on screen,
+		// 10-19 Y2 (NTSC=88h+(224/2), (PAL=A3h+(264/2))  ;/relative to VSYNC
+		// 20-23 Not used (zero)
+		{
+			u32 v1=data & 0x000003FF; //(short)(data & 0x3ff);
+			u32 v2=(data & 0x000FFC00) >> 10; //(short)((data>>10) & 0x3ff);
+			if ((gpu_unai.DisplayArea[4]!=v1)||(gpu_unai.DisplayArea[5]!=v2))
+			{
+				gpu_unai.DisplayArea[4] = v1;
+				gpu_unai.DisplayArea[5] = v2;
+				#ifdef ENABLE_GPU_LOG_SUPPORT
+					fprintf(stdout,"video_clear(CHANGE_Y)\n");
+				#endif
+				video_clear();
+			}
+		}
 		break;
 	case 0x08:
 		{
-			GPU_GP1 = (GPU_GP1 & ~0x007F0000) | ((data & 0x3F) << 17) | ((data & 0x40) << 10);
-			static u32 HorizontalResolution[8] = { 256, 368, 320, 384, 512, 512, 640, 640 };
-			DisplayArea[2] = HorizontalResolution[(GPU_GP1 >> 16) & 7];
-			static u32 VerticalResolution[4] = { 240, 480, 256, 480 };
-			DisplayArea[3] = VerticalResolution[(GPU_GP1 >> 19) & 3];
-			isPAL = (data & 0x08) ? true : false; // if 1 - PAL mode, else NTSC
+			static const u32 HorizontalResolution[8] = { 256, 368, 320, 384, 512, 512, 640, 640 };
+			static const u32 VerticalResolution[4] = { 240, 480, 256, 480 };
+			gpu_unai.GPU_GP1 = (gpu_unai.GPU_GP1 & ~0x007F0000) | ((data & 0x3F) << 17) | ((data & 0x40) << 10);
+			#ifdef ENABLE_GPU_LOG_SUPPORT
+				fprintf(stdout,"GPU_writeStatus(RES=%dx%d,BITS=%d,PAL=%d)\n",HorizontalResolution[(gpu_unai.GPU_GP1 >> 16) & 7],
+						VerticalResolution[(gpu_unai.GPU_GP1 >> 19) & 3],(gpu_unai.GPU_GP1&0x00200000?24:15),(IS_PAL?1:0));
+			#endif
+			// Video mode change
+			u32 new_width = HorizontalResolution[(gpu_unai.GPU_GP1 >> 16) & 7];
+			u32 new_height = VerticalResolution[(gpu_unai.GPU_GP1 >> 19) & 3];
+
+			if (gpu_unai.DisplayArea[2] != new_width || gpu_unai.DisplayArea[3] != new_height)
+			{
+				// Update width
+				gpu_unai.DisplayArea[2] = new_width;
+
+				if (PixelSkipEnabled()) {
+					// Set blit_mask for high horizontal resolutions. This allows skipping
+					//  rendering pixels that would never get displayed on low-resolution
+					//  platforms that use simple pixel-dropping scaler.
+					switch (gpu_unai.DisplayArea[2])
+					{
+						case 512: gpu_unai.blit_mask = 0xa4; break; // GPU_BlitWWSWWSWS
+						case 640: gpu_unai.blit_mask = 0xaa; break; // GPU_BlitWS
+						default:  gpu_unai.blit_mask = 0;    break;
+					}
+				} else {
+					gpu_unai.blit_mask = 0;
+				}
+
+				// Update height
+				gpu_unai.DisplayArea[3] = new_height;
+
+				if (LineSkipEnabled()) {
+					// Set rendering line-skip (only render every other line in high-res
+					//  480 vertical mode, or, optionally, force it for all video modes)
+
+					if (gpu_unai.DisplayArea[3] == 480) {
+						if (gpu_unai.config.ilace_force) {
+							gpu_unai.ilace_mask = 3; // Only need 1/4 of lines
+						} else {
+							gpu_unai.ilace_mask = 1; // Only need 1/2 of lines
+						}
+					} else {
+						// Vert resolution changed from 480 to lower one
+						gpu_unai.ilace_mask = gpu_unai.config.ilace_force;
+					}
+				} else {
+					gpu_unai.ilace_mask = 0;
+				}
+
+				#ifdef ENABLE_GPU_LOG_SUPPORT
+					fprintf(stdout,"video_clear(CHANGE_RES)\n");
+				#endif
+				video_clear();
+			}
+
 		}
-		fb_dirty = true;
 		break;
 	case 0x10:
-		switch (data & 0xffff) {
-		case 0:
-		case 1:
-		case 3:
-			GP0 = (DrawingArea[1] << 10) | DrawingArea[0];
-			break;
-		case 4:
-			GP0 = ((DrawingArea[3]-1) << 10) | (DrawingArea[2]-1);
-			break;
-		case 6:
-		case 5:
-			GP0 = (DrawingOffset[1] << 11) | DrawingOffset[0];
-			break;
-		case 7:
-			GP0 = 2;
-			break;
-		default:
-			GP0 = 0;
+		switch (data & 0xff) {
+			case 2: gpu_unai.GPU_GP0 = gpu_unai.tex_window; break;
+			case 3: gpu_unai.GPU_GP0 = (gpu_unai.DrawingArea[1] << 10) | gpu_unai.DrawingArea[0]; break;
+			case 4: gpu_unai.GPU_GP0 = ((gpu_unai.DrawingArea[3]-1) << 10) | (gpu_unai.DrawingArea[2]-1); break;
+			case 5: case 6:	gpu_unai.GPU_GP0 = (((u32)gpu_unai.DrawingOffset[1] & 0x7ff) << 11) | ((u32)gpu_unai.DrawingOffset[0] & 0x7ff); break;
+			case 7: gpu_unai.GPU_GP0 = 2; break;
+			case 8: case 15: gpu_unai.GPU_GP0 = 0xBFC03720; break;
 		}
 		break;
 	}
-	pcsx4all_prof_end_with_resume(PCSX4ALL_PROF_GPU,PCSX4ALL_PROF_HW_WRITE);
-	pcsx4all_prof_resume(PCSX4ALL_PROF_CPU);
 }
 
-#ifndef REARMED
-
 // Blitting functions
 #include "gpu_blit.h"
 
-INLINE void gpuVideoOutput(void)
+static void gpuVideoOutput(void)
 {
-	static s16 old_res_horz, old_res_vert, old_rgb24;
-	s16 h0, x0, y0, w0, h1;
+	int h0, x0, y0, w0, h1;
 
-	x0 = DisplayArea[0];
-	y0 = DisplayArea[1];
+	x0 = gpu_unai.DisplayArea[0];
+	y0 = gpu_unai.DisplayArea[1];
 
-	w0 = DisplayArea[2];
-	h0 = DisplayArea[3];  // video mode
+	w0 = gpu_unai.DisplayArea[2];
+	h0 = gpu_unai.DisplayArea[3];  // video mode
 
-	h1 = DisplayArea[5] - DisplayArea[4]; // display needed
+	h1 = gpu_unai.DisplayArea[5] - gpu_unai.DisplayArea[4]; // display needed
 	if (h0 == 480) h1 = Min2(h1*2,480);
 
-	u16* dest_screen16 = SCREEN;
-	u16* src_screen16  = &((u16*)GPU_FrameBuffer)[FRAME_OFFSET(x0,y0)];
-	u32 isRGB24 = (GPU_GP1 & 0x00200000 ? 32 : 0);
+	bool isRGB24 = (gpu_unai.GPU_GP1 & 0x00200000 ? true : false);
+	u16* dst16 = SCREEN;
+	u16* src16 = (u16*)gpu_unai.vram;
 
-	/* Clear the screen if resolution changed to prevent interlacing and clipping to clash */
-	if( (w0 != old_res_horz || h1 != old_res_vert || (s16)isRGB24 != old_rgb24) )
-	{
-		// Update old resolution
-		old_res_horz = w0;
-		old_res_vert = h1;
-		old_rgb24 = (s16)isRGB24;
-		// Finally, clear the screen for this special case
-		video_clear();
-	}
+	// PS1 fb read wraps around (fixes black screen in 'Tobal no. 1')
+	unsigned int src16_offs_msk = 1024*512-1;
+	unsigned int src16_offs = (x0 + y0*1024) & src16_offs_msk;
 
 	//  Height centering
 	int sizeShift = 1;
-	if(h0==256) h0 = 240; else if(h0==480) sizeShift = 2;
-	if(h1>h0) { src_screen16 += ((h1-h0)>>sizeShift)*1024; h1 = h0; }
-	else if(h1<h0) dest_screen16 += ((h0-h1)>>sizeShift)*VIDEO_WIDTH;
+	if (h0 == 256) {
+		h0 = 240;
+	} else if (h0 == 480) {
+		sizeShift = 2;
+	}
+	if (h1 > h0) {
+		src16_offs = (src16_offs + (((h1-h0) / 2) * 1024)) & src16_offs_msk;
+		h1 = h0;
+	} else if (h1<h0) {
+		dst16 += ((h0-h1) >> sizeShift) * VIDEO_WIDTH;
+	}
+
 
 	/* Main blitter */
 	int incY = (h0==480) ? 2 : 1;
 	h0=(h0==480 ? 2048 : 1024);
 
 	{
-		const int li=linesInterlace;
-		bool pi=progressInterlace;
-		bool pif=progressInterlace_flag;
+		const int li=gpu_unai.ilace_mask;
+		bool pi = ProgressiveInterlaceEnabled();
+		bool pif = gpu_unai.prog_ilace_flag;
 		switch ( w0 )
 		{
 			case 256:
 				for(int y1=y0+h1; y0<y1; y0+=incY)
 				{
-					if(( 0 == (y0&li) ) && ((!pi) || (pif=!pif))) GPU_BlitWWDWW(	src_screen16,	dest_screen16, isRGB24);
-					dest_screen16 += VIDEO_WIDTH;
-					src_screen16  += h0;
+					if (( 0 == (y0&li) ) && ((!pi) || (pif=!pif)))
+						GPU_BlitWWDWW(src16 + src16_offs, dst16, isRGB24);
+					dst16 += VIDEO_WIDTH;
+					src16_offs = (src16_offs + h0) & src16_offs_msk;
 				}
 				break;
 			case 368:
 				for(int y1=y0+h1; y0<y1; y0+=incY)
 				{
-					if(( 0 == (y0&li) ) && ((!pi) || (pif=!pif))) GPU_BlitWWWWWWWWS(	src_screen16,	dest_screen16, isRGB24, 4);
-					dest_screen16 += VIDEO_WIDTH;
-					src_screen16  += h0;
+					if (( 0 == (y0&li) ) && ((!pi) || (pif=!pif)))
+						GPU_BlitWWWWWWWWS(src16 + src16_offs, dst16, isRGB24, 4);
+					dst16 += VIDEO_WIDTH;
+					src16_offs = (src16_offs + h0) & src16_offs_msk;
 				}
 				break;
 			case 320:
+				// Ensure 32-bit alignment for GPU_BlitWW() blitter:
+				src16_offs &= ~1;
 				for(int y1=y0+h1; y0<y1; y0+=incY)
 				{
-					if(( 0 == (y0&li) ) && ((!pi) || (pif=!pif))) GPU_BlitWW(	src_screen16,	dest_screen16, isRGB24);
-					dest_screen16 += VIDEO_WIDTH;
-					src_screen16  += h0;
+					if (( 0 == (y0&li) ) && ((!pi) || (pif=!pif)))
+						GPU_BlitWW(src16 + src16_offs, dst16, isRGB24);
+					dst16 += VIDEO_WIDTH;
+					src16_offs = (src16_offs + h0) & src16_offs_msk;
 				}
 				break;
 			case 384:
 				for(int y1=y0+h1; y0<y1; y0+=incY)
 				{
-					if(( 0 == (y0&li) ) && ((!pi) || (pif=!pif))) GPU_BlitWWWWWS(	src_screen16,	dest_screen16, isRGB24);
-					dest_screen16 += VIDEO_WIDTH;
-					src_screen16  += h0;
+					if (( 0 == (y0&li) ) && ((!pi) || (pif=!pif)))
+						GPU_BlitWWWWWS(src16 + src16_offs, dst16, isRGB24);
+					dst16 += VIDEO_WIDTH;
+					src16_offs = (src16_offs + h0) & src16_offs_msk;
 				}
 				break;
 			case 512:
 				for(int y1=y0+h1; y0<y1; y0+=incY)
 				{
-					if(( 0 == (y0&li) ) && ((!pi) || (pif=!pif))) GPU_BlitWWSWWSWS(	src_screen16, dest_screen16, isRGB24);
-					dest_screen16 += VIDEO_WIDTH;
-					src_screen16  += h0;
+					if (( 0 == (y0&li) ) && ((!pi) || (pif=!pif)))
+						GPU_BlitWWSWWSWS(src16 + src16_offs, dst16, isRGB24);
+					dst16 += VIDEO_WIDTH;
+					src16_offs = (src16_offs + h0) & src16_offs_msk;
 				}
 				break;
 			case 640:
 				for(int y1=y0+h1; y0<y1; y0+=incY)
 				{
-					if(( 0 == (y0&li) ) && ((!pi) || (pif=!pif))) GPU_BlitWS(	src_screen16, dest_screen16, isRGB24);
-					dest_screen16 += VIDEO_WIDTH;
-					src_screen16  += h0;
+					if (( 0 == (y0&li) ) && ((!pi) || (pif=!pif)))
+						GPU_BlitWS(src16 + src16_offs, dst16, isRGB24);
+					dst16 += VIDEO_WIDTH;
+					src16_offs = (src16_offs + h0) & src16_offs_msk;
 				}
 				break;
 		}
-		progressInterlace_flag=!progressInterlace_flag;
+		gpu_unai.prog_ilace_flag = !gpu_unai.prog_ilace_flag;
 	}
 	video_flip();
 }
 
-///////////////////////////////////////////////////////////////////////////////
-void  GPU_updateLace(void)
-{
-#ifdef  ENABLE_GPU_LOG_SUPPORT
-	fprintf(stdout,"GPU_updateLace()\n");
-#endif
-#ifdef DEBUG_ANALYSIS
-	dbg_anacnt_GPU_updateLace++;
-#endif
-	pcsx4all_prof_start_with_pause(PCSX4ALL_PROF_GPU,PCSX4ALL_PROF_COUNTERS);
-#ifdef PROFILER_PCSX4ALL
-	pcsx4all_prof_frames++;
-#endif
-#ifdef DEBUG_FRAME
-	if(isdbg_frame())
-	{
-		static int passed=0;
-		if (!passed) dbg_enable();
-		else pcsx4all_exit();
-		passed++;
-	}
-#endif
+// Update frames-skip each second>>3 (8 times per second)
+#define GPU_FRAMESKIP_UPDATE 3
 
-	// Frame skip table
-	static const unsigned char skipTable[12][12] =
-	{
-		{ 0,0,0,0,0,0,0,0,0,0,0,0 },
-		{ 0,0,0,0,0,0,0,0,0,0,0,1 },
-		{ 0,0,0,0,0,1,0,0,0,0,0,1 },
-		{ 0,0,0,1,0,0,0,1,0,0,0,1 },
-		{ 0,0,1,0,0,1,0,0,1,0,0,1 },
-		{ 0,1,0,0,1,0,1,0,0,1,0,1 },
-		{ 0,1,0,1,0,1,0,1,0,1,0,1 },
-		{ 0,1,0,1,1,0,1,0,1,1,0,1 },
-		{ 0,1,1,0,1,1,0,1,1,0,1,1 },
-		{ 0,1,1,1,0,1,1,1,0,1,1,1 },
-		{ 0,1,1,1,1,1,0,1,1,1,1,1 },
-		{ 0,1,1,1,1,1,1,1,1,1,1,1 }
-	};
-	
-	// Interlace bit toggle
-	GPU_GP1 ^= 0x80000000;
-
-	// Update display
-	if ((!skipFrame) && (!isSkip) && (fb_dirty) && (!(((GPU_GP1&0x08000000))||((GPU_GP1&0x00800000)))))
-	{
-		gpuVideoOutput(); // Display updated
-
-		if (DisplayArea[3] == 480)
-		{
-			if (linesInterlace_user) linesInterlace = 3; // 1/4 of lines
-			else linesInterlace = 1; // if 480 we only need half of lines
-		}
-		else if (linesInterlace != linesInterlace_user)
-		{
-			linesInterlace = linesInterlace_user; // resolution changed from 480 to lower one
-			video_clear();
-		}
-	}
-
-	// Limit FPS
-	if (frameLimit)
-	{
-		static unsigned next=get_ticks();
-		if (!skipFrame)
-		{
-			unsigned now=get_ticks();
-			if (now<next) wait_ticks(next-now);
-		}
-		next+=(isPAL?(1000000/50):((unsigned)(1000000.0/59.94)));
-	}
+static void GPU_frameskip (bool show)
+{
+	u32 now=get_ticks(); // current frame
 
-	// Show FPS statistics
-	if (show_fps)
+	// Update frameskip
+	if (gpu_unai.frameskip.skipCount==0) gpu_unai.frameskip.skipFrame=false; // frameskip off
+	else if (gpu_unai.frameskip.skipCount==7) { if (show) gpu_unai.frameskip.skipFrame=!gpu_unai.frameskip.skipFrame; } // frameskip medium
+	else if (gpu_unai.frameskip.skipCount==8) gpu_unai.frameskip.skipFrame=true; // frameskip maximum
+	else
 	{
-		static u32 real_fps=0;
-		static u32 prev=get_ticks();
-		static char msg[32]="FPS=000/00 SPD=000%";
-		u32 now=get_ticks();
-		real_fps++;
-		if ((now-prev)>=1000000)
+		static u32 spd=100; // speed %
+		static u32 frames=0; // frames counter
+		static u32 prev=now; // previous fps calculation
+		frames++;
+		if ((now-prev)>=(TPS>>GPU_FRAMESKIP_UPDATE))
 		{
-			u32 expected_fps=(isPAL?50:60);
-			sprintf(msg,"FPS=%3d/%2d SPD=%3d%%",((real_fps*(12-skipCount))/12),((expected_fps*(12-skipCount))/12),((real_fps*100)/expected_fps));
+			if (IS_PAL) spd=(frames<<1);
+			else spd=((frames*1001)/600);
+			spd<<=GPU_FRAMESKIP_UPDATE;
+			frames=0;
 			prev=now;
-			real_fps=0;
 		}
-		port_printf(5,5,msg);
-	}
-
-	// Update frame-skip
-	if (!alt_fps)
-	{
-		// Video frame-skip
-		skipFrame=skipTable[skipCount][skCount];
-		skCount--; if (skCount<0) skCount=11;
-		isSkip=skipFrame;
-	}
-	else
-	{
-		// Game frame-skip
-		if (!isSkip)
+		switch(gpu_unai.frameskip.skipCount)
 		{
-			skipFrame=skipTable[skipCount][skCount];
-			skCount--; if (skCount<0) skCount=11;
-			isSkip=true;
+			case 1: if (spd<50) gpu_unai.frameskip.skipFrame=true; else gpu_unai.frameskip.skipFrame=false; break; // frameskip on (spd<50%)
+			case 2: if (spd<60) gpu_unai.frameskip.skipFrame=true; else gpu_unai.frameskip.skipFrame=false; break; // frameskip on (spd<60%)
+			case 3: if (spd<70) gpu_unai.frameskip.skipFrame=true; else gpu_unai.frameskip.skipFrame=false; break; // frameskip on (spd<70%)
+			case 4: if (spd<80) gpu_unai.frameskip.skipFrame=true; else gpu_unai.frameskip.skipFrame=false; break; // frameskip on (spd<80%)
+			case 5: if (spd<90) gpu_unai.frameskip.skipFrame=true; else gpu_unai.frameskip.skipFrame=false; break; // frameskip on (spd<90%)
 		}
 	}
-	fb_dirty=false;
-
-	pcsx4all_prof_end_with_resume(PCSX4ALL_PROF_GPU,PCSX4ALL_PROF_COUNTERS);
-}
-
-#else
-
-#include "../../frontend/plugin_lib.h"
-
-extern "C" {
-
-static const struct rearmed_cbs *cbs;
-static s16 old_res_horz, old_res_vert, old_rgb24;
-
-static void blit(void)
-{
-	u16 *base = (u16 *)GPU_FrameBuffer;
-	s16 isRGB24 = (GPU_GP1 & 0x00200000) ? 1 : 0;
-	s16 h0, x0, y0, w0, h1;
-
-	x0 = DisplayArea[0] & ~1; // alignment needed by blitter
-	y0 = DisplayArea[1];
-	base += FRAME_OFFSET(x0, y0);
-
-	w0 = DisplayArea[2];
-	h0 = DisplayArea[3];  // video mode
-
-	h1 = DisplayArea[5] - DisplayArea[4]; // display needed
-	if (h0 == 480) h1 = Min2(h1*2,480);
-
-	if (h1 <= 0)
-		return;
-
-	if (w0 != old_res_horz || h1 != old_res_vert || isRGB24 != old_rgb24)
-	{
-		old_res_horz = w0;
-		old_res_vert = h1;
-		old_rgb24 = (s16)isRGB24;
-		cbs->pl_vout_set_mode(w0, h1, w0, h1, isRGB24 ? 24 : 16);
-	}
-
-	cbs->pl_vout_flip(base, 1024, isRGB24, w0, h1);
 }
 
+///////////////////////////////////////////////////////////////////////////////
 void GPU_updateLace(void)
 {
 	// Interlace bit toggle
-	GPU_GP1 ^= 0x80000000;
+	gpu_unai.GPU_GP1 ^= 0x80000000;
 
-	if (!fb_dirty || (GPU_GP1&0x08800000))
-		return;
-
-	if (!wasSkip) {
-		blit();
-		fb_dirty = false;
-		skCount = 0;
-	}
-	else {
-		skCount++;
-		if (skCount >= 8)
-			wasSkip = isSkip = 0;
+	// Update display?
+	if ((gpu_unai.fb_dirty) && (!gpu_unai.frameskip.wasSkip) && (!(gpu_unai.GPU_GP1&0x00800000)))
+	{
+		// Display updated
+		gpuVideoOutput();
+		GPU_frameskip(true);
+		#ifdef ENABLE_GPU_LOG_SUPPORT
+			fprintf(stdout,"GPU_updateLace(UPDATE)\n");
+		#endif
+	} else {
+		GPU_frameskip(false);
+		#ifdef ENABLE_GPU_LOG_SUPPORT
+			fprintf(stdout,"GPU_updateLace(SKIP)\n");
+		#endif
 	}
 
-	skipFrame = cbs->fskip_advice || cbs->frameskip == 1;
-}
+	if ((!gpu_unai.frameskip.skipCount) && (gpu_unai.DisplayArea[3] == 480)) gpu_unai.frameskip.skipGPU=true; // Tekken 3 hack
 
-long GPUopen(unsigned long *, char *, char *)
-{
-	cbs->pl_vout_open();
-	return 0;
+	gpu_unai.fb_dirty=false;
+	gpu_unai.dma.last_dma = NULL;
 }
 
-long GPUclose(void)
+// Allows frontend to signal plugin to redraw screen after returning to emu
+void GPU_requestScreenRedraw()
 {
-	cbs->pl_vout_close();
-	return 0;
+	gpu_unai.fb_dirty = true;
 }
 
-long GPUfreeze(unsigned int ulGetFreezeData, GPUFreeze_t* p2)
+void GPU_getScreenInfo(GPUScreenInfo_t *sinfo)
 {
-	if (ulGetFreezeData > 1)
-		return 0;
-
-	return GPU_freeze(ulGetFreezeData, p2);
+	bool depth24 = (gpu_unai.GPU_GP1 & 0x00200000 ? true : false);
+	int16_t hres = (uint16_t)gpu_unai.DisplayArea[2];
+	int16_t vres = (uint16_t)gpu_unai.DisplayArea[3];
+	int16_t w = hres; // Original gpu_unai doesn't support width < 100%
+	int16_t h = gpu_unai.DisplayArea[5] - gpu_unai.DisplayArea[4];
+	if (vres == 480)
+		h *= 2;
+	if (h <= 0 || h > vres)
+		h = vres;
+
+	sinfo->vram    = (uint8_t*)gpu_unai.vram;
+	sinfo->x       = (uint16_t)gpu_unai.DisplayArea[0];
+	sinfo->y       = (uint16_t)gpu_unai.DisplayArea[1];
+	sinfo->w       = w;
+	sinfo->h       = h;
+	sinfo->hres    = hres;
+	sinfo->vres    = vres;
+	sinfo->depth24 = depth24;
+	sinfo->pal     = IS_PAL;
 }
-
-void GPUrearmedCallbacks(const struct rearmed_cbs *cbs_)
-{
-	enableAbbeyHack = cbs_->gpu_unai.abe_hack;
-	light = !cbs_->gpu_unai.no_light;
-	blend = !cbs_->gpu_unai.no_blend;
-	if (cbs_->pl_vout_set_raw_vram)
-		cbs_->pl_vout_set_raw_vram((void *)GPU_FrameBuffer);
-
-	cbs = cbs_;
-	if (cbs->pl_set_gpu_caps)
-		cbs->pl_set_gpu_caps(0);
-}
-
-} /* extern "C" */
-
-#endif
diff --git a/plugins/gpu_unai/gpu.h b/plugins/gpu_unai/gpu.h
index 18116303..eade2a8e 100644
--- a/plugins/gpu_unai/gpu.h
+++ b/plugins/gpu_unai/gpu.h
@@ -1,6 +1,7 @@
 /***************************************************************************
 *   Copyright (C) 2010 PCSX4ALL Team                                      *
 *   Copyright (C) 2010 Unai                                               *
+*   Copyright (C) 2016 Senquack (dansilsby <AT> gmail <DOT> com)          *
 *                                                                         *
 *   This program is free software; you can redistribute it and/or modify  *
 *   it under the terms of the GNU General Public License as published by  *
@@ -18,70 +19,52 @@
 *   51 Franklin Street, Fifth Floor, Boston, MA 02111-1307 USA.           *
 ***************************************************************************/
 
-#ifndef NEW_GPU_H
-#define NEW_GPU_H
+#ifndef GPU_UNAI_GPU_H
+#define GPU_UNAI_GPU_H
 
-///////////////////////////////////////////////////////////////////////////////
-//  GPU global definitions
-#define	FRAME_BUFFER_SIZE	(1024*512*2)
-#define	FRAME_WIDTH			  1024
-#define	FRAME_HEIGHT		  512
-#define	FRAME_OFFSET(x,y)	(((y)<<10)+(x))
+struct gpu_unai_config_t {
+	uint8_t pixel_skip:1;     // If 1, allows skipping rendering pixels that
+	                          //  would not be visible when a high horizontal
+	                          //  resolution PS1 video mode is set.
+	                          //  Only applies to devices with low resolutions
+	                          //  like 320x240. Should not be used if a
+	                          //  down-scaling framebuffer blitter is in use.
+	                          //  Can cause gfx artifacts if game reads VRAM
+	                          //  to do framebuffer effects.
 
-#define VIDEO_WIDTH 320
+	uint8_t ilace_force:3;    // Option to force skipping rendering of lines,
+	                          //  for very slow platforms. Value will be
+	                          //  assigned to 'ilace_mask' in gpu_unai struct.
+	                          //  Normally 0. Value '1' will skip rendering
+	                          //  odd lines.
 
-typedef char				s8;
-typedef signed short		s16;
-typedef signed int			s32;
-typedef signed long long	s64;
+	uint8_t lighting:1;
+	uint8_t fast_lighting:1;
+	uint8_t blending:1;
+	uint8_t dithering:1;
 
-typedef unsigned char		u8;
-typedef unsigned short		u16;
-typedef unsigned int		u32;
-typedef unsigned long long	u64;
+	//senquack Only PCSX Rearmed's version of gpu_unai had this, and I
+	// don't think it's necessary. It would require adding 'AH' flag to
+	// gpuSpriteSpanFn() increasing size of sprite span function array.
+	//uint8_t enableAbbeyHack:1;  // Abe's Odyssey hack
 
-#include "gpu_fixedpoint.h"
-
-///////////////////////////////////////////////////////////////////////////////
-//  Tweaks and Hacks
-extern  int  skipCount;
-extern  bool enableAbbeyHack;
-extern  bool show_fps;
-extern  bool alt_fps;
-
-///////////////////////////////////////////////////////////////////////////////
-//  interlaced rendering
-extern  int linesInterlace_user;
-extern  bool progressInterlace;
-
-extern  bool light;
-extern  bool blend;
-
-typedef struct {
-	u32 Version;
-	u32 GPU_gp1;
-	u32 Control[256];
-	unsigned char FrameBuffer[1024*512*2];
-} GPUFreeze_t;
-
-struct  GPUPacket
-{
-	union
-	{
-		u32 U4[16];
-		s32 S4[16];
-		u16 U2[32];
-		s16 S2[32];
-		u8  U1[64];
-		s8  S1[64];
-	};
+	////////////////////////////////////////////////////////////////////////////
+	// Variables used only by older standalone version of gpu_unai (gpu.cpp)
+#ifndef USE_GPULIB
+	uint8_t prog_ilace:1;         // Progressive interlace option (old option)
+	                              //  This option was somewhat oddly named:
+	                              //  When in interlaced video mode, on a low-res
+	                              //  320x240 device, only the even lines are
+	                              //  rendered. This option will take that one
+	                              //  step further and only render half the even
+	                              //  even lines one frame, and then the other half.
+	uint8_t frameskip_count:3;    // Frame skip (0..7)
+#endif
 };
 
-///////////////////////////////////////////////////////////////////////////////
-//  Compile Options
+extern gpu_unai_config_t gpu_unai_config_ext;
 
-//#define ENABLE_GPU_NULL_SUPPORT   // Enables NullGPU support
-//#define ENABLE_GPU_LOG_SUPPORT    // Enables gpu logger, very slow only for windows debugging
+// TODO: clean up show_fps frontend option
+extern  bool show_fps;
 
-///////////////////////////////////////////////////////////////////////////////
-#endif  // NEW_GPU_H
+#endif // GPU_UNAI_GPU_H
diff --git a/plugins/gpu_unai/gpu_blit.h b/plugins/gpu_unai/gpu_blit.h
index 35cd056e..e93f12ff 100644
--- a/plugins/gpu_unai/gpu_blit.h
+++ b/plugins/gpu_unai/gpu_blit.h
@@ -32,10 +32,10 @@
 ///////////////////////////////////////////////////////////////////////////////
 //  GPU Blitting code with rescale and interlace support.
 
-INLINE void GPU_BlitWW(const void* src, u16* dst16, u32 isRGB24)
+INLINE void GPU_BlitWW(const void* src, u16* dst16, bool isRGB24)
 {
 	u32 uCount;
-	if(isRGB24 == 0)
+	if(!isRGB24)
 	{
 		#ifndef USE_BGR15
 			uCount = 20;
@@ -85,10 +85,10 @@ INLINE void GPU_BlitWW(const void* src, u16* dst16, u32 isRGB24)
 	}
 }
 
-INLINE void GPU_BlitWWSWWSWS(const void* src, u16* dst16, u32 isRGB24)
+INLINE void GPU_BlitWWSWWSWS(const void* src, u16* dst16, bool isRGB24)
 {
 	u32 uCount;
-	if(isRGB24 == 0)
+	if(!isRGB24)
 	{
 		#ifndef USE_BGR15
 			uCount = 32;
@@ -145,10 +145,10 @@ INLINE void GPU_BlitWWSWWSWS(const void* src, u16* dst16, u32 isRGB24)
 	}
 }
 
-INLINE void GPU_BlitWWWWWS(const void* src, u16* dst16, u32 isRGB24)
+INLINE void GPU_BlitWWWWWS(const void* src, u16* dst16, bool isRGB24)
 {
 	u32 uCount;
-	if(isRGB24 == 0)
+	if(!isRGB24)
 	{
 		#ifndef USE_BGR15
 			uCount = 32;
@@ -201,10 +201,10 @@ INLINE void GPU_BlitWWWWWS(const void* src, u16* dst16, u32 isRGB24)
 	}
 }
 
-INLINE void GPU_BlitWWWWWWWWS(const void* src, u16* dst16, u32 isRGB24, u32 uClip_src)
+INLINE void GPU_BlitWWWWWWWWS(const void* src, u16* dst16, bool isRGB24, u32 uClip_src)
 {
 	u32 uCount;
-	if(isRGB24 == 0)
+	if(!isRGB24)
 	{
 		#ifndef USE_BGR15
 			uCount = 20;
@@ -274,10 +274,10 @@ INLINE void GPU_BlitWWWWWWWWS(const void* src, u16* dst16, u32 isRGB24, u32 uCli
 	}
 }
 
-INLINE void GPU_BlitWWDWW(const void* src, u16* dst16, u32 isRGB24)
+INLINE void GPU_BlitWWDWW(const void* src, u16* dst16, bool isRGB24)
 {
 	u32 uCount;
-	if(isRGB24 == 0)
+	if(!isRGB24)
 	{
 		#ifndef USE_BGR15
 			uCount = 32;
@@ -331,10 +331,10 @@ INLINE void GPU_BlitWWDWW(const void* src, u16* dst16, u32 isRGB24)
 }
 
 
-INLINE void GPU_BlitWS(const void* src, u16* dst16, u32 isRGB24)
+INLINE void GPU_BlitWS(const void* src, u16* dst16, bool isRGB24)
 {
 	u32 uCount;
-	if(isRGB24 == 0)
+	if(!isRGB24)
 	{
 		#ifndef USE_BGR15
 			uCount = 20;
diff --git a/plugins/gpu_unai/gpu_command.h b/plugins/gpu_unai/gpu_command.h
index d6e7a742..e39fe3c5 100644
--- a/plugins/gpu_unai/gpu_command.h
+++ b/plugins/gpu_unai/gpu_command.h
@@ -1,6 +1,7 @@
 /***************************************************************************
 *   Copyright (C) 2010 PCSX4ALL Team                                      *
 *   Copyright (C) 2010 Unai                                               *
+*   Copyright (C) 2016 Senquack (dansilsby <AT> gmail <DOT> com)          *
 *                                                                         *
 *   This program is free software; you can redistribute it and/or modify  *
 *   it under the terms of the GNU General Public License as published by  *
@@ -19,34 +20,35 @@
 ***************************************************************************/
 
 ///////////////////////////////////////////////////////////////////////////////
-INLINE void gpuSetTexture(u16 tpage)
+void gpuSetTexture(u16 tpage)
 {
-	u32 tp;
-	u32 tx, ty;
-	GPU_GP1 = (GPU_GP1 & ~0x1FF) | (tpage & 0x1FF);
+	u32 tmode, tx, ty;
+	gpu_unai.GPU_GP1 = (gpu_unai.GPU_GP1 & ~0x1FF) | (tpage & 0x1FF);
+	gpu_unai.TextureWindow[0]&= ~gpu_unai.TextureWindow[2];
+	gpu_unai.TextureWindow[1]&= ~gpu_unai.TextureWindow[3];
 
-	TextureWindow[0]&= ~TextureWindow[2];
-	TextureWindow[1]&= ~TextureWindow[3];
+	tmode = (tpage >> 7) & 3;  // 16bpp, 8bpp, or 4bpp texture colors?
+	                           // 0: 4bpp     1: 8bpp     2/3: 16bpp
+
+	// Nocash PSX docs state setting of 3 is same as setting of 2 (16bpp):
+	// Note: DrHell assumes 3 is same as 0.. TODO: verify which is correct?
+	if (tmode == 3) tmode = 2;
 
-	tp = (tpage >> 7) & 3;
 	tx = (tpage & 0x0F) << 6;
 	ty = (tpage & 0x10) << 4;
-	if (tp == 3) tp = 2;
 
-	tx += (TextureWindow[0] >> (2 - tp));
-	ty += TextureWindow[1];
+	tx += (gpu_unai.TextureWindow[0] >> (2 - tmode));
+	ty += gpu_unai.TextureWindow[1];
 	
-	BLEND_MODE  = (((tpage>>5)&0x3)     ) << 3;
-	TEXT_MODE   = (((tpage>>7)&0x3) + 1 ) << 5; // +1 el cero no lo usamos
-
-	TBA = &((u16*)GPU_FrameBuffer)[FRAME_OFFSET(tx, ty)];
-
+	gpu_unai.BLEND_MODE  = ((tpage>>5) & 3) << 3;
+	gpu_unai.TEXT_MODE   = (tmode + 1) << 5; // gpu_unai.TEXT_MODE should be values 1..3, so add one
+	gpu_unai.TBA = &((u16*)gpu_unai.vram)[FRAME_OFFSET(tx, ty)];
 }
 
 ///////////////////////////////////////////////////////////////////////////////
-INLINE void gpuSetCLUT(u16 clut)
+inline void gpuSetCLUT(u16 clut)
 {
-	CBA = &((u16*)GPU_FrameBuffer)[(clut & 0x7FFF) << 4];
+	gpu_unai.CBA = &((u16*)gpu_unai.vram)[(clut & 0x7FFF) << 4];
 }
 
 #ifdef  ENABLE_GPU_NULL_SUPPORT
@@ -61,159 +63,305 @@ INLINE void gpuSetCLUT(u16 clut)
 #define DO_LOG(expr) {}
 #endif
 
-#define Blending (((PRIM&0x2)&&(blend))?(PRIM&0x2):0)
-#define Blending_Mode (((PRIM&0x2)&&(blend))?BLEND_MODE:0)
-#define Lighting (((~PRIM)&0x1)&&(light))
+#define Blending      (((PRIM&0x2) && BlendingEnabled()) ? (PRIM&0x2) : 0)
+#define Blending_Mode (((PRIM&0x2) && BlendingEnabled()) ? gpu_unai.BLEND_MODE : 0)
+#define Lighting      (((~PRIM)&0x1) && LightingEnabled())
+// Dithering applies only to Gouraud-shaded polys or texture-blended polys:
+#define Dithering     (((((~PRIM)&0x1) || (PRIM&0x10)) && DitheringEnabled()) ?            \
+                       (ForcedDitheringEnabled() ? (1<<9) : (gpu_unai.GPU_GP1 & (1 << 9))) \
+                       : 0)
+
+///////////////////////////////////////////////////////////////////////////////
+//Now handled by Rearmed's gpulib and gpu_unai/gpulib_if.cpp:
+///////////////////////////////////////////////////////////////////////////////
+#ifndef USE_GPULIB
+
+// Handles GP0 draw settings commands 0xE1...0xE6
+static void gpuGP0Cmd_0xEx(gpu_unai_t &gpu_unai, u32 cmd_word)
+{
+	// Assume incoming GP0 command is 0xE1..0xE6, convert to 1..6
+	u8 num = (cmd_word >> 24) & 7;
+	switch (num) {
+		case 1: {
+			// GP0(E1h) - Draw Mode setting (aka "Texpage")
+			DO_LOG(("GP0(0xE1) DrawMode TexPage(0x%x)\n", cmd_word));
+			u32 cur_texpage = gpu_unai.GPU_GP1 & 0x7FF;
+			u32 new_texpage = cmd_word & 0x7FF;
+			if (cur_texpage != new_texpage) {
+				gpu_unai.GPU_GP1 = (gpu_unai.GPU_GP1 & ~0x7FF) | new_texpage;
+				gpuSetTexture(gpu_unai.GPU_GP1);
+			}
+		} break;
+
+		case 2: {
+			// GP0(E2h) - Texture Window setting
+			DO_LOG(("GP0(0xE2) TextureWindow(0x%x)\n", cmd_word));
+			if (cmd_word != gpu_unai.TextureWindowCur) {
+				static const u8 TextureMask[32] = {
+					255, 7, 15, 7, 31, 7, 15, 7, 63, 7, 15, 7, 31, 7, 15, 7,
+					127, 7, 15, 7, 31, 7, 15, 7, 63, 7, 15, 7, 31, 7, 15, 7
+				};
+				gpu_unai.TextureWindowCur = cmd_word;
+				gpu_unai.TextureWindow[0] = ((cmd_word >> 10) & 0x1F) << 3;
+				gpu_unai.TextureWindow[1] = ((cmd_word >> 15) & 0x1F) << 3;
+				gpu_unai.TextureWindow[2] = TextureMask[(cmd_word >> 0) & 0x1F];
+				gpu_unai.TextureWindow[3] = TextureMask[(cmd_word >> 5) & 0x1F];
+				gpu_unai.TextureWindow[0] &= ~gpu_unai.TextureWindow[2];
+				gpu_unai.TextureWindow[1] &= ~gpu_unai.TextureWindow[3];
+
+				// Inner loop vars must be updated whenever texture window is changed:
+				const u32 fb = FIXED_BITS;  // # of fractional fixed-pt bits of u4/v4
+				gpu_unai.u_msk = (((u32)gpu_unai.TextureWindow[2]) << fb) | ((1 << fb) - 1);
+				gpu_unai.v_msk = (((u32)gpu_unai.TextureWindow[3]) << fb) | ((1 << fb) - 1);
+
+				gpuSetTexture(gpu_unai.GPU_GP1);
+			}
+		} break;
+
+		case 3: {
+			// GP0(E3h) - Set Drawing Area top left (X1,Y1)
+			DO_LOG(("GP0(0xE3) DrawingArea Pos(0x%x)\n", cmd_word));
+			gpu_unai.DrawingArea[0] = cmd_word         & 0x3FF;
+			gpu_unai.DrawingArea[1] = (cmd_word >> 10) & 0x3FF;
+		} break;
+
+		case 4: {
+			// GP0(E4h) - Set Drawing Area bottom right (X2,Y2)
+			DO_LOG(("GP0(0xE4) DrawingArea Size(0x%x)\n", cmd_word));
+			gpu_unai.DrawingArea[2] = (cmd_word         & 0x3FF) + 1;
+			gpu_unai.DrawingArea[3] = ((cmd_word >> 10) & 0x3FF) + 1;
+		} break;
+
+		case 5: {
+			// GP0(E5h) - Set Drawing Offset (X,Y)
+			DO_LOG(("GP0(0xE5) DrawingOffset(0x%x)\n", cmd_word));
+			gpu_unai.DrawingOffset[0] = ((s32)cmd_word<<(32-11))>>(32-11);
+			gpu_unai.DrawingOffset[1] = ((s32)cmd_word<<(32-22))>>(32-11);
+		} break;
+
+		case 6: {
+			// GP0(E6h) - Mask Bit Setting
+			DO_LOG(("GP0(0xE6) SetMask(0x%x)\n", cmd_word));
+			gpu_unai.Masking  = (cmd_word & 0x2) <<  1;
+			gpu_unai.PixelMSB = (cmd_word & 0x1) <<  8;
+		} break;
+	}
+}
 
 void gpuSendPacketFunction(const int PRIM)
 {
 	//printf("0x%x\n",PRIM);
 
+	//senquack - TODO: optimize this (packet pointer union as prim draw parameter
+	// introduced as optimization for gpulib command-list processing)
+	PtrUnion packet = { .ptr = (void*)&gpu_unai.PacketBuffer };
+
 	switch (PRIM)
 	{
-		case 0x02:
+		case 0x02: {
 			NULL_GPU();
-			gpuClearImage();    //  prim handles updateLace && skip
+			gpuClearImage(packet);    //  prim handles updateLace && skip
+			gpu_unai.fb_dirty = true;
 			DO_LOG(("gpuClearImage(0x%x)\n",PRIM));
-			break;
+		} break;
+
 		case 0x20:
 		case 0x21:
 		case 0x22:
-		case 0x23:
-			if (!isSkip)
+		case 0x23: {          // Monochrome 3-pt poly
+			if (!gpu_unai.frameskip.skipGPU)
 			{
 				NULL_GPU();
-				gpuDrawF3(gpuPolySpanDrivers [Blending_Mode | Masking | Blending | PixelMSB]);
-				DO_LOG(("gpuDrawF3(0x%x)\n",PRIM));
+				PP driver = gpuPolySpanDrivers[
+					(gpu_unai.blit_mask?1024:0) |
+					Blending_Mode |
+					gpu_unai.Masking | Blending | gpu_unai.PixelMSB
+				];
+				gpuDrawPolyF(packet, driver, false);
+				gpu_unai.fb_dirty = true;
+				DO_LOG(("gpuDrawPolyF(0x%x)\n",PRIM));
 			}
-			break;
+		} break;
+
 		case 0x24:
 		case 0x25:
 		case 0x26:
-		case 0x27:
-			if (!isSkip)
+		case 0x27: {          // Textured 3-pt poly
+			if (!gpu_unai.frameskip.skipGPU)
 			{
 				NULL_GPU();
-				gpuSetCLUT    (PacketBuffer.U4[2] >> 16);
-				gpuSetTexture (PacketBuffer.U4[4] >> 16);
-				if ((PacketBuffer.U1[0]>0x5F) && (PacketBuffer.U1[1]>0x5F) && (PacketBuffer.U1[2]>0x5F))
-					gpuDrawFT3(gpuPolySpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | PixelMSB]);
-				else
-					gpuDrawFT3(gpuPolySpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | Lighting | PixelMSB]);
-				DO_LOG(("gpuDrawFT3(0x%x)\n",PRIM));
+				gpuSetCLUT    (gpu_unai.PacketBuffer.U4[2] >> 16);
+				gpuSetTexture (gpu_unai.PacketBuffer.U4[4] >> 16);
+
+				u32 driver_idx =
+					(gpu_unai.blit_mask?1024:0) |
+					Dithering |
+					Blending_Mode | gpu_unai.TEXT_MODE |
+					gpu_unai.Masking | Blending | gpu_unai.PixelMSB;
+
+				if (!FastLightingEnabled()) {
+					driver_idx |= Lighting;
+				} else {
+					if (!((gpu_unai.PacketBuffer.U1[0]>0x5F) && (gpu_unai.PacketBuffer.U1[1]>0x5F) && (gpu_unai.PacketBuffer.U1[2]>0x5F)))
+						driver_idx |= Lighting;
+				}
+
+				PP driver = gpuPolySpanDrivers[driver_idx];
+				gpuDrawPolyFT(packet, driver, false);
+				gpu_unai.fb_dirty = true;
+				DO_LOG(("gpuDrawPolyFT(0x%x)\n",PRIM));
 			}
-			break;
+		} break;
+
 		case 0x28:
 		case 0x29:
 		case 0x2A:
-		case 0x2B:
-			if (!isSkip)
+		case 0x2B: {          // Monochrome 4-pt poly
+			if (!gpu_unai.frameskip.skipGPU)
 			{
 				NULL_GPU();
-				const PP gpuPolySpanDriver  = gpuPolySpanDrivers [Blending_Mode | Masking | Blending | PixelMSB];
-				//--PacketBuffer.S2[6];
-				gpuDrawF3(gpuPolySpanDriver);
-				PacketBuffer.U4[1] = PacketBuffer.U4[4];
-				//--PacketBuffer.S2[2];
-				gpuDrawF3(gpuPolySpanDriver);
-				DO_LOG(("gpuDrawF4(0x%x)\n",PRIM));
+				PP driver = gpuPolySpanDrivers[
+					(gpu_unai.blit_mask?1024:0) |
+					Blending_Mode |
+					gpu_unai.Masking | Blending | gpu_unai.PixelMSB
+				];
+				gpuDrawPolyF(packet, driver, true); // is_quad = true
+				gpu_unai.fb_dirty = true;
+				DO_LOG(("gpuDrawPolyF(0x%x) (4-pt QUAD)\n",PRIM));
 			}
-			break;
+		} break;
+
 		case 0x2C:
 		case 0x2D:
 		case 0x2E:
-		case 0x2F:
-			if (!isSkip)
+		case 0x2F: {          // Textured 4-pt poly
+			if (!gpu_unai.frameskip.skipGPU)
 			{
 				NULL_GPU();
-				gpuSetCLUT    (PacketBuffer.U4[2] >> 16);
-				gpuSetTexture (PacketBuffer.U4[4] >> 16);
-				PP gpuPolySpanDriver;
-				if ((PacketBuffer.U1[0]>0x5F) && (PacketBuffer.U1[1]>0x5F) && (PacketBuffer.U1[2]>0x5F))
-					gpuPolySpanDriver = gpuPolySpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | PixelMSB];
-				else
-					gpuPolySpanDriver = gpuPolySpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | Lighting | PixelMSB];
-				//--PacketBuffer.S2[6];
-				gpuDrawFT3(gpuPolySpanDriver);
-				PacketBuffer.U4[1] = PacketBuffer.U4[7];
-				PacketBuffer.U4[2] = PacketBuffer.U4[8];
-				//--PacketBuffer.S2[2];
-				gpuDrawFT3(gpuPolySpanDriver);
-				DO_LOG(("gpuDrawFT4(0x%x)\n",PRIM));
+				gpuSetCLUT    (gpu_unai.PacketBuffer.U4[2] >> 16);
+				gpuSetTexture (gpu_unai.PacketBuffer.U4[4] >> 16);
+
+				u32 driver_idx =
+					(gpu_unai.blit_mask?1024:0) |
+					Dithering |
+					Blending_Mode | gpu_unai.TEXT_MODE |
+					gpu_unai.Masking | Blending | gpu_unai.PixelMSB;
+
+				if (!FastLightingEnabled()) {
+					driver_idx |= Lighting;
+				} else {
+					if (!((gpu_unai.PacketBuffer.U1[0]>0x5F) && (gpu_unai.PacketBuffer.U1[1]>0x5F) && (gpu_unai.PacketBuffer.U1[2]>0x5F)))
+						driver_idx |= Lighting;
+				}
+
+				PP driver = gpuPolySpanDrivers[driver_idx];
+				gpuDrawPolyFT(packet, driver, true); // is_quad = true
+				gpu_unai.fb_dirty = true;
+				DO_LOG(("gpuDrawPolyFT(0x%x) (4-pt QUAD)\n",PRIM));
 			}
-			break;
+		} break;
+
 		case 0x30:
 		case 0x31:
 		case 0x32:
-		case 0x33:
-			if (!isSkip)
+		case 0x33: {          // Gouraud-shaded 3-pt poly
+			if (!gpu_unai.frameskip.skipGPU)
 			{
 				NULL_GPU();
-				gpuDrawG3(gpuPolySpanDrivers [Blending_Mode | Masking | Blending | 129 | PixelMSB]);
-				DO_LOG(("gpuDrawG3(0x%x)\n",PRIM));
+				//NOTE: The '129' here is CF_GOURAUD | CF_LIGHT, however
+				// this is an untextured poly, so CF_LIGHT (texture blend)
+				// shouldn't apply. Until the original array of template
+				// instantiation ptrs is fixed, we're stuck with this. (TODO)
+				PP driver = gpuPolySpanDrivers[
+					(gpu_unai.blit_mask?1024:0) |
+					Dithering |
+					Blending_Mode |
+					gpu_unai.Masking | Blending | 129 | gpu_unai.PixelMSB
+				];
+				gpuDrawPolyG(packet, driver, false);
+				gpu_unai.fb_dirty = true;
+				DO_LOG(("gpuDrawPolyG(0x%x)\n",PRIM));
 			}
-			break;
+		} break;
+
 		case 0x34:
 		case 0x35:
 		case 0x36:
-		case 0x37:
-			if (!isSkip)
+		case 0x37: {          // Gouraud-shaded, textured 3-pt poly
+			if (!gpu_unai.frameskip.skipGPU)
 			{
 				NULL_GPU();
-				gpuSetCLUT    (PacketBuffer.U4[2] >> 16);
-				gpuSetTexture (PacketBuffer.U4[5] >> 16);
-				gpuDrawGT3(gpuPolySpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | ((Lighting)?129:0) | PixelMSB]);
-				DO_LOG(("gpuDrawGT3(0x%x)\n",PRIM));
+				gpuSetCLUT    (gpu_unai.PacketBuffer.U4[2] >> 16);
+				gpuSetTexture (gpu_unai.PacketBuffer.U4[5] >> 16);
+				PP driver = gpuPolySpanDrivers[
+					(gpu_unai.blit_mask?1024:0) |
+					Dithering |
+					Blending_Mode | gpu_unai.TEXT_MODE |
+					gpu_unai.Masking | Blending | ((Lighting)?129:0) | gpu_unai.PixelMSB
+				];
+				gpuDrawPolyGT(packet, driver, false);
+				gpu_unai.fb_dirty = true;
+				DO_LOG(("gpuDrawPolyGT(0x%x)\n",PRIM));
 			}
-			break;
+		} break;
+
 		case 0x38:
 		case 0x39:
 		case 0x3A:
-		case 0x3B:
-			if (!isSkip)
+		case 0x3B: {          // Gouraud-shaded 4-pt poly
+			if (!gpu_unai.frameskip.skipGPU)
 			{
 				NULL_GPU();
-				const PP gpuPolySpanDriver  = gpuPolySpanDrivers [Blending_Mode | Masking | Blending | 129 | PixelMSB];
-				//--PacketBuffer.S2[6];
-				gpuDrawG3(gpuPolySpanDriver);
-				PacketBuffer.U4[0] = PacketBuffer.U4[6];
-				PacketBuffer.U4[1] = PacketBuffer.U4[7];
-				//--PacketBuffer.S2[2];
-				gpuDrawG3(gpuPolySpanDriver);
-				DO_LOG(("gpuDrawG4(0x%x)\n",PRIM));
+				// See notes regarding '129' for 0x30..0x33 further above -senquack
+				PP driver = gpuPolySpanDrivers[
+					(gpu_unai.blit_mask?1024:0) |
+					Dithering |
+					Blending_Mode |
+					gpu_unai.Masking | Blending | 129 | gpu_unai.PixelMSB
+				];
+				gpuDrawPolyG(packet, driver, true); // is_quad = true
+				gpu_unai.fb_dirty = true;
+				DO_LOG(("gpuDrawPolyG(0x%x) (4-pt QUAD)\n",PRIM));
 			}
-			break;
+		} break;
+
 		case 0x3C:
 		case 0x3D:
 		case 0x3E:
-		case 0x3F:
-			if (!isSkip)
+		case 0x3F: {          // Gouraud-shaded, textured 4-pt poly
+			if (!gpu_unai.frameskip.skipGPU)
 			{
 				NULL_GPU();
-				gpuSetCLUT    (PacketBuffer.U4[2] >> 16);
-				gpuSetTexture (PacketBuffer.U4[5] >> 16);
-				const PP gpuPolySpanDriver  = gpuPolySpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | ((Lighting)?129:0) | PixelMSB];
-				//--PacketBuffer.S2[6];
-				gpuDrawGT3(gpuPolySpanDriver);
-				PacketBuffer.U4[0] = PacketBuffer.U4[9];
-				PacketBuffer.U4[1] = PacketBuffer.U4[10];
-				PacketBuffer.U4[2] = PacketBuffer.U4[11];
-				//--PacketBuffer.S2[2];
-				gpuDrawGT3(gpuPolySpanDriver);
-				DO_LOG(("gpuDrawGT4(0x%x)\n",PRIM));
+				gpuSetCLUT    (gpu_unai.PacketBuffer.U4[2] >> 16);
+				gpuSetTexture (gpu_unai.PacketBuffer.U4[5] >> 16);
+				PP driver = gpuPolySpanDrivers[
+					(gpu_unai.blit_mask?1024:0) |
+					Dithering |
+					Blending_Mode | gpu_unai.TEXT_MODE |
+					gpu_unai.Masking | Blending | ((Lighting)?129:0) | gpu_unai.PixelMSB
+				];
+				gpuDrawPolyGT(packet, driver, true); // is_quad = true
+				gpu_unai.fb_dirty = true;
+				DO_LOG(("gpuDrawPolyGT(0x%x) (4-pt QUAD)\n",PRIM));
 			}
-			break;
+		} break;
+
 		case 0x40:
 		case 0x41:
 		case 0x42:
-		case 0x43:
-			if (!isSkip)
+		case 0x43: {          // Monochrome line
+			if (!gpu_unai.frameskip.skipGPU)
 			{
 				NULL_GPU();
-				gpuDrawLF(gpuPixelDrivers [ (Blending_Mode | Masking | Blending | (PixelMSB>>3)) >> 1]);
-				DO_LOG(("gpuDrawLF(0x%x)\n",PRIM));
+				// Shift index right by one, as untextured prims don't use lighting
+				u32 driver_idx = (Blending_Mode | gpu_unai.Masking | Blending | (gpu_unai.PixelMSB>>3)) >> 1;
+				PSD driver = gpuPixelSpanDrivers[driver_idx];
+				gpuDrawLineF(packet, driver);
+				gpu_unai.fb_dirty = true;
+				DO_LOG(("gpuDrawLineF(0x%x)\n",PRIM));
 			}
-			break;
+		} break;
+
 		case 0x48:
 		case 0x49:
 		case 0x4A:
@@ -221,32 +369,44 @@ void gpuSendPacketFunction(const int PRIM)
 		case 0x4C:
 		case 0x4D:
 		case 0x4E:
-		case 0x4F:
-			if (!isSkip)
+		case 0x4F: { // Monochrome line strip
+			if (!gpu_unai.frameskip.skipGPU)
 			{
 				NULL_GPU();
-				gpuDrawLF(gpuPixelDrivers [ (Blending_Mode | Masking | Blending | (PixelMSB>>3)) >> 1]);
-				DO_LOG(("gpuDrawLF(0x%x)\n",PRIM));
+				// Shift index right by one, as untextured prims don't use lighting
+				u32 driver_idx = (Blending_Mode | gpu_unai.Masking | Blending | (gpu_unai.PixelMSB>>3)) >> 1;
+				PSD driver = gpuPixelSpanDrivers[driver_idx];
+				gpuDrawLineF(packet, driver);
+				gpu_unai.fb_dirty = true;
+				DO_LOG(("gpuDrawLineF(0x%x)\n",PRIM));
 			}
-			if ((PacketBuffer.U4[3] & 0xF000F000) != 0x50005000)
+			if ((gpu_unai.PacketBuffer.U4[3] & 0xF000F000) != 0x50005000)
 			{
-				PacketBuffer.U4[1] = PacketBuffer.U4[2];
-				PacketBuffer.U4[2] = PacketBuffer.U4[3];
-				PacketCount = 1;
-				PacketIndex = 3;
+				gpu_unai.PacketBuffer.U4[1] = gpu_unai.PacketBuffer.U4[2];
+				gpu_unai.PacketBuffer.U4[2] = gpu_unai.PacketBuffer.U4[3];
+				gpu_unai.PacketCount = 1;
+				gpu_unai.PacketIndex = 3;
 			}
-			break;
+		} break;
+
 		case 0x50:
 		case 0x51:
 		case 0x52:
-		case 0x53:
-			if (!isSkip)
+		case 0x53: {          // Gouraud-shaded line
+			if (!gpu_unai.frameskip.skipGPU)
 			{
 				NULL_GPU();
-				gpuDrawLG(gpuPixelDrivers [ (Blending_Mode | Masking | Blending | (PixelMSB>>3)) >> 1]);
-				DO_LOG(("gpuDrawLG(0x%x)\n",PRIM));
+				// Shift index right by one, as untextured prims don't use lighting
+				u32 driver_idx = (Blending_Mode | gpu_unai.Masking | Blending | (gpu_unai.PixelMSB>>3)) >> 1;
+				// Index MSB selects Gouraud-shaded PixelSpanDriver:
+				driver_idx |= (1 << 5);
+				PSD driver = gpuPixelSpanDrivers[driver_idx];
+				gpuDrawLineG(packet, driver);
+				gpu_unai.fb_dirty = true;
+				DO_LOG(("gpuDrawLineG(0x%x)\n",PRIM));
 			}
-			break;
+		} break;
+
 		case 0x58:
 		case 0x59:
 		case 0x5A:
@@ -254,204 +414,203 @@ void gpuSendPacketFunction(const int PRIM)
 		case 0x5C:
 		case 0x5D:
 		case 0x5E:
-		case 0x5F:
-			if (!isSkip)
+		case 0x5F: { // Gouraud-shaded line strip
+			if (!gpu_unai.frameskip.skipGPU)
 			{
 				NULL_GPU();
-				gpuDrawLG(gpuPixelDrivers [ (Blending_Mode | Masking | Blending | (PixelMSB>>3)) >> 1]);
-				DO_LOG(("gpuDrawLG(0x%x)\n",PRIM));
+				// Shift index right by one, as untextured prims don't use lighting
+				u32 driver_idx = (Blending_Mode | gpu_unai.Masking | Blending | (gpu_unai.PixelMSB>>3)) >> 1;
+				// Index MSB selects Gouraud-shaded PixelSpanDriver:
+				driver_idx |= (1 << 5);
+				PSD driver = gpuPixelSpanDrivers[driver_idx];
+				gpuDrawLineG(packet, driver);
+				gpu_unai.fb_dirty = true;
+				DO_LOG(("gpuDrawLineG(0x%x)\n",PRIM));
 			}
-			if ((PacketBuffer.U4[4] & 0xF000F000) != 0x50005000)
+			if ((gpu_unai.PacketBuffer.U4[4] & 0xF000F000) != 0x50005000)
 			{
-				PacketBuffer.U1[3 + (2 * 4)] = PacketBuffer.U1[3 + (0 * 4)];
-				PacketBuffer.U4[0] = PacketBuffer.U4[2];
-				PacketBuffer.U4[1] = PacketBuffer.U4[3];
-				PacketBuffer.U4[2] = PacketBuffer.U4[4];
-				PacketCount = 2;
-				PacketIndex = 3;
+				gpu_unai.PacketBuffer.U1[3 + (2 * 4)] = gpu_unai.PacketBuffer.U1[3 + (0 * 4)];
+				gpu_unai.PacketBuffer.U4[0] = gpu_unai.PacketBuffer.U4[2];
+				gpu_unai.PacketBuffer.U4[1] = gpu_unai.PacketBuffer.U4[3];
+				gpu_unai.PacketBuffer.U4[2] = gpu_unai.PacketBuffer.U4[4];
+				gpu_unai.PacketCount = 2;
+				gpu_unai.PacketIndex = 3;
 			}
-			break;
+		} break;
+
 		case 0x60:
 		case 0x61:
 		case 0x62:
-		case 0x63:
-			if (!isSkip)
+		case 0x63: {          // Monochrome rectangle (variable size)
+			if (!gpu_unai.frameskip.skipGPU)
 			{
 				NULL_GPU();
-				gpuDrawT(gpuTileSpanDrivers [Blending_Mode | Masking | Blending | (PixelMSB>>3)]);
+				PT driver = gpuTileSpanDrivers[(Blending_Mode | gpu_unai.Masking | Blending | (gpu_unai.PixelMSB>>3)) >> 1];
+				gpuDrawT(packet, driver);
+				gpu_unai.fb_dirty = true;
 				DO_LOG(("gpuDrawT(0x%x)\n",PRIM));
 			}
-			break;
+		} break;
+
 		case 0x64:
 		case 0x65:
 		case 0x66:
-		case 0x67:
-			if (!isSkip)
+		case 0x67: {          // Textured rectangle (variable size)
+			if (!gpu_unai.frameskip.skipGPU)
 			{
 				NULL_GPU();
-				gpuSetCLUT    (PacketBuffer.U4[2] >> 16);
-				gpuSetTexture (GPU_GP1);
-				if ((PacketBuffer.U1[0]>0x5F) && (PacketBuffer.U1[1]>0x5F) && (PacketBuffer.U1[2]>0x5F))
-					gpuDrawS(gpuSpriteSpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | (enableAbbeyHack<<7)  | PixelMSB]);
-				else
-					gpuDrawS(gpuSpriteSpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | Lighting | (enableAbbeyHack<<7)  | PixelMSB]);
+				gpuSetCLUT    (gpu_unai.PacketBuffer.U4[2] >> 16);
+				u32 driver_idx = Blending_Mode | gpu_unai.TEXT_MODE | gpu_unai.Masking | Blending | (gpu_unai.PixelMSB>>1);
+
+				// This fixes Silent Hill running animation on loading screens:
+				// (On PSX, color values 0x00-0x7F darken the source texture's color,
+				//  0x81-FF lighten textures (ultimately clamped to 0x1F),
+				//  0x80 leaves source texture color unchanged, HOWEVER,
+				//   gpu_unai uses a simple lighting LUT whereby only the upper
+				//   5 bits of an 8-bit color are used, so 0x80-0x87 all behave as
+				//   0x80.
+				// 
+				// NOTE: I've changed all textured sprite draw commands here and
+				//  elsewhere to use proper behavior, but left poly commands
+				//  alone, I don't want to slow rendering down too much. (TODO)
+				//if ((gpu_unai.PacketBuffer.U1[0]>0x5F) && (gpu_unai.PacketBuffer.U1[1]>0x5F) && (gpu_unai.PacketBuffer.U1[2]>0x5F))
+				// Strip lower 3 bits of each color and determine if lighting should be used:
+				if ((gpu_unai.PacketBuffer.U4[0] & 0xF8F8F8) != 0x808080)
+					driver_idx |= Lighting;
+				PS driver = gpuSpriteSpanDrivers[driver_idx];
+				gpuDrawS(packet, driver);
+				gpu_unai.fb_dirty = true;
 				DO_LOG(("gpuDrawS(0x%x)\n",PRIM));
 			}
-			break;
+		} break;
+
 		case 0x68:
 		case 0x69:
 		case 0x6A:
-		case 0x6B:
-			if (!isSkip)
+		case 0x6B: {          // Monochrome rectangle (1x1 dot)
+			if (!gpu_unai.frameskip.skipGPU)
 			{
 				NULL_GPU();
-				PacketBuffer.U4[2] = 0x00010001;
-				gpuDrawT(gpuTileSpanDrivers [Blending_Mode | Masking | Blending | (PixelMSB>>3)]);
+				gpu_unai.PacketBuffer.U4[2] = 0x00010001;
+				PT driver = gpuTileSpanDrivers[(Blending_Mode | gpu_unai.Masking | Blending | (gpu_unai.PixelMSB>>3)) >> 1];
+				gpuDrawT(packet, driver);
+				gpu_unai.fb_dirty = true;
 				DO_LOG(("gpuDrawT(0x%x)\n",PRIM));
 			}
-			break;
+		} break;
+
 		case 0x70:
 		case 0x71:
 		case 0x72:
-		case 0x73:
-			if (!isSkip)
+		case 0x73: {          // Monochrome rectangle (8x8)
+			if (!gpu_unai.frameskip.skipGPU)
 			{
 				NULL_GPU();
-				PacketBuffer.U4[2] = 0x00080008;
-				gpuDrawT(gpuTileSpanDrivers [Blending_Mode | Masking | Blending | (PixelMSB>>3)]);
+				gpu_unai.PacketBuffer.U4[2] = 0x00080008;
+				PT driver = gpuTileSpanDrivers[(Blending_Mode | gpu_unai.Masking | Blending | (gpu_unai.PixelMSB>>3)) >> 1];
+				gpuDrawT(packet, driver);
+				gpu_unai.fb_dirty = true;
 				DO_LOG(("gpuDrawT(0x%x)\n",PRIM));
 			}
-			break;
+		} break;
+
 		case 0x74:
 		case 0x75:
 		case 0x76:
-		case 0x77:
-			if (!isSkip)
+		case 0x77: {          // Textured rectangle (8x8)
+			if (!gpu_unai.frameskip.skipGPU)
 			{
 				NULL_GPU();
-				PacketBuffer.U4[3] = 0x00080008;
-				gpuSetCLUT    (PacketBuffer.U4[2] >> 16);
-				gpuSetTexture (GPU_GP1);
-				if ((PacketBuffer.U1[0]>0x5F) && (PacketBuffer.U1[1]>0x5F) && (PacketBuffer.U1[2]>0x5F))
-					gpuDrawS(gpuSpriteSpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | (enableAbbeyHack<<7)  | PixelMSB]);
-				else
-					gpuDrawS(gpuSpriteSpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | Lighting | (enableAbbeyHack<<7)  | PixelMSB]);
+				gpu_unai.PacketBuffer.U4[3] = 0x00080008;
+				gpuSetCLUT    (gpu_unai.PacketBuffer.U4[2] >> 16);
+				u32 driver_idx = Blending_Mode | gpu_unai.TEXT_MODE | gpu_unai.Masking | Blending | (gpu_unai.PixelMSB>>1);
+
+				//senquack - Only color 808080h-878787h allows skipping lighting calculation:
+				//if ((gpu_unai.PacketBuffer.U1[0]>0x5F) && (gpu_unai.PacketBuffer.U1[1]>0x5F) && (gpu_unai.PacketBuffer.U1[2]>0x5F))
+				// Strip lower 3 bits of each color and determine if lighting should be used:
+				if ((gpu_unai.PacketBuffer.U4[0] & 0xF8F8F8) != 0x808080)
+					driver_idx |= Lighting;
+				PS driver = gpuSpriteSpanDrivers[driver_idx];
+				gpuDrawS(packet, driver);
+				gpu_unai.fb_dirty = true;
 				DO_LOG(("gpuDrawS(0x%x)\n",PRIM));
 			}
-			break;
+		} break;
+
 		case 0x78:
 		case 0x79:
 		case 0x7A:
-		case 0x7B:
-			if (!isSkip)
+		case 0x7B: {          // Monochrome rectangle (16x16)
+			if (!gpu_unai.frameskip.skipGPU)
 			{
 				NULL_GPU();
-				PacketBuffer.U4[2] = 0x00100010;
-				gpuDrawT(gpuTileSpanDrivers [Blending_Mode | Masking | Blending | (PixelMSB>>3)]);
+				gpu_unai.PacketBuffer.U4[2] = 0x00100010;
+				PT driver = gpuTileSpanDrivers[(Blending_Mode | gpu_unai.Masking | Blending | (gpu_unai.PixelMSB>>3)) >> 1];
+				gpuDrawT(packet, driver);
+				gpu_unai.fb_dirty = true;
 				DO_LOG(("gpuDrawT(0x%x)\n",PRIM));
 			}
-			break;
+		} break;
+
 		case 0x7C:
 		case 0x7D:
-#ifdef __arm__
-			if ((GPU_GP1 & 0x180) == 0 && (Masking | PixelMSB) == 0)
+			#ifdef __arm__
+			/* Notaz 4bit sprites optimization */
+			if ((!gpu_unai.frameskip.skipGPU) && (!(gpu_unai.GPU_GP1&0x180)) && (!(gpu_unai.Masking|gpu_unai.PixelMSB)))
 			{
-				gpuSetCLUT    (PacketBuffer.U4[2] >> 16);
-				gpuSetTexture (GPU_GP1);
-				gpuDrawS16();
+				gpuSetCLUT    (gpu_unai.PacketBuffer.U4[2] >> 16);
+				gpuDrawS16(packet);
+				gpu_unai.fb_dirty = true;
 				break;
 			}
-			// fallthrough
-#endif
+			#endif
 		case 0x7E:
-		case 0x7F:
-			if (!isSkip)
+		case 0x7F: {          // Textured rectangle (16x16)
+			if (!gpu_unai.frameskip.skipGPU)
 			{
 				NULL_GPU();
-				PacketBuffer.U4[3] = 0x00100010;
-				gpuSetCLUT    (PacketBuffer.U4[2] >> 16);
-				gpuSetTexture (GPU_GP1);
-				if ((PacketBuffer.U1[0]>0x5F) && (PacketBuffer.U1[1]>0x5F) && (PacketBuffer.U1[2]>0x5F))
-					gpuDrawS(gpuSpriteSpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | (enableAbbeyHack<<7)  | PixelMSB]);
-				else
-					gpuDrawS(gpuSpriteSpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | Lighting | (enableAbbeyHack<<7)  | PixelMSB]);
+				gpu_unai.PacketBuffer.U4[3] = 0x00100010;
+				gpuSetCLUT    (gpu_unai.PacketBuffer.U4[2] >> 16);
+				u32 driver_idx = Blending_Mode | gpu_unai.TEXT_MODE | gpu_unai.Masking | Blending | (gpu_unai.PixelMSB>>1);
+
+				//senquack - Only color 808080h-878787h allows skipping lighting calculation:
+				//if ((gpu_unai.PacketBuffer.U1[0]>0x5F) && (gpu_unai.PacketBuffer.U1[1]>0x5F) && (gpu_unai.PacketBuffer.U1[2]>0x5F))
+				// Strip lower 3 bits of each color and determine if lighting should be used:
+				if ((gpu_unai.PacketBuffer.U4[0] & 0xF8F8F8) != 0x808080)
+					driver_idx |= Lighting;
+				PS driver = gpuSpriteSpanDrivers[driver_idx];
+				gpuDrawS(packet, driver);
+				gpu_unai.fb_dirty = true;
 				DO_LOG(("gpuDrawS(0x%x)\n",PRIM));
 			}
-			break;
+		} break;
+
 		case 0x80:          //  vid -> vid
-			gpuMoveImage();   //  prim handles updateLace && skip
+			gpuMoveImage(packet);   //  prim handles updateLace && skip
+			if ((!gpu_unai.frameskip.skipCount) && (gpu_unai.DisplayArea[3] == 480)) // Tekken 3 hack
+			{
+				if (!gpu_unai.frameskip.skipGPU) gpu_unai.fb_dirty = true;
+			}
+			else
+			{
+				gpu_unai.fb_dirty = true;
+			}
 			DO_LOG(("gpuMoveImage(0x%x)\n",PRIM));
 			break;
 		case 0xA0:          //  sys ->vid
-			gpuLoadImage();   //  prim handles updateLace && skip
-#ifndef isSkip // not a define
-			if (alt_fps) isSkip=false;
-#endif
+			gpuLoadImage(packet);   //  prim handles updateLace && skip
 			DO_LOG(("gpuLoadImage(0x%x)\n",PRIM));
 			break;
 		case 0xC0:          //  vid -> sys
-			gpuStoreImage();  //  prim handles updateLace && skip
+			gpuStoreImage(packet);  //  prim handles updateLace && skip
 			DO_LOG(("gpuStoreImage(0x%x)\n",PRIM));
 			break;
-		case 0xE1:
-			{
-				const u32 temp = PacketBuffer.U4[0];
-				GPU_GP1 = (GPU_GP1 & ~0x000007FF) | (temp & 0x000007FF);
-				gpuSetTexture(temp);
-				DO_LOG(("gpuSetTexture(0x%x)\n",PRIM));
-			}
-			break;
-		case 0xE2:	  
-			{
-				static const u8  TextureMask[32] = {
-					255, 7, 15, 7, 31, 7, 15, 7, 63, 7, 15, 7, 31, 7, 15, 7,	//
-					127, 7, 15, 7, 31, 7, 15, 7, 63, 7, 15, 7, 31, 7, 15, 7	  //
-				};
-				const u32 temp = PacketBuffer.U4[0];
-				TextureWindow[0] = ((temp >> 10) & 0x1F) << 3;
-				TextureWindow[1] = ((temp >> 15) & 0x1F) << 3;
-				TextureWindow[2] = TextureMask[(temp >> 0) & 0x1F];
-				TextureWindow[3] = TextureMask[(temp >> 5) & 0x1F];
-				gpuSetTexture(GPU_GP1);
-				//isSkip = false;
-				DO_LOG(("TextureWindow(0x%x)\n",PRIM));
-			}
-			break;
-		case 0xE3:
-			{
-				const u32 temp = PacketBuffer.U4[0];
-				DrawingArea[0] = temp         & 0x3FF;
-				DrawingArea[1] = (temp >> 10) & 0x3FF;
-				//isSkip = false;
-				DO_LOG(("DrawingArea_Pos(0x%x)\n",PRIM));
-			}
-			break;
-		case 0xE4:
-			{
-				const u32 temp = PacketBuffer.U4[0];
-				DrawingArea[2] = (temp         & 0x3FF) + 1;
-				DrawingArea[3] = ((temp >> 10) & 0x3FF) + 1;
-				//isSkip = false;
-				DO_LOG(("DrawingArea_Size(0x%x)\n",PRIM));
-			}
-			break;
-		case 0xE5:
-			{
-				const u32 temp = PacketBuffer.U4[0];
-				DrawingOffset[0] = ((s32)temp<<(32-11))>>(32-11);
-				DrawingOffset[1] = ((s32)temp<<(32-22))>>(32-11);
-				//isSkip = false;
-				DO_LOG(("DrawingOffset(0x%x)\n",PRIM));
-			}
-			break;
-		case 0xE6:
-			{
-				const u32 temp = PacketBuffer.U4[0];
-				//GPU_GP1 = (GPU_GP1 & ~0x00001800) | ((temp&3) << 11);
-				Masking = (temp & 0x2) <<  1;
-				PixelMSB =(temp & 0x1) <<  8;
-				DO_LOG(("SetMask(0x%x)\n",PRIM));
-			}
-			break;
+		case 0xE1 ... 0xE6: { // Draw settings
+			gpuGP0Cmd_0xEx(gpu_unai, gpu_unai.PacketBuffer.U4[0]);
+		} break;
 	}
 }
+#endif //!USE_GPULIB
+///////////////////////////////////////////////////////////////////////////////
+// End of code specific to non-gpulib standalone version of gpu_unai
+///////////////////////////////////////////////////////////////////////////////
diff --git a/plugins/gpu_unai/gpu_fixedpoint.h b/plugins/gpu_unai/gpu_fixedpoint.h
index e72fda12..5df42cf0 100644
--- a/plugins/gpu_unai/gpu_fixedpoint.h
+++ b/plugins/gpu_unai/gpu_fixedpoint.h
@@ -21,60 +21,73 @@
 #ifndef FIXED_H
 #define FIXED_H
 
-#include "arm_features.h"
-
 typedef s32 fixed;
 
-#ifdef GPU_TABLE_10_BITS
-#define TABLE_BITS 10
-#else
-#define TABLE_BITS 16
-#endif
-
-#define FIXED_BITS 16
+//senquack - The gpu_drhell poly routines I adapted use 22.10 fixed point,
+//           while original Unai used 16.16: (see README_senquack.txt)
+//#define FIXED_BITS 16
+#define FIXED_BITS 10
 
 #define fixed_ZERO ((fixed)0)
 #define fixed_ONE  ((fixed)1<<FIXED_BITS)
 #define fixed_TWO  ((fixed)2<<FIXED_BITS)
 #define fixed_HALF ((fixed)((1<<FIXED_BITS)>>1))
 
-//  big precision inverse table.
-s32 s_invTable[(1<<TABLE_BITS)];
+#define fixed_LOMASK ((fixed)((1<<FIXED_BITS)-1))
+#define fixed_HIMASK ((fixed)(~fixed_LOMASK))
+
+// int<->fixed conversions:
+#define i2x(x) ((x)<<FIXED_BITS)
+#define x2i(x) ((x)>>FIXED_BITS)
+
+INLINE fixed FixedCeil(const fixed x)
+{
+	return (x + (fixed_ONE - 1)) & fixed_HIMASK;
+}
 
-INLINE  fixed i2x(const int   _x) { return  ((_x)<<FIXED_BITS); }
-INLINE  fixed x2i(const fixed _x) { return  ((_x)>>FIXED_BITS); }
+INLINE s32 FixedCeilToInt(const fixed x)
+{
+	return (x + (fixed_ONE - 1)) >> FIXED_BITS;
+}
 
-/*
-INLINE u32 Log2(u32 _a)
+//senquack - float<->fixed conversions:
+#define f2x(x) ((s32)((x) * (float)(1<<FIXED_BITS)))
+#define x2f(x) ((float)(x) / (float)(1<<FIXED_BITS))
+
+//senquack - floating point reciprocal:
+//NOTE: These assume x is always != 0 !!!
+#ifdef GPU_UNAI_USE_FLOATMATH
+#if defined(_MIPS_ARCH_MIPS32R2) || (__mips == 64)
+INLINE float FloatInv(const float x)
+{
+	float res;
+	asm("recip.s %0,%1" : "=f" (res) : "f" (x));
+	return res;
+}
+#else
+INLINE float FloatInv(const float x)
 {
-  u32 c = 0; // result of log2(v) will go here
-  if (_a & 0xFFFF0000) { _a >>= 16; c |= 16;  }
-  if (_a & 0xFF00) { _a >>= 8; c |= 8;  }
-  if (_a & 0xF0) { _a >>= 4; c |= 4;  }
-  if (_a & 0xC) { _a >>= 2; c |= 2;  }
-  if (_a & 0x2) { _a >>= 1; c |= 1;  }
-  return c;
+	return (1.0f / x);
 }
-*/
+#endif
+#endif
 
-#ifdef HAVE_ARMV5
+///////////////////////////////////////////////////////////////////////////
+// --- BEGIN INVERSE APPROXIMATION SECTION ---
+///////////////////////////////////////////////////////////////////////////
+#ifdef GPU_UNAI_USE_INT_DIV_MULTINV
+
+//  big precision inverse table.
+#define TABLE_BITS 16
+s32 s_invTable[(1<<TABLE_BITS)];
+
+//senquack - MIPS32 happens to have same instruction/format:
+#if defined(__arm__) || (__mips == 32)
 INLINE u32 Log2(u32 x) { u32 res; asm("clz %0,%1" : "=r" (res) : "r" (x)); return 32-res; }
 #else
 INLINE u32 Log2(u32 x) { u32 i = 0; for ( ; x > 0; ++i, x >>= 1); return i - 1; }
 #endif
 
-#ifdef GPU_TABLE_10_BITS
-INLINE  void  xInv (const fixed _b, s32& iFactor_, s32& iShift_)
-{
-    u32 uD   = (_b<0) ? -_b : _b ;
-    u32 uLog = Log2(uD);
-    uLog = uLog>(TABLE_BITS-1) ? uLog-(TABLE_BITS-1) : 0;
-    u32 uDen = uD>>uLog;
-    iFactor_ = s_invTable[uDen];
-    iFactor_ = (_b<0) ? -iFactor_ :iFactor_;
-    iShift_  = 15+uLog;
-}
-#else
 INLINE  void  xInv (const fixed _b, s32& iFactor_, s32& iShift_)
 {
   u32 uD = (_b<0) ? -_b : _b;
@@ -82,10 +95,12 @@ INLINE  void  xInv (const fixed _b, s32& iFactor_, s32& iShift_)
   {
 	u32 uLog = Log2(uD);
     uLog = uLog>(TABLE_BITS-1) ? uLog-(TABLE_BITS-1) : 0;
-    u32 uDen = (uD>>uLog)-1;
+    u32 uDen = (uD>>uLog);
     iFactor_ = s_invTable[uDen];
     iFactor_ = (_b<0) ? -iFactor_ :iFactor_;
-    iShift_  = 15+uLog;
+    //senquack - Adapted to 22.10 fixed point (originally 16.16):
+    //iShift_  = 15+uLog;
+    iShift_  = 21+uLog;
   }
   else
   {
@@ -93,7 +108,6 @@ INLINE  void  xInv (const fixed _b, s32& iFactor_, s32& iShift_)
     iShift_ = 0;
   }
 }
-#endif
 
 INLINE  fixed xInvMulx  (const fixed _a, const s32 _iFact, const s32 _iShift)
 {
@@ -112,20 +126,9 @@ INLINE  fixed xLoDivx   (const fixed _a, const fixed _b)
   xInv(_b, iFact, iShift);
   return xInvMulx(_a, iFact, iShift);
 }
-
+#endif // GPU_UNAI_USE_INT_DIV_MULTINV
 ///////////////////////////////////////////////////////////////////////////
-template<typename T>
-INLINE  T Min2 (const T _a, const T _b)             { return (_a<_b)?_a:_b; }
-
-template<typename T>
-INLINE  T Min3 (const T _a, const T _b, const T _c) { return  Min2(Min2(_a,_b),_c); }
-
+// --- END INVERSE APPROXIMATION SECTION ---
 ///////////////////////////////////////////////////////////////////////////
-template<typename T>
-INLINE  T Max2 (const T _a, const T _b)             { return  (_a>_b)?_a:_b; }
 
-template<typename T>
-INLINE  T Max3 (const T _a, const T _b, const T _c) { return  Max2(Max2(_a,_b),_c); }
-
-///////////////////////////////////////////////////////////////////////////
 #endif  //FIXED_H
diff --git a/plugins/gpu_unai/gpu_inner.h b/plugins/gpu_unai/gpu_inner.h
index 4cd7bffe..2228f04e 100644
--- a/plugins/gpu_unai/gpu_inner.h
+++ b/plugins/gpu_unai/gpu_inner.h
@@ -1,6 +1,7 @@
 /***************************************************************************
 *   Copyright (C) 2010 PCSX4ALL Team                                      *
 *   Copyright (C) 2010 Unai                                               *
+*   Copyright (C) 2016 Senquack (dansilsby <AT> gmail <DOT> com)          *
 *                                                                         *
 *   This program is free software; you can redistribute it and/or modify  *
 *   it under the terms of the GNU General Public License as published by  *
@@ -19,415 +20,685 @@
 ***************************************************************************/
 
 ///////////////////////////////////////////////////////////////////////////////
-//  Inner loop driver instanciation file
+// Inner loop driver instantiation file
 
 ///////////////////////////////////////////////////////////////////////////////
-//  Option Masks
-#define   L ((CF>>0)&1)
-#define   B ((CF>>1)&1)
-#define   M ((CF>>2)&1)
-#define  BM ((CF>>3)&3)
-#define  TM ((CF>>5)&3)
-#define   G ((CF>>7)&1)
-
-#define  AH ((CF>>7)&1)
-
-#define  MB ((CF>>8)&1)
+//  Option Masks (CF template paramter)
+#define  CF_LIGHT     ((CF>> 0)&1) // Lighting
+#define  CF_BLEND     ((CF>> 1)&1) // Blending
+#define  CF_MASKCHECK ((CF>> 2)&1) // Mask bit check
+#define  CF_BLENDMODE ((CF>> 3)&3) // Blend mode   0..3
+#define  CF_TEXTMODE  ((CF>> 5)&3) // Texture mode 1..3 (0: texturing disabled)
+#define  CF_GOURAUD   ((CF>> 7)&1) // Gouraud shading
+#define  CF_MASKSET   ((CF>> 8)&1) // Mask bit set
+#define  CF_DITHER    ((CF>> 9)&1) // Dithering
+#define  CF_BLITMASK  ((CF>>10)&1) // blit_mask check (skip rendering pixels
+                                   //  that wouldn't end up displayed on
+                                   //  low-res screen using simple downscaler)
 
+#ifdef __arm__
+#ifndef ENABLE_GPU_ARMV7
+/* ARMv5 */
+#include "gpu_inner_blend_arm5.h"
+#else
+/* ARMv7 optimized */
+#include "gpu_inner_blend_arm7.h"
+#endif
+#else
 #include "gpu_inner_blend.h"
+#endif
+
+#include "gpu_inner_quantization.h"
 #include "gpu_inner_light.h"
 
+// If defined, Gouraud colors are fixed-point 5.11, otherwise they are 8.16
+// This is only for debugging/verification of low-precision colors in C.
+// Low-precision Gouraud is intended for use by SIMD-optimized inner drivers
+// which get/use Gouraud colors in SIMD registers.
+//#define GPU_GOURAUD_LOW_PRECISION
+
+// How many bits of fixed-point precision GouraudColor uses
+#ifdef GPU_GOURAUD_LOW_PRECISION
+#define GPU_GOURAUD_FIXED_BITS 11
+#else
+#define GPU_GOURAUD_FIXED_BITS 16
+#endif
+
+// Used to pass Gouraud colors to gpuPixelSpanFn() (lines)
+struct GouraudColor {
+#ifdef GPU_GOURAUD_LOW_PRECISION
+	u16 r, g, b;
+	s16 r_incr, g_incr, b_incr;
+#else
+	u32 r, g, b;
+	s32 r_incr, g_incr, b_incr;
+#endif
+};
+
+static inline u16 gpuGouraudColor15bpp(u32 r, u32 g, u32 b)
+{
+	r >>= GPU_GOURAUD_FIXED_BITS;
+	g >>= GPU_GOURAUD_FIXED_BITS;
+	b >>= GPU_GOURAUD_FIXED_BITS;
+
+#ifndef GPU_GOURAUD_LOW_PRECISION
+	// High-precision Gouraud colors are 8-bit + fractional
+	r >>= 3;  g >>= 3;  b >>= 3;
+#endif
+
+	return r | (g << 5) | (b << 10);
+}
+
 ///////////////////////////////////////////////////////////////////////////////
-//  GPU Pixel opperations generator
-template<const int CF>
-INLINE void gpuPixelFn(u16 *pixel,const u16 data)
+//  GPU Pixel span operations generator gpuPixelSpanFn<>
+//  Oct 2016: Created/adapted from old gpuPixelFn by senquack:
+//  Original gpuPixelFn was used to draw lines one pixel at a time. I wrote
+//  new line algorithms that draw lines using horizontal/vertical/diagonal
+//  spans of pixels, necessitating new pixel-drawing function that could
+//  not only render spans of pixels, but gouraud-shade them as well.
+//  This speeds up line rendering and would allow tile-rendering (untextured
+//  rectangles) to use the same set of functions. Since tiles are always
+//  monochrome, they simply wouldn't use the extra set of 32 gouraud-shaded
+//  gpuPixelSpanFn functions (TODO?).
+//
+// NOTE: While the PS1 framebuffer is 16 bit, we use 8-bit pointers here,
+//       so that pDst can be incremented directly by 'incr' parameter
+//       without having to shift it before use.
+template<int CF>
+static u8* gpuPixelSpanFn(u8* pDst, uintptr_t data, ptrdiff_t incr, size_t len)
 {
-	if ((!M)&&(!B))
-	{
-		if(MB) { *pixel = data | 0x8000; }
-		else   { *pixel = data; }
+	// Blend func can save an operation if it knows uSrc MSB is
+	//  unset. For untextured prims, this is always true.
+	const bool skip_uSrc_mask = true;
+
+	u16 col;
+	struct GouraudColor * gcPtr;
+	u32 r, g, b;
+	s32 r_incr, g_incr, b_incr;
+
+	if (CF_GOURAUD) {
+		gcPtr = (GouraudColor*)data;
+		r = gcPtr->r;  r_incr = gcPtr->r_incr;
+		g = gcPtr->g;  g_incr = gcPtr->g_incr;
+		b = gcPtr->b;  b_incr = gcPtr->b_incr;
+	} else {
+		col = (u16)data;
 	}
-	else if ((M)&&(!B))
-	{
-		if (!(*pixel&0x8000))
-		{
-			if(MB) { *pixel = data | 0x8000; }
-			else   { *pixel = data; }
+
+	do {
+		if (!CF_GOURAUD)
+		{   // NO GOURAUD
+			if (!CF_MASKCHECK && !CF_BLEND) {
+				if (CF_MASKSET) { *(u16*)pDst = col | 0x8000; }
+				else            { *(u16*)pDst = col;          }
+			} else if (CF_MASKCHECK && !CF_BLEND) {
+				if (!(*(u16*)pDst & 0x8000)) {
+					if (CF_MASKSET) { *(u16*)pDst = col | 0x8000; }
+					else            { *(u16*)pDst = col;          }
+				}
+			} else {
+				u16 uDst = *(u16*)pDst;
+				if (CF_MASKCHECK) { if (uDst & 0x8000) goto endpixel; }
+
+				u16 uSrc = col;
+
+				if (CF_BLEND)
+					uSrc = gpuBlending<CF_BLENDMODE, skip_uSrc_mask>(uSrc, uDst);
+
+				if (CF_MASKSET) { *(u16*)pDst = uSrc | 0x8000; }
+				else            { *(u16*)pDst = uSrc;          }
+			}
+
+		} else
+		{   // GOURAUD
+
+			if (!CF_MASKCHECK && !CF_BLEND) {
+				col = gpuGouraudColor15bpp(r, g, b);
+				if (CF_MASKSET) { *(u16*)pDst = col | 0x8000; }
+				else            { *(u16*)pDst = col;          }
+			} else if (CF_MASKCHECK && !CF_BLEND) {
+				col = gpuGouraudColor15bpp(r, g, b);
+				if (!(*(u16*)pDst & 0x8000)) {
+					if (CF_MASKSET) { *(u16*)pDst = col | 0x8000; }
+					else            { *(u16*)pDst = col;          }
+				}
+			} else {
+				u16 uDst = *(u16*)pDst;
+				if (CF_MASKCHECK) { if (uDst & 0x8000) goto endpixel; }
+				col = gpuGouraudColor15bpp(r, g, b);
+
+				u16 uSrc = col;
+
+				// Blend func can save an operation if it knows uSrc MSB is
+				//  unset. For untextured prims, this is always true.
+				const bool skip_uSrc_mask = true;
+
+				if (CF_BLEND)
+					uSrc = gpuBlending<CF_BLENDMODE, skip_uSrc_mask>(uSrc, uDst);
+
+				if (CF_MASKSET) { *(u16*)pDst = uSrc | 0x8000; }
+				else            { *(u16*)pDst = uSrc;          }
+			}
 		}
+
+endpixel:
+		if (CF_GOURAUD) {
+			r += r_incr;
+			g += g_incr;
+			b += b_incr;
+		}
+		pDst += incr;
+	} while (len-- > 1);
+
+	// Note from senquack: Normally, I'd prefer to write a 'do {} while (--len)'
+	//  loop, or even a for() loop, however, on MIPS platforms anything but the
+	//  'do {} while (len-- > 1)' tends to generate very unoptimal asm, with
+	//  many unneeded MULs/ADDs/branches at the ends of these functions.
+	//  If you change the loop structure above, be sure to compare the quality
+	//  of the generated code!!
+
+	if (CF_GOURAUD) {
+		gcPtr->r = r;
+		gcPtr->g = g;
+		gcPtr->b = b;
 	}
-	else
-	{
-		u16 uDst = *pixel;
-		if(M) { if (uDst&0x8000) return; }
-		u16 uSrc = data;
-		u32 uMsk; if (BM==0) uMsk=0x7BDE;
-		if (BM==0) gpuBlending00(uSrc, uDst);
-		if (BM==1) gpuBlending01(uSrc, uDst);
-		if (BM==2) gpuBlending02(uSrc, uDst);
-		if (BM==3) gpuBlending03(uSrc, uDst);
-		if(MB) { *pixel = uSrc | 0x8000; }
-		else   { *pixel = uSrc; }
-	}
+	return pDst;
+}
+
+static u8* PixelSpanNULL(u8* pDst, uintptr_t data, ptrdiff_t incr, size_t len)
+{
+	#ifdef ENABLE_GPU_LOG_SUPPORT
+		fprintf(stdout,"PixelSpanNULL()\n");
+	#endif
+	return pDst;
 }
-///////////////////////////////////////////////////////////////////////////////
 
 ///////////////////////////////////////////////////////////////////////////////
-//  Pixel drawing drivers, for lines (only blending)
-typedef void (*PD)(u16 *pixel,const u16 data);
-const PD  gpuPixelDrivers[32] =   //  We only generate pixel op for MASKING/BLEND_ENABLE/BLEND_MODE
+//  PixelSpan (lines) innerloops driver
+typedef u8* (*PSD)(u8* dst, uintptr_t data, ptrdiff_t incr, size_t len);
+
+const PSD gpuPixelSpanDrivers[64] =
 { 
-	gpuPixelFn<0x00<<1>,gpuPixelFn<0x01<<1>,gpuPixelFn<0x02<<1>,gpuPixelFn<0x03<<1>,  
-	NULL,gpuPixelFn<0x05<<1>,NULL,gpuPixelFn<0x07<<1>,
-	NULL,gpuPixelFn<0x09<<1>,NULL,gpuPixelFn<0x0B<<1>,
-	NULL,gpuPixelFn<0x0D<<1>,NULL,gpuPixelFn<0x0F<<1>,
-
-	gpuPixelFn<(0x00<<1)|256>,gpuPixelFn<(0x01<<1)|256>,gpuPixelFn<(0x02<<1)|256>,gpuPixelFn<(0x03<<1)|256>,  
-	NULL,gpuPixelFn<(0x05<<1)|256>,NULL,gpuPixelFn<(0x07<<1)|256>,
-	NULL,gpuPixelFn<(0x09<<1)|256>,NULL,gpuPixelFn<(0x0B<<1)|256>,
-	NULL,gpuPixelFn<(0x0D<<1)|256>,NULL,gpuPixelFn<(0x0F<<1)|256>
+	// Array index | 'CF' template field | Field value
+	// ------------+---------------------+----------------
+	// Bit 0       | CF_BLEND            | off (0), on (1)
+	// Bit 1       | CF_MASKCHECK        | off (0), on (1)
+	// Bit 3:2     | CF_BLENDMODE        | 0..3
+	// Bit 4       | CF_MASKSET          | off (0), on (1)
+	// Bit 5       | CF_GOURAUD          | off (0), on (1)
+	//
+	// NULL entries are ones for which blending is disabled and blend-mode
+	//  field is non-zero, which is obviously invalid.
+
+	// Flat-shaded
+	gpuPixelSpanFn<0x00<<1>,         gpuPixelSpanFn<0x01<<1>,         gpuPixelSpanFn<0x02<<1>,         gpuPixelSpanFn<0x03<<1>,
+	PixelSpanNULL,                   gpuPixelSpanFn<0x05<<1>,         PixelSpanNULL,                   gpuPixelSpanFn<0x07<<1>,
+	PixelSpanNULL,                   gpuPixelSpanFn<0x09<<1>,         PixelSpanNULL,                   gpuPixelSpanFn<0x0B<<1>,
+	PixelSpanNULL,                   gpuPixelSpanFn<0x0D<<1>,         PixelSpanNULL,                   gpuPixelSpanFn<0x0F<<1>,
+
+	// Flat-shaded + PixelMSB (CF_MASKSET)
+	gpuPixelSpanFn<(0x00<<1)|0x100>, gpuPixelSpanFn<(0x01<<1)|0x100>, gpuPixelSpanFn<(0x02<<1)|0x100>, gpuPixelSpanFn<(0x03<<1)|0x100>,
+	PixelSpanNULL,                   gpuPixelSpanFn<(0x05<<1)|0x100>, PixelSpanNULL,                   gpuPixelSpanFn<(0x07<<1)|0x100>,
+	PixelSpanNULL,                   gpuPixelSpanFn<(0x09<<1)|0x100>, PixelSpanNULL,                   gpuPixelSpanFn<(0x0B<<1)|0x100>,
+	PixelSpanNULL,                   gpuPixelSpanFn<(0x0D<<1)|0x100>, PixelSpanNULL,                   gpuPixelSpanFn<(0x0F<<1)|0x100>,
+
+	// Gouraud-shaded (CF_GOURAUD)
+	gpuPixelSpanFn<(0x00<<1)|0x80>,  gpuPixelSpanFn<(0x01<<1)|0x80>,  gpuPixelSpanFn<(0x02<<1)|0x80>,  gpuPixelSpanFn<(0x03<<1)|0x80>,
+	PixelSpanNULL,                   gpuPixelSpanFn<(0x05<<1)|0x80>,  PixelSpanNULL,                   gpuPixelSpanFn<(0x07<<1)|0x80>,
+	PixelSpanNULL,                   gpuPixelSpanFn<(0x09<<1)|0x80>,  PixelSpanNULL,                   gpuPixelSpanFn<(0x0B<<1)|0x80>,
+	PixelSpanNULL,                   gpuPixelSpanFn<(0x0D<<1)|0x80>,  PixelSpanNULL,                   gpuPixelSpanFn<(0x0F<<1)|0x80>,
+
+	// Gouraud-shaded (CF_GOURAUD) + PixelMSB (CF_MASKSET)
+	gpuPixelSpanFn<(0x00<<1)|0x180>, gpuPixelSpanFn<(0x01<<1)|0x180>, gpuPixelSpanFn<(0x02<<1)|0x180>, gpuPixelSpanFn<(0x03<<1)|0x180>,
+	PixelSpanNULL,                   gpuPixelSpanFn<(0x05<<1)|0x180>, PixelSpanNULL,                   gpuPixelSpanFn<(0x07<<1)|0x180>,
+	PixelSpanNULL,                   gpuPixelSpanFn<(0x09<<1)|0x180>, PixelSpanNULL,                   gpuPixelSpanFn<(0x0B<<1)|0x180>,
+	PixelSpanNULL,                   gpuPixelSpanFn<(0x0D<<1)|0x180>, PixelSpanNULL,                   gpuPixelSpanFn<(0x0F<<1)|0x180>
 };
 
 ///////////////////////////////////////////////////////////////////////////////
 //  GPU Tiles innerloops generator
 
-template<const int CF>
-INLINE void  gpuTileSpanFn(u16 *pDst, u32 count, u16 data)
+template<int CF>
+static void gpuTileSpanFn(u16 *pDst, u32 count, u16 data)
 {
-	if ((!M)&&(!B))
-	{
-		if (MB) { data = data | 0x8000; }
+	if (!CF_MASKCHECK && !CF_BLEND) {
+		if (CF_MASKSET) { data = data | 0x8000; }
 		do { *pDst++ = data; } while (--count);
-	}
-	else if ((M)&&(!B))
-	{
-		if (MB) { data = data | 0x8000; }
+	} else if (CF_MASKCHECK && !CF_BLEND) {
+		if (CF_MASKSET) { data = data | 0x8000; }
 		do { if (!(*pDst&0x8000)) { *pDst = data; } pDst++; } while (--count);
-	}
-	else
+	} else
 	{
-		u16 uSrc;
-		u16 uDst;
-		u32 uMsk; if (BM==0) uMsk=0x7BDE;
+		// Blend func can save an operation if it knows uSrc MSB is
+		//  unset. For untextured prims, this is always true.
+		const bool skip_uSrc_mask = true;
+
+		u16 uSrc, uDst;
 		do
 		{
-			//  MASKING
-			uDst = *pDst;
-			if(M) { if (uDst&0x8000) goto endtile;  }
+			if (CF_MASKCHECK || CF_BLEND) { uDst = *pDst; }
+			if (CF_MASKCHECK) { if (uDst&0x8000) goto endtile; }
+
 			uSrc = data;
 
-			//  BLEND
-			if (BM==0) gpuBlending00(uSrc, uDst);
-			if (BM==1) gpuBlending01(uSrc, uDst);
-			if (BM==2) gpuBlending02(uSrc, uDst);
-			if (BM==3) gpuBlending03(uSrc, uDst);
+			if (CF_BLEND)
+				uSrc = gpuBlending<CF_BLENDMODE, skip_uSrc_mask>(uSrc, uDst);
 
-			if (MB) { *pDst = uSrc | 0x8000; }
-			else    { *pDst = uSrc; }
-			endtile: pDst++;
+			if (CF_MASKSET) { *pDst = uSrc | 0x8000; }
+			else            { *pDst = uSrc;          }
+
+			//senquack - Did not apply "Silent Hill" mask-bit fix to here.
+			// It is hard to tell from scarce documentation available and
+			//  lack of comments in code, but I believe the tile-span
+			//  functions here should not bother to preserve any source MSB,
+			//  as they are not drawing from a texture.
+endtile:
+			pDst++;
 		}
 		while (--count);
 	}
 }
 
+static void TileNULL(u16 *pDst, u32 count, u16 data)
+{
+	#ifdef ENABLE_GPU_LOG_SUPPORT
+		fprintf(stdout,"TileNULL()\n");
+	#endif
+}
+
 ///////////////////////////////////////////////////////////////////////////////
 //  Tiles innerloops driver
 typedef void (*PT)(u16 *pDst, u32 count, u16 data);
-const PT gpuTileSpanDrivers[64] = 
-{
-	gpuTileSpanFn<0x00>,NULL,gpuTileSpanFn<0x02>,NULL,  gpuTileSpanFn<0x04>,NULL,gpuTileSpanFn<0x06>,NULL,  NULL,NULL,gpuTileSpanFn<0x0A>,NULL,  NULL,NULL,gpuTileSpanFn<0x0E>,NULL,
-	NULL,NULL,gpuTileSpanFn<0x12>,NULL,  NULL,NULL,gpuTileSpanFn<0x16>,NULL,  NULL,NULL,gpuTileSpanFn<0x1A>,NULL,  NULL,NULL,gpuTileSpanFn<0x1E>,NULL,
 
-	gpuTileSpanFn<0x100>,NULL,gpuTileSpanFn<0x102>,NULL,  gpuTileSpanFn<0x104>,NULL,gpuTileSpanFn<0x106>,NULL,  NULL,NULL,gpuTileSpanFn<0x10A>,NULL,  NULL,NULL,gpuTileSpanFn<0x10E>,NULL,
-	NULL,NULL,gpuTileSpanFn<0x112>,NULL,  NULL,NULL,gpuTileSpanFn<0x116>,NULL,  NULL,NULL,gpuTileSpanFn<0x11A>,NULL,  NULL,NULL,gpuTileSpanFn<0x11E>,NULL,
+// Template instantiation helper macros
+#define TI(cf) gpuTileSpanFn<(cf)>
+#define TN     TileNULL
+#define TIBLOCK(ub) \
+	TI((ub)|0x00), TI((ub)|0x02), TI((ub)|0x04), TI((ub)|0x06), \
+	TN,            TI((ub)|0x0a), TN,            TI((ub)|0x0e), \
+	TN,            TI((ub)|0x12), TN,            TI((ub)|0x16), \
+	TN,            TI((ub)|0x1a), TN,            TI((ub)|0x1e)
+
+const PT gpuTileSpanDrivers[32] = {
+	TIBLOCK(0<<8), TIBLOCK(1<<8)
 };
 
+#undef TI
+#undef TN
+#undef TIBLOCK
+
+
 ///////////////////////////////////////////////////////////////////////////////
 //  GPU Sprites innerloops generator
 
-template<const int CF>
-INLINE void  gpuSpriteSpanFn(u16 *pDst, u32 count, u32 u0, const u32 mask)
+template<int CF>
+static void gpuSpriteSpanFn(u16 *pDst, u32 count, u8* pTxt, u32 u0)
 {
-	u16 uSrc;
-	u16 uDst;
-	const u16* pTxt = TBA+(u0&~0x1ff); u0=u0&0x1ff;
-	const u16 *_CBA; if(TM!=3) _CBA=CBA;
-	u32 lCol; if(L)  { lCol = ((u32)(b4<< 2)&(0x03ff)) | ((u32)(g4<<13)&(0x07ff<<10)) | ((u32)(r4<<24)&(0x07ff<<21));  }
-	u8 rgb; if (TM==1) rgb = ((u8*)pTxt)[u0>>1];
-	u32 uMsk; if ((B)&&(BM==0)) uMsk=0x7BDE;
+	// Blend func can save an operation if it knows uSrc MSB is unset.
+	//  Untextured prims can always skip (source color always comes with MSB=0).
+	//  For textured prims, lighting funcs always return it unset. (bonus!)
+	const bool skip_uSrc_mask = (!CF_TEXTMODE) || CF_LIGHT;
+
+	u16 uSrc, uDst, srcMSB;
+	u32 u0_mask = gpu_unai.TextureWindow[2];
+
+	u8 r5, g5, b5;
+	if (CF_LIGHT) {
+		r5 = gpu_unai.r5;
+		g5 = gpu_unai.g5;
+		b5 = gpu_unai.b5;
+	}
+
+	if (CF_TEXTMODE==3) {
+		// Texture is accessed byte-wise, so adjust mask if 16bpp
+		u0_mask <<= 1;
+	}
+
+	const u16 *CBA_; if (CF_TEXTMODE!=3) CBA_ = gpu_unai.CBA;
 
 	do
 	{
-		//  MASKING
-		if(M)   { uDst = *pDst;   if (uDst&0x8000) { u0=(u0+1)&mask; goto endsprite; }  }
+		if (CF_MASKCHECK || CF_BLEND) { uDst = *pDst; }
+		if (CF_MASKCHECK) if (uDst&0x8000) { goto endsprite; }
 
-		//  TEXTURE MAPPING
-		if (TM==1) { if (!(u0&1)) rgb = ((u8*)pTxt)[u0>>1]; uSrc = _CBA[(rgb>>((u0&1)<<2))&0xf]; u0=(u0+1)&mask; }
-		if (TM==2) { uSrc = _CBA[((u8*)pTxt)[u0]]; u0=(u0+1)&mask; }
-		if (TM==3) { uSrc = pTxt[u0]; u0=(u0+1)&mask; }
-		if(!AH) { if (!uSrc) goto endsprite; }
-
-		//  BLEND
-		if(B)
-		{
-			if(uSrc&0x8000)
-			{
-				//  LIGHTING CALCULATIONS
-				if(L)  { gpuLightingTXT(uSrc, lCol);   }
-
-				if(!M)    { uDst = *pDst; }
-				if (BM==0) gpuBlending00(uSrc, uDst);
-				if (BM==1) gpuBlending01(uSrc, uDst);
-				if (BM==2) gpuBlending02(uSrc, uDst);
-				if (BM==3) gpuBlending03(uSrc, uDst);
-			}
-			else
-			{
-				//  LIGHTING CALCULATIONS
-				if(L)  { gpuLightingTXT(uSrc, lCol); }
-			}
+		if (CF_TEXTMODE==1) {  //  4bpp (CLUT)
+			u8 rgb = pTxt[(u0 & u0_mask)>>1];
+			uSrc = CBA_[(rgb>>((u0&1)<<2))&0xf];
 		}
-		else
-		{
-			//  LIGHTING CALCULATIONS
-			if(L)  { gpuLightingTXT(uSrc, lCol);   } else
-			{ if(!MB) uSrc&= 0x7fff;               }
+		if (CF_TEXTMODE==2) {  //  8bpp (CLUT)
+			uSrc = CBA_[pTxt[u0 & u0_mask]];
+		}
+		if (CF_TEXTMODE==3) {  // 16bpp
+			uSrc = *(u16*)(&pTxt[u0 & u0_mask]);
 		}
 
-		if (MB) { *pDst = uSrc | 0x8000; }
-		else    { *pDst = uSrc; }
+		if (!uSrc) goto endsprite;
+
+		//senquack - save source MSB, as blending or lighting macros will not
+		//           (Silent Hill gray rectangles mask bit bug)
+		if (CF_BLEND || CF_LIGHT) srcMSB = uSrc & 0x8000;
 		
-		endsprite: pDst++;
+		if (CF_LIGHT)
+			uSrc = gpuLightingTXT(uSrc, r5, g5, b5);
+
+		if (CF_BLEND && srcMSB)
+			uSrc = gpuBlending<CF_BLENDMODE, skip_uSrc_mask>(uSrc, uDst);
+
+		if (CF_MASKSET)                { *pDst = uSrc | 0x8000; }
+		else if (CF_BLEND || CF_LIGHT) { *pDst = uSrc | srcMSB; }
+		else                           { *pDst = uSrc;          }
+
+endsprite:
+		u0 += (CF_TEXTMODE==3) ? 2 : 1;
+		pDst++;
 	}
 	while (--count);
 }
+
+static void SpriteNULL(u16 *pDst, u32 count, u8* pTxt, u32 u0)
+{
+	#ifdef ENABLE_GPU_LOG_SUPPORT
+		fprintf(stdout,"SpriteNULL()\n");
+	#endif
+}
+
 ///////////////////////////////////////////////////////////////////////////////
 
 ///////////////////////////////////////////////////////////////////////////////
 //  Sprite innerloops driver
-typedef void (*PS)(u16 *pDst, u32 count, u32 u0, const u32 mask);
-const PS gpuSpriteSpanDrivers[512] = 
-{
-	NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,
-	NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,
-	gpuSpriteSpanFn<0x20>,gpuSpriteSpanFn<0x21>,gpuSpriteSpanFn<0x22>,gpuSpriteSpanFn<0x23>,  gpuSpriteSpanFn<0x24>,gpuSpriteSpanFn<0x25>,gpuSpriteSpanFn<0x26>,gpuSpriteSpanFn<0x27>,  NULL,NULL,gpuSpriteSpanFn<0x2A>,gpuSpriteSpanFn<0x2B>,  NULL,NULL,gpuSpriteSpanFn<0x2E>,gpuSpriteSpanFn<0x2F>,
-	NULL,NULL,gpuSpriteSpanFn<0x32>,gpuSpriteSpanFn<0x33>,  NULL,NULL,gpuSpriteSpanFn<0x36>,gpuSpriteSpanFn<0x37>,  NULL,NULL,gpuSpriteSpanFn<0x3A>,gpuSpriteSpanFn<0x3B>,  NULL,NULL,gpuSpriteSpanFn<0x3E>,gpuSpriteSpanFn<0x3F>,
-	gpuSpriteSpanFn<0x40>,gpuSpriteSpanFn<0x41>,gpuSpriteSpanFn<0x42>,gpuSpriteSpanFn<0x43>,  gpuSpriteSpanFn<0x44>,gpuSpriteSpanFn<0x45>,gpuSpriteSpanFn<0x46>,gpuSpriteSpanFn<0x47>,  NULL,NULL,gpuSpriteSpanFn<0x4A>,gpuSpriteSpanFn<0x4B>,  NULL,NULL,gpuSpriteSpanFn<0x4E>,gpuSpriteSpanFn<0x4F>,
-	NULL,NULL,gpuSpriteSpanFn<0x52>,gpuSpriteSpanFn<0x53>,  NULL,NULL,gpuSpriteSpanFn<0x56>,gpuSpriteSpanFn<0x57>,  NULL,NULL,gpuSpriteSpanFn<0x5A>,gpuSpriteSpanFn<0x5B>,  NULL,NULL,gpuSpriteSpanFn<0x5E>,gpuSpriteSpanFn<0x5F>,
-	gpuSpriteSpanFn<0x60>,gpuSpriteSpanFn<0x61>,gpuSpriteSpanFn<0x62>,gpuSpriteSpanFn<0x63>,  gpuSpriteSpanFn<0x64>,gpuSpriteSpanFn<0x65>,gpuSpriteSpanFn<0x66>,gpuSpriteSpanFn<0x67>,  NULL,NULL,gpuSpriteSpanFn<0x6A>,gpuSpriteSpanFn<0x6B>,  NULL,NULL,gpuSpriteSpanFn<0x6E>,gpuSpriteSpanFn<0x6F>,
-	NULL,NULL,gpuSpriteSpanFn<0x72>,gpuSpriteSpanFn<0x73>,  NULL,NULL,gpuSpriteSpanFn<0x76>,gpuSpriteSpanFn<0x77>,  NULL,NULL,gpuSpriteSpanFn<0x7A>,gpuSpriteSpanFn<0x7B>,  NULL,NULL,gpuSpriteSpanFn<0x7E>,gpuSpriteSpanFn<0x7F>,
-
-	NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,
-	NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,
-	gpuSpriteSpanFn<0xa0>,gpuSpriteSpanFn<0xa1>,gpuSpriteSpanFn<0xa2>,gpuSpriteSpanFn<0xa3>,  gpuSpriteSpanFn<0xa4>,gpuSpriteSpanFn<0xa5>,gpuSpriteSpanFn<0xa6>,gpuSpriteSpanFn<0xa7>,  NULL,NULL,gpuSpriteSpanFn<0xaA>,gpuSpriteSpanFn<0xaB>,  NULL,NULL,gpuSpriteSpanFn<0xaE>,gpuSpriteSpanFn<0xaF>,
-	NULL,NULL,gpuSpriteSpanFn<0xb2>,gpuSpriteSpanFn<0xb3>,  NULL,NULL,gpuSpriteSpanFn<0xb6>,gpuSpriteSpanFn<0xb7>,  NULL,NULL,gpuSpriteSpanFn<0xbA>,gpuSpriteSpanFn<0xbB>,  NULL,NULL,gpuSpriteSpanFn<0xbE>,gpuSpriteSpanFn<0xbF>,
-	gpuSpriteSpanFn<0xc0>,gpuSpriteSpanFn<0xc1>,gpuSpriteSpanFn<0xc2>,gpuSpriteSpanFn<0xc3>,  gpuSpriteSpanFn<0xc4>,gpuSpriteSpanFn<0xc5>,gpuSpriteSpanFn<0xc6>,gpuSpriteSpanFn<0xc7>,  NULL,NULL,gpuSpriteSpanFn<0xcA>,gpuSpriteSpanFn<0xcB>,  NULL,NULL,gpuSpriteSpanFn<0xcE>,gpuSpriteSpanFn<0xcF>,
-	NULL,NULL,gpuSpriteSpanFn<0xd2>,gpuSpriteSpanFn<0xd3>,  NULL,NULL,gpuSpriteSpanFn<0xd6>,gpuSpriteSpanFn<0xd7>,  NULL,NULL,gpuSpriteSpanFn<0xdA>,gpuSpriteSpanFn<0xdB>,  NULL,NULL,gpuSpriteSpanFn<0xdE>,gpuSpriteSpanFn<0xdF>,
-	gpuSpriteSpanFn<0xe0>,gpuSpriteSpanFn<0xe1>,gpuSpriteSpanFn<0xe2>,gpuSpriteSpanFn<0xe3>,  gpuSpriteSpanFn<0xe4>,gpuSpriteSpanFn<0xe5>,gpuSpriteSpanFn<0xe6>,gpuSpriteSpanFn<0xe7>,  NULL,NULL,gpuSpriteSpanFn<0xeA>,gpuSpriteSpanFn<0xeB>,  NULL,NULL,gpuSpriteSpanFn<0xeE>,gpuSpriteSpanFn<0xeF>,
-	NULL,NULL,gpuSpriteSpanFn<0xf2>,gpuSpriteSpanFn<0xf3>,  NULL,NULL,gpuSpriteSpanFn<0xf6>,gpuSpriteSpanFn<0xf7>,  NULL,NULL,gpuSpriteSpanFn<0xfA>,gpuSpriteSpanFn<0xfB>,  NULL,NULL,gpuSpriteSpanFn<0xfE>,gpuSpriteSpanFn<0xfF>,
-
-	NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,
-	NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,
-	gpuSpriteSpanFn<0x120>,gpuSpriteSpanFn<0x121>,gpuSpriteSpanFn<0x122>,gpuSpriteSpanFn<0x123>,  gpuSpriteSpanFn<0x124>,gpuSpriteSpanFn<0x125>,gpuSpriteSpanFn<0x126>,gpuSpriteSpanFn<0x127>,  NULL,NULL,gpuSpriteSpanFn<0x12A>,gpuSpriteSpanFn<0x12B>,  NULL,NULL,gpuSpriteSpanFn<0x12E>,gpuSpriteSpanFn<0x12F>,
-	NULL,NULL,gpuSpriteSpanFn<0x132>,gpuSpriteSpanFn<0x133>,  NULL,NULL,gpuSpriteSpanFn<0x136>,gpuSpriteSpanFn<0x137>,  NULL,NULL,gpuSpriteSpanFn<0x13A>,gpuSpriteSpanFn<0x13B>,  NULL,NULL,gpuSpriteSpanFn<0x13E>,gpuSpriteSpanFn<0x13F>,
-	gpuSpriteSpanFn<0x140>,gpuSpriteSpanFn<0x141>,gpuSpriteSpanFn<0x142>,gpuSpriteSpanFn<0x143>,  gpuSpriteSpanFn<0x144>,gpuSpriteSpanFn<0x145>,gpuSpriteSpanFn<0x146>,gpuSpriteSpanFn<0x147>,  NULL,NULL,gpuSpriteSpanFn<0x14A>,gpuSpriteSpanFn<0x14B>,  NULL,NULL,gpuSpriteSpanFn<0x14E>,gpuSpriteSpanFn<0x14F>,
-	NULL,NULL,gpuSpriteSpanFn<0x152>,gpuSpriteSpanFn<0x153>,  NULL,NULL,gpuSpriteSpanFn<0x156>,gpuSpriteSpanFn<0x157>,  NULL,NULL,gpuSpriteSpanFn<0x15A>,gpuSpriteSpanFn<0x15B>,  NULL,NULL,gpuSpriteSpanFn<0x15E>,gpuSpriteSpanFn<0x15F>,
-	gpuSpriteSpanFn<0x160>,gpuSpriteSpanFn<0x161>,gpuSpriteSpanFn<0x162>,gpuSpriteSpanFn<0x163>,  gpuSpriteSpanFn<0x164>,gpuSpriteSpanFn<0x165>,gpuSpriteSpanFn<0x166>,gpuSpriteSpanFn<0x167>,  NULL,NULL,gpuSpriteSpanFn<0x16A>,gpuSpriteSpanFn<0x16B>,  NULL,NULL,gpuSpriteSpanFn<0x16E>,gpuSpriteSpanFn<0x16F>,
-	NULL,NULL,gpuSpriteSpanFn<0x172>,gpuSpriteSpanFn<0x173>,  NULL,NULL,gpuSpriteSpanFn<0x176>,gpuSpriteSpanFn<0x177>,  NULL,NULL,gpuSpriteSpanFn<0x17A>,gpuSpriteSpanFn<0x17B>,  NULL,NULL,gpuSpriteSpanFn<0x17E>,gpuSpriteSpanFn<0x17F>,
-                                                                                                                                                                                                                                                                                                                                                                                      
-	NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,
-	NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,
-	gpuSpriteSpanFn<0x1a0>,gpuSpriteSpanFn<0x1a1>,gpuSpriteSpanFn<0x1a2>,gpuSpriteSpanFn<0x1a3>,  gpuSpriteSpanFn<0x1a4>,gpuSpriteSpanFn<0x1a5>,gpuSpriteSpanFn<0x1a6>,gpuSpriteSpanFn<0x1a7>,  NULL,NULL,gpuSpriteSpanFn<0x1aA>,gpuSpriteSpanFn<0x1aB>,  NULL,NULL,gpuSpriteSpanFn<0x1aE>,gpuSpriteSpanFn<0x1aF>,
-	NULL,NULL,gpuSpriteSpanFn<0x1b2>,gpuSpriteSpanFn<0x1b3>,  NULL,NULL,gpuSpriteSpanFn<0x1b6>,gpuSpriteSpanFn<0x1b7>,  NULL,NULL,gpuSpriteSpanFn<0x1bA>,gpuSpriteSpanFn<0x1bB>,  NULL,NULL,gpuSpriteSpanFn<0x1bE>,gpuSpriteSpanFn<0x1bF>,
-	gpuSpriteSpanFn<0x1c0>,gpuSpriteSpanFn<0x1c1>,gpuSpriteSpanFn<0x1c2>,gpuSpriteSpanFn<0x1c3>,  gpuSpriteSpanFn<0x1c4>,gpuSpriteSpanFn<0x1c5>,gpuSpriteSpanFn<0x1c6>,gpuSpriteSpanFn<0x1c7>,  NULL,NULL,gpuSpriteSpanFn<0x1cA>,gpuSpriteSpanFn<0x1cB>,  NULL,NULL,gpuSpriteSpanFn<0x1cE>,gpuSpriteSpanFn<0x1cF>,
-	NULL,NULL,gpuSpriteSpanFn<0x1d2>,gpuSpriteSpanFn<0x1d3>,  NULL,NULL,gpuSpriteSpanFn<0x1d6>,gpuSpriteSpanFn<0x1d7>,  NULL,NULL,gpuSpriteSpanFn<0x1dA>,gpuSpriteSpanFn<0x1dB>,  NULL,NULL,gpuSpriteSpanFn<0x1dE>,gpuSpriteSpanFn<0x1dF>,
-	gpuSpriteSpanFn<0x1e0>,gpuSpriteSpanFn<0x1e1>,gpuSpriteSpanFn<0x1e2>,gpuSpriteSpanFn<0x1e3>,  gpuSpriteSpanFn<0x1e4>,gpuSpriteSpanFn<0x1e5>,gpuSpriteSpanFn<0x1e6>,gpuSpriteSpanFn<0x1e7>,  NULL,NULL,gpuSpriteSpanFn<0x1eA>,gpuSpriteSpanFn<0x1eB>,  NULL,NULL,gpuSpriteSpanFn<0x1eE>,gpuSpriteSpanFn<0x1eF>,
-	NULL,NULL,gpuSpriteSpanFn<0x1f2>,gpuSpriteSpanFn<0x1f3>,  NULL,NULL,gpuSpriteSpanFn<0x1f6>,gpuSpriteSpanFn<0x1f7>,  NULL,NULL,gpuSpriteSpanFn<0x1fA>,gpuSpriteSpanFn<0x1fB>,  NULL,NULL,gpuSpriteSpanFn<0x1fE>,gpuSpriteSpanFn<0x1fF>
+typedef void (*PS)(u16 *pDst, u32 count, u8* pTxt, u32 u0);
+
+// Template instantiation helper macros
+#define TI(cf) gpuSpriteSpanFn<(cf)>
+#define TN     SpriteNULL
+#define TIBLOCK(ub) \
+	TN,            TN,            TN,            TN,            TN,            TN,            TN,            TN,            \
+	TN,            TN,            TN,            TN,            TN,            TN,            TN,            TN,            \
+	TN,            TN,            TN,            TN,            TN,            TN,            TN,            TN,            \
+	TN,            TN,            TN,            TN,            TN,            TN,            TN,            TN,            \
+	TI((ub)|0x20), TI((ub)|0x21), TI((ub)|0x22), TI((ub)|0x23), TI((ub)|0x24), TI((ub)|0x25), TI((ub)|0x26), TI((ub)|0x27), \
+	TN,            TN,            TI((ub)|0x2a), TI((ub)|0x2b), TN,            TN,            TI((ub)|0x2e), TI((ub)|0x2f), \
+	TN,            TN,            TI((ub)|0x32), TI((ub)|0x33), TN,            TN,            TI((ub)|0x36), TI((ub)|0x37), \
+	TN,            TN,            TI((ub)|0x3a), TI((ub)|0x3b), TN,            TN,            TI((ub)|0x3e), TI((ub)|0x3f), \
+	TI((ub)|0x40), TI((ub)|0x41), TI((ub)|0x42), TI((ub)|0x43), TI((ub)|0x44), TI((ub)|0x45), TI((ub)|0x46), TI((ub)|0x47), \
+	TN,            TN,            TI((ub)|0x4a), TI((ub)|0x4b), TN,            TN,            TI((ub)|0x4e), TI((ub)|0x4f), \
+	TN,            TN,            TI((ub)|0x52), TI((ub)|0x53), TN,            TN,            TI((ub)|0x56), TI((ub)|0x57), \
+	TN,            TN,            TI((ub)|0x5a), TI((ub)|0x5b), TN,            TN,            TI((ub)|0x5e), TI((ub)|0x5f), \
+	TI((ub)|0x60), TI((ub)|0x61), TI((ub)|0x62), TI((ub)|0x63), TI((ub)|0x64), TI((ub)|0x65), TI((ub)|0x66), TI((ub)|0x67), \
+	TN,            TN,            TI((ub)|0x6a), TI((ub)|0x6b), TN,            TN,            TI((ub)|0x6e), TI((ub)|0x6f), \
+	TN,            TN,            TI((ub)|0x72), TI((ub)|0x73), TN,            TN,            TI((ub)|0x76), TI((ub)|0x77), \
+	TN,            TN,            TI((ub)|0x7a), TI((ub)|0x7b), TN,            TN,            TI((ub)|0x7e), TI((ub)|0x7f)
+
+const PS gpuSpriteSpanDrivers[256] = {
+	TIBLOCK(0<<8), TIBLOCK(1<<8)
 };
 
+#undef TI
+#undef TN
+#undef TIBLOCK
+
 ///////////////////////////////////////////////////////////////////////////////
 //  GPU Polygon innerloops generator
-template<const int CF>
-INLINE void  gpuPolySpanFn(u16 *pDst, u32 count)
+
+//senquack - Newer version with following changes:
+//           * Adapted to work with new poly routings in gpu_raster_polygon.h
+//             adapted from DrHell GPU. They are less glitchy and use 22.10
+//             fixed-point instead of original UNAI's 16.16.
+//           * Texture coordinates are no longer packed together into one
+//             unsigned int. This seems to lose too much accuracy (they each
+//             end up being only 8.7 fixed-point that way) and pixel-droupouts
+//             were noticeable both with original code and current DrHell
+//             adaptations. An example would be the sky in NFS3. Now, they are
+//             stored in separate ints, using separate masks.
+//           * Function is no longer INLINE, as it was always called
+//             through a function pointer.
+//           * Function now ensures the mask bit of source texture is preserved
+//             across calls to blending functions (Silent Hill rectangles fix)
+//           * November 2016: Large refactoring of blending/lighting when
+//             JohnnyF added dithering. See gpu_inner_quantization.h and
+//             relevant blend/light headers.
+// (see README_senquack.txt)
+template<int CF>
+static void gpuPolySpanFn(const gpu_unai_t &gpu_unai, u16 *pDst, u32 count)
 {
-	if (!TM)
-	{	
-		// NO TEXTURE
-		if (!G)
+	// Blend func can save an operation if it knows uSrc MSB is unset.
+	//  Untextured prims can always skip this (src color MSB is always 0).
+	//  For textured prims, lighting funcs always return it unset. (bonus!)
+	const bool skip_uSrc_mask = (!CF_TEXTMODE) || CF_LIGHT;
+
+	u32 bMsk; if (CF_BLITMASK) bMsk = gpu_unai.blit_mask;
+
+	if (!CF_TEXTMODE)
+	{
+		if (!CF_GOURAUD)
 		{
-			// NO GOURAUD
-			u16 data;
-			if (L) { u32 lCol=((u32)(b4<< 2)&(0x03ff)) | ((u32)(g4<<13)&(0x07ff<<10)) | ((u32)(r4<<24)&(0x07ff<<21)); gpuLightingRGB(data,lCol); }
-			else data=PixelData;
-			if ((!M)&&(!B))
-			{
-				if (MB) { data = data | 0x8000; }
-				do { *pDst++ = data; } while (--count);
-			}
-			else if ((M)&&(!B))
-			{
-				if (MB) { data = data | 0x8000; }
-				do { if (!(*pDst&0x8000)) { *pDst = data; } pDst++; } while (--count);
-			}
-			else
-			{
-				u16 uSrc;
-				u16 uDst;
-				u32 uMsk; if (BM==0) uMsk=0x7BDE;
-				do
-				{
-					//  masking
-					uDst = *pDst;
-					if(M) { if (uDst&0x8000) goto endtile;  }
-					uSrc = data;
-					//  blend
-					if (BM==0) gpuBlending00(uSrc, uDst);
-					if (BM==1) gpuBlending01(uSrc, uDst);
-					if (BM==2) gpuBlending02(uSrc, uDst);
-					if (BM==3) gpuBlending03(uSrc, uDst);
-					if (MB) { *pDst = uSrc | 0x8000; }
-					else    { *pDst = uSrc; }
-					endtile: pDst++;
-				}
-				while (--count);
-			}
+			// UNTEXTURED, NO GOURAUD
+			const u16 pix15 = gpu_unai.PixelData;
+			do {
+				u16 uSrc, uDst;
+
+				// NOTE: Don't enable CF_BLITMASK  pixel skipping (speed hack)
+				//  on untextured polys. It seems to do more harm than good: see
+				//  gravestone text at end of Medieval intro sequence. -senquack
+				//if (CF_BLITMASK) { if ((bMsk>>((((uintptr_t)pDst)>>1)&7))&1) { goto endpolynotextnogou; } }
+
+				if (CF_BLEND || CF_MASKCHECK) uDst = *pDst;
+				if (CF_MASKCHECK) { if (uDst&0x8000) { goto endpolynotextnogou; } }
+
+				uSrc = pix15;
+
+				if (CF_BLEND)
+					uSrc = gpuBlending<CF_BLENDMODE, skip_uSrc_mask>(uSrc, uDst);
+
+				if (CF_MASKSET) { *pDst = uSrc | 0x8000; }
+				else            { *pDst = uSrc;          }
+
+endpolynotextnogou:
+				pDst++;
+			} while(--count);
 		}
 		else
 		{
-			// GOURAUD
-			u16 uDst;
-			u16 uSrc;
-			u32 linc=lInc;
-			u32 lCol=((u32)(b4>>14)&(0x03ff)) | ((u32)(g4>>3)&(0x07ff<<10)) | ((u32)(r4<<8)&(0x07ff<<21));
-			u32 uMsk; if ((B)&&(BM==0)) uMsk=0x7BDE;
-			do
-			{
-				//  masking
-				if(M) { uDst = *pDst;  if (uDst&0x8000) goto endgou;  }
-				//  blend
-				if(B)
-				{
-					//  light
-					gpuLightingRGB(uSrc,lCol);
-					if(!M)    { uDst = *pDst; }
-					if (BM==0) gpuBlending00(uSrc, uDst);
-					if (BM==1) gpuBlending01(uSrc, uDst);
-					if (BM==2) gpuBlending02(uSrc, uDst);
-					if (BM==3) gpuBlending03(uSrc, uDst);
-				}
-				else
-				{
-					//  light
-					gpuLightingRGB(uSrc,lCol);
+			// UNTEXTURED, GOURAUD
+			u32 l_gCol = gpu_unai.gCol;
+			u32 l_gInc = gpu_unai.gInc;
+
+			do {
+				u16 uDst, uSrc;
+
+				// See note in above loop regarding CF_BLITMASK
+				//if (CF_BLITMASK) { if ((bMsk>>((((uintptr_t)pDst)>>1)&7))&1) goto endpolynotextgou; }
+
+				if (CF_BLEND || CF_MASKCHECK) uDst = *pDst;
+				if (CF_MASKCHECK) { if (uDst&0x8000) goto endpolynotextgou; }
+
+				if (CF_DITHER) {
+					// GOURAUD, DITHER
+
+					u32 uSrc24 = gpuLightingRGB24(l_gCol);
+					if (CF_BLEND)
+						uSrc24 = gpuBlending24<CF_BLENDMODE>(uSrc24, uDst);
+					uSrc = gpuColorQuantization24<CF_DITHER>(uSrc24, pDst);
+				} else {
+					// GOURAUD, NO DITHER
+
+					uSrc = gpuLightingRGB(l_gCol);
+
+					if (CF_BLEND)
+						uSrc = gpuBlending<CF_BLENDMODE, skip_uSrc_mask>(uSrc, uDst);
 				}
-				if (MB) { *pDst = uSrc | 0x8000; }
-				else    { *pDst = uSrc; }
-				endgou: pDst++; lCol=(lCol+linc);
+
+				if (CF_MASKSET) { *pDst = uSrc | 0x8000; }
+				else            { *pDst = uSrc;          }
+
+endpolynotextgou:
+				pDst++;
+				l_gCol += l_gInc;
 			}
 			while (--count);
 		}
 	}
 	else
 	{
-		// TEXTURE
-		u16 uDst;
-		u16 uSrc;
-		u32 linc; if (L&&G) linc=lInc;
-		u32 tinc=tInc;
-		u32 tmsk=tMsk;
-		u32 tCor = ((u32)( u4<<7)&0x7fff0000) | ((u32)( v4>>9)&0x00007fff); tCor&= tmsk;
-		const u16* _TBA=TBA;
-		const u16* _CBA; if (TM!=3) _CBA=CBA;
-		u32 lCol;
-		if(L && !G) { lCol = ((u32)(b4<< 2)&(0x03ff)) | ((u32)(g4<<13)&(0x07ff<<10)) | ((u32)(r4<<24)&(0x07ff<<21)); }
-		else if(L && G) { lCol = ((u32)(b4>>14)&(0x03ff)) | ((u32)(g4>>3)&(0x07ff<<10)) | ((u32)(r4<<8)&(0x07ff<<21)); 	}
-		u32 uMsk; if ((B)&&(BM==0)) uMsk=0x7BDE;
+		// TEXTURED
+
+		u16 uDst, uSrc, srcMSB;
+
+		//senquack - note: original UNAI code had gpu_unai.{u4/v4} packed into
+		// one 32-bit unsigned int, but this proved to lose too much accuracy
+		// (pixel drouputs noticeable in NFS3 sky), so now are separate vars.
+		u32 l_u_msk = gpu_unai.u_msk;     u32 l_v_msk = gpu_unai.v_msk;
+		u32 l_u = gpu_unai.u & l_u_msk;   u32 l_v = gpu_unai.v & l_v_msk;
+		s32 l_u_inc = gpu_unai.u_inc;     s32 l_v_inc = gpu_unai.v_inc;
+
+		const u16* TBA_ = gpu_unai.TBA;
+		const u16* CBA_; if (CF_TEXTMODE!=3) CBA_ = gpu_unai.CBA;
+
+		u8 r5, g5, b5;
+		u8 r8, g8, b8;
+
+		u32 l_gInc, l_gCol;
+
+		if (CF_LIGHT) {
+			if (CF_GOURAUD) {
+				l_gInc = gpu_unai.gInc;
+				l_gCol = gpu_unai.gCol;
+			} else {
+				if (CF_DITHER) {
+					r8 = gpu_unai.r8;
+					g8 = gpu_unai.g8;
+					b8 = gpu_unai.b8;
+				} else {
+					r5 = gpu_unai.r5;
+					g5 = gpu_unai.g5;
+					b5 = gpu_unai.b5;
+				}
+			}
+		}
+
 		do
 		{
-			//  masking
-			if(M) { uDst = *pDst;  if (uDst&0x8000) goto endpoly;  }
-			//  texture
-			if (TM==1) { u32 tu=(tCor>>23); u32 tv=(tCor<<4)&(0xff<<11); u8 rgb=((u8*)_TBA)[tv+(tu>>1)]; uSrc=_CBA[(rgb>>((tu&1)<<2))&0xf]; if(!uSrc) goto endpoly; }
-			if (TM==2) { uSrc = _CBA[(((u8*)_TBA)[(tCor>>23)+((tCor<<4)&(0xff<<11))])]; if(!uSrc)  goto endpoly; }
-			if (TM==3) { uSrc = _TBA[(tCor>>23)+((tCor<<3)&(0xff<<10))]; if(!uSrc)  goto endpoly; }
-			//  blend
-			if(B)
-			{
-				if (uSrc&0x8000)
-				{
-					//  light
-					if(L) gpuLightingTXT(uSrc, lCol);
-					if(!M)    { uDst = *pDst; }
-					if (BM==0) gpuBlending00(uSrc, uDst);
-					if (BM==1) gpuBlending01(uSrc, uDst);
-					if (BM==2) gpuBlending02(uSrc, uDst);
-					if (BM==3) gpuBlending03(uSrc, uDst);
-				}
-				else
-				{
-					// light
-					if(L) gpuLightingTXT(uSrc, lCol);
-				}
+			if (CF_BLITMASK) { if ((bMsk>>((((uintptr_t)pDst)>>1)&7))&1) goto endpolytext; }
+			if (CF_MASKCHECK || CF_BLEND) { uDst = *pDst; }
+			if (CF_MASKCHECK) if (uDst&0x8000) { goto endpolytext; }
+
+			//senquack - adapted to work with new 22.10 fixed point routines:
+			//           (UNAI originally used 16.16)
+			if (CF_TEXTMODE==1) {  //  4bpp (CLUT)
+				u32 tu=(l_u>>10);
+				u32 tv=(l_v<<1)&(0xff<<11);
+				u8 rgb=((u8*)TBA_)[tv+(tu>>1)];
+				uSrc=CBA_[(rgb>>((tu&1)<<2))&0xf];
+				if (!uSrc) goto endpolytext;
+			}
+			if (CF_TEXTMODE==2) {  //  8bpp (CLUT)
+				uSrc = CBA_[(((u8*)TBA_)[(l_u>>10)+((l_v<<1)&(0xff<<11))])];
+				if (!uSrc) goto endpolytext;
 			}
-			else
+			if (CF_TEXTMODE==3) {  // 16bpp
+				uSrc = TBA_[(l_u>>10)+((l_v)&(0xff<<10))];
+				if (!uSrc) goto endpolytext;
+			}
+
+			// Save source MSB, as blending or lighting will not (Silent Hill)
+			if (CF_BLEND || CF_LIGHT) srcMSB = uSrc & 0x8000;
+
+			// When textured, only dither when LIGHT (texture blend) is enabled
+			// LIGHT &&  BLEND => dither
+			// LIGHT && !BLEND => dither
+			//!LIGHT &&  BLEND => no dither
+			//!LIGHT && !BLEND => no dither
+
+			if (CF_DITHER && CF_LIGHT) {
+				u32 uSrc24;
+				if ( CF_GOURAUD)
+					uSrc24 = gpuLightingTXT24Gouraud(uSrc, l_gCol);
+				if (!CF_GOURAUD)
+					uSrc24 = gpuLightingTXT24(uSrc, r8, g8, b8);
+
+				if (CF_BLEND && srcMSB)
+					uSrc24 = gpuBlending24<CF_BLENDMODE>(uSrc24, uDst);
+
+				uSrc = gpuColorQuantization24<CF_DITHER>(uSrc24, pDst);
+			} else
 			{
-				//  light
-				if(L)  { gpuLightingTXT(uSrc, lCol); } else if(!MB) { uSrc&= 0x7fff; }
+				if (CF_LIGHT) {
+					if ( CF_GOURAUD)
+						uSrc = gpuLightingTXTGouraud(uSrc, l_gCol);
+					if (!CF_GOURAUD)
+						uSrc = gpuLightingTXT(uSrc, r5, g5, b5);
+				}
+
+				if (CF_BLEND && srcMSB)
+					uSrc = gpuBlending<CF_BLENDMODE, skip_uSrc_mask>(uSrc, uDst);
 			}
-			if (MB) { *pDst = uSrc | 0x8000; }
-			else    { *pDst = uSrc; }
-			endpoly: pDst++;
-			tCor=(tCor+tinc)&tmsk;
-			if (L&&G) lCol=(lCol+linc);
+
+			if (CF_MASKSET)                { *pDst = uSrc | 0x8000; }
+			else if (CF_BLEND || CF_LIGHT) { *pDst = uSrc | srcMSB; }
+			else                           { *pDst = uSrc;          }
+endpolytext:
+			pDst++;
+			l_u = (l_u + l_u_inc) & l_u_msk;
+			l_v = (l_v + l_v_inc) & l_v_msk;
+			if (CF_LIGHT && CF_GOURAUD) l_gCol += l_gInc;
 		}
 		while (--count);
 	}
 }
 
-// supposedly shouldn't be called?
-static void gpuPolySpanFn_NULL_(u16 *pDst, u32 count)
+static void PolyNULL(const gpu_unai_t &gpu_unai, u16 *pDst, u32 count)
 {
+	#ifdef ENABLE_GPU_LOG_SUPPORT
+		fprintf(stdout,"PolyNULL()\n");
+	#endif
 }
 
-///////////////////////////////////////////////////////////////////////////////
-
 ///////////////////////////////////////////////////////////////////////////////
 //  Polygon innerloops driver
-typedef void (*PP)(u16 *pDst, u32 count);
-const PP gpuPolySpanDrivers[512] =
-{
-	gpuPolySpanFn<0x00>,gpuPolySpanFn<0x01>,gpuPolySpanFn<0x02>,gpuPolySpanFn<0x03>,  gpuPolySpanFn<0x04>,gpuPolySpanFn<0x05>,gpuPolySpanFn<0x06>,gpuPolySpanFn<0x07>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x0A>,gpuPolySpanFn<0x0B>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x0E>,gpuPolySpanFn<0x0F>,
-	gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x12>,gpuPolySpanFn<0x13>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x16>,gpuPolySpanFn<0x17>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1A>,gpuPolySpanFn<0x1B>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1E>,gpuPolySpanFn<0x1F>,
-	gpuPolySpanFn<0x20>,gpuPolySpanFn<0x21>,gpuPolySpanFn<0x22>,gpuPolySpanFn<0x23>,  gpuPolySpanFn<0x24>,gpuPolySpanFn<0x25>,gpuPolySpanFn<0x26>,gpuPolySpanFn<0x27>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x2A>,gpuPolySpanFn<0x2B>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x2E>,gpuPolySpanFn<0x2F>,
-	gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x32>,gpuPolySpanFn<0x33>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x36>,gpuPolySpanFn<0x37>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x3A>,gpuPolySpanFn<0x3B>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x3E>,gpuPolySpanFn<0x3F>,
-	gpuPolySpanFn<0x40>,gpuPolySpanFn<0x41>,gpuPolySpanFn<0x42>,gpuPolySpanFn<0x43>,  gpuPolySpanFn<0x44>,gpuPolySpanFn<0x45>,gpuPolySpanFn<0x46>,gpuPolySpanFn<0x47>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x4A>,gpuPolySpanFn<0x4B>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x4E>,gpuPolySpanFn<0x4F>,
-	gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x52>,gpuPolySpanFn<0x53>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x56>,gpuPolySpanFn<0x57>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x5A>,gpuPolySpanFn<0x5B>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x5E>,gpuPolySpanFn<0x5F>,
-	gpuPolySpanFn<0x60>,gpuPolySpanFn<0x61>,gpuPolySpanFn<0x62>,gpuPolySpanFn<0x63>,  gpuPolySpanFn<0x64>,gpuPolySpanFn<0x65>,gpuPolySpanFn<0x66>,gpuPolySpanFn<0x67>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x6A>,gpuPolySpanFn<0x6B>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x6E>,gpuPolySpanFn<0x6F>,
-	gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x72>,gpuPolySpanFn<0x73>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x76>,gpuPolySpanFn<0x77>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x7A>,gpuPolySpanFn<0x7B>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x7E>,gpuPolySpanFn<0x7F>,
-
-	gpuPolySpanFn_NULL_,gpuPolySpanFn<0x81>,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x83>,  gpuPolySpanFn_NULL_,gpuPolySpanFn<0x85>,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x87>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x8B>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x8F>,
-	gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x93>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x97>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x9B>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x9F>,
-	gpuPolySpanFn_NULL_,gpuPolySpanFn<0xa1>,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xa3>,  gpuPolySpanFn_NULL_,gpuPolySpanFn<0xa5>,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xa7>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xaB>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xaF>,
-	gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xb3>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xb7>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xbB>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xbF>,
-	gpuPolySpanFn_NULL_,gpuPolySpanFn<0xc1>,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xc3>,  gpuPolySpanFn_NULL_,gpuPolySpanFn<0xc5>,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xc7>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xcB>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xcF>,
-	gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xd3>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xd7>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xdB>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xdF>,
-	gpuPolySpanFn_NULL_,gpuPolySpanFn<0xe1>,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xe3>,  gpuPolySpanFn_NULL_,gpuPolySpanFn<0xe5>,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xe7>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xeB>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xeF>,
-	gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xf3>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xf7>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xfB>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0xfF>,
-
-	gpuPolySpanFn<0x100>,gpuPolySpanFn<0x101>,gpuPolySpanFn<0x102>,gpuPolySpanFn<0x103>,  gpuPolySpanFn<0x104>,gpuPolySpanFn<0x105>,gpuPolySpanFn<0x106>,gpuPolySpanFn<0x107>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x10A>,gpuPolySpanFn<0x10B>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x10E>,gpuPolySpanFn<0x10F>,
-	gpuPolySpanFn_NULL_, gpuPolySpanFn_NULL_, gpuPolySpanFn<0x112>,gpuPolySpanFn<0x113>,  gpuPolySpanFn_NULL_, gpuPolySpanFn_NULL_, gpuPolySpanFn<0x116>,gpuPolySpanFn<0x117>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x11A>,gpuPolySpanFn<0x11B>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x11E>,gpuPolySpanFn<0x11F>,
-	gpuPolySpanFn<0x120>,gpuPolySpanFn<0x121>,gpuPolySpanFn<0x122>,gpuPolySpanFn<0x123>,  gpuPolySpanFn<0x124>,gpuPolySpanFn<0x125>,gpuPolySpanFn<0x126>,gpuPolySpanFn<0x127>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x12A>,gpuPolySpanFn<0x12B>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x12E>,gpuPolySpanFn<0x12F>,
-	gpuPolySpanFn_NULL_, gpuPolySpanFn_NULL_, gpuPolySpanFn<0x132>,gpuPolySpanFn<0x133>,  gpuPolySpanFn_NULL_, gpuPolySpanFn_NULL_, gpuPolySpanFn<0x136>,gpuPolySpanFn<0x137>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x13A>,gpuPolySpanFn<0x13B>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x13E>,gpuPolySpanFn<0x13F>,
-	gpuPolySpanFn<0x140>,gpuPolySpanFn<0x141>,gpuPolySpanFn<0x142>,gpuPolySpanFn<0x143>,  gpuPolySpanFn<0x144>,gpuPolySpanFn<0x145>,gpuPolySpanFn<0x146>,gpuPolySpanFn<0x147>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x14A>,gpuPolySpanFn<0x14B>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x14E>,gpuPolySpanFn<0x14F>,
-	gpuPolySpanFn_NULL_, gpuPolySpanFn_NULL_, gpuPolySpanFn<0x152>,gpuPolySpanFn<0x153>,  gpuPolySpanFn_NULL_, gpuPolySpanFn_NULL_, gpuPolySpanFn<0x156>,gpuPolySpanFn<0x157>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x15A>,gpuPolySpanFn<0x15B>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x15E>,gpuPolySpanFn<0x15F>,
-	gpuPolySpanFn<0x160>,gpuPolySpanFn<0x161>,gpuPolySpanFn<0x162>,gpuPolySpanFn<0x163>,  gpuPolySpanFn<0x164>,gpuPolySpanFn<0x165>,gpuPolySpanFn<0x166>,gpuPolySpanFn<0x167>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x16A>,gpuPolySpanFn<0x16B>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x16E>,gpuPolySpanFn<0x16F>,
-	gpuPolySpanFn_NULL_, gpuPolySpanFn_NULL_, gpuPolySpanFn<0x172>,gpuPolySpanFn<0x173>,  gpuPolySpanFn_NULL_, gpuPolySpanFn_NULL_, gpuPolySpanFn<0x176>,gpuPolySpanFn<0x177>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x17A>,gpuPolySpanFn<0x17B>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x17E>,gpuPolySpanFn<0x17F>,
-                                                                                                                                                                                                                                                                                                                                                                                      
-	gpuPolySpanFn_NULL_,gpuPolySpanFn<0x181>,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x183>,  gpuPolySpanFn_NULL_,gpuPolySpanFn<0x185>,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x187>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x18B>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x18F>,
-	gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_, gpuPolySpanFn_NULL_,gpuPolySpanFn<0x193>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_, gpuPolySpanFn_NULL_,gpuPolySpanFn<0x197>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x19B>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x19F>,
-	gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1a1>,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1a3>,  gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1a5>,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1a7>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1aB>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1aF>,
-	gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_, gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1b3>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_, gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1b7>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1bB>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1bF>,
-	gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1c1>,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1c3>,  gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1c5>,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1c7>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1cB>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1cF>,
-	gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_, gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1d3>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_, gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1d7>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1dB>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1dF>,
-	gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1e1>,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1e3>,  gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1e5>,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1e7>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1eB>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1eF>,
-	gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_, gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1f3>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_, gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1f7>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1fB>,  gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn_NULL_,gpuPolySpanFn<0x1fF>
+typedef void (*PP)(const gpu_unai_t &gpu_unai, u16 *pDst, u32 count);
+
+// Template instantiation helper macros
+#define TI(cf) gpuPolySpanFn<(cf)>
+#define TN     PolyNULL
+#define TIBLOCK(ub) \
+	TI((ub)|0x00), TI((ub)|0x01), TI((ub)|0x02), TI((ub)|0x03), TI((ub)|0x04), TI((ub)|0x05), TI((ub)|0x06), TI((ub)|0x07), \
+	TN,            TN,            TI((ub)|0x0a), TI((ub)|0x0b), TN,            TN,            TI((ub)|0x0e), TI((ub)|0x0f), \
+	TN,            TN,            TI((ub)|0x12), TI((ub)|0x13), TN,            TN,            TI((ub)|0x16), TI((ub)|0x17), \
+	TN,            TN,            TI((ub)|0x1a), TI((ub)|0x1b), TN,            TN,            TI((ub)|0x1e), TI((ub)|0x1f), \
+	TI((ub)|0x20), TI((ub)|0x21), TI((ub)|0x22), TI((ub)|0x23), TI((ub)|0x24), TI((ub)|0x25), TI((ub)|0x26), TI((ub)|0x27), \
+	TN,            TN,            TI((ub)|0x2a), TI((ub)|0x2b), TN,            TN,            TI((ub)|0x2e), TI((ub)|0x2f), \
+	TN,            TN,            TI((ub)|0x32), TI((ub)|0x33), TN,            TN,            TI((ub)|0x36), TI((ub)|0x37), \
+	TN,            TN,            TI((ub)|0x3a), TI((ub)|0x3b), TN,            TN,            TI((ub)|0x3e), TI((ub)|0x3f), \
+	TI((ub)|0x40), TI((ub)|0x41), TI((ub)|0x42), TI((ub)|0x43), TI((ub)|0x44), TI((ub)|0x45), TI((ub)|0x46), TI((ub)|0x47), \
+	TN,            TN,            TI((ub)|0x4a), TI((ub)|0x4b), TN,            TN,            TI((ub)|0x4e), TI((ub)|0x4f), \
+	TN,            TN,            TI((ub)|0x52), TI((ub)|0x53), TN,            TN,            TI((ub)|0x56), TI((ub)|0x57), \
+	TN,            TN,            TI((ub)|0x5a), TI((ub)|0x5b), TN,            TN,            TI((ub)|0x5e), TI((ub)|0x5f), \
+	TI((ub)|0x60), TI((ub)|0x61), TI((ub)|0x62), TI((ub)|0x63), TI((ub)|0x64), TI((ub)|0x65), TI((ub)|0x66), TI((ub)|0x67), \
+	TN,            TN,            TI((ub)|0x6a), TI((ub)|0x6b), TN,            TN,            TI((ub)|0x6e), TI((ub)|0x6f), \
+	TN,            TN,            TI((ub)|0x72), TI((ub)|0x73), TN,            TN,            TI((ub)|0x76), TI((ub)|0x77), \
+	TN,            TN,            TI((ub)|0x7a), TI((ub)|0x7b), TN,            TN,            TI((ub)|0x7e), TI((ub)|0x7f), \
+	TN,            TI((ub)|0x81), TN,            TI((ub)|0x83), TN,            TI((ub)|0x85), TN,            TI((ub)|0x87), \
+	TN,            TN,            TN,            TI((ub)|0x8b), TN,            TN,            TN,            TI((ub)|0x8f), \
+	TN,            TN,            TN,            TI((ub)|0x93), TN,            TN,            TN,            TI((ub)|0x97), \
+	TN,            TN,            TN,            TI((ub)|0x9b), TN,            TN,            TN,            TI((ub)|0x9f), \
+	TN,            TI((ub)|0xa1), TN,            TI((ub)|0xa3), TN,            TI((ub)|0xa5), TN,            TI((ub)|0xa7), \
+	TN,            TN,            TN,            TI((ub)|0xab), TN,            TN,            TN,            TI((ub)|0xaf), \
+	TN,            TN,            TN,            TI((ub)|0xb3), TN,            TN,            TN,            TI((ub)|0xb7), \
+	TN,            TN,            TN,            TI((ub)|0xbb), TN,            TN,            TN,            TI((ub)|0xbf), \
+	TN,            TI((ub)|0xc1), TN,            TI((ub)|0xc3), TN,            TI((ub)|0xc5), TN,            TI((ub)|0xc7), \
+	TN,            TN,            TN,            TI((ub)|0xcb), TN,            TN,            TN,            TI((ub)|0xcf), \
+	TN,            TN,            TN,            TI((ub)|0xd3), TN,            TN,            TN,            TI((ub)|0xd7), \
+	TN,            TN,            TN,            TI((ub)|0xdb), TN,            TN,            TN,            TI((ub)|0xdf), \
+	TN,            TI((ub)|0xe1), TN,            TI((ub)|0xe3), TN,            TI((ub)|0xe5), TN,            TI((ub)|0xe7), \
+	TN,            TN,            TN,            TI((ub)|0xeb), TN,            TN,            TN,            TI((ub)|0xef), \
+	TN,            TN,            TN,            TI((ub)|0xf3), TN,            TN,            TN,            TI((ub)|0xf7), \
+	TN,            TN,            TN,            TI((ub)|0xfb), TN,            TN,            TN,            TI((ub)|0xff)
+
+const PP gpuPolySpanDrivers[2048] = {
+	TIBLOCK(0<<8), TIBLOCK(1<<8), TIBLOCK(2<<8), TIBLOCK(3<<8),
+	TIBLOCK(4<<8), TIBLOCK(5<<8), TIBLOCK(6<<8), TIBLOCK(7<<8)
 };
+
+#undef TI
+#undef TN
+#undef TIBLOCK
diff --git a/plugins/gpu_unai/gpu_inner_blend.h b/plugins/gpu_unai/gpu_inner_blend.h
index ce439d3b..93c268bc 100644
--- a/plugins/gpu_unai/gpu_inner_blend.h
+++ b/plugins/gpu_unai/gpu_inner_blend.h
@@ -23,132 +23,166 @@
 
 //  GPU Blending operations functions
 
-#ifdef __arm__
-#define gpuBlending00(uSrc,uDst) \
-{ \
-	asm ("and  %[src], %[src], %[msk]\n" \
-	     "and  %[dst], %[dst], %[msk]\n" \
-	     "add  %[src], %[dst], %[src]\n" \
-	     "mov  %[src], %[src], lsr #1\n" \
-	 : [src] "=&r" (uSrc), [dst] "=&r" (uDst) : "0" (uSrc), "1" (uDst), [msk] "r" (uMsk)); \
-}
-#else
-#define gpuBlending00(uSrc,uDst) \
-{ \
-	uSrc = (((uDst & uMsk) + (uSrc & uMsk)) >> 1); \
-}
-#endif
+////////////////////////////////////////////////////////////////////////////////
+// Blend bgr555 color in 'uSrc' (foreground) with bgr555 color
+//  in 'uDst' (background), returning resulting color.
+//
+// INPUT:
+//  'uSrc','uDst' input: -bbbbbgggggrrrrr
+//                       ^ bit 16
+// OUTPUT:
+//           u16 output: 0bbbbbgggggrrrrr
+//                       ^ bit 16
+// RETURNS:
+// Where '0' is zero-padding, and '-' is don't care
+////////////////////////////////////////////////////////////////////////////////
+template <int BLENDMODE, bool SKIP_USRC_MSB_MASK>
+GPU_INLINE u16 gpuBlending(u16 uSrc, u16 uDst)
+{
+	// These use Blargg's bitwise modulo-clamping:
+	//  http://blargg.8bitalley.com/info/rgb_mixing.html
+	//  http://blargg.8bitalley.com/info/rgb_clamped_add.html
+	//  http://blargg.8bitalley.com/info/rgb_clamped_sub.html
 
-//	1.0 x Back + 1.0 x Forward
-#ifdef __arm__
-#define gpuBlending01(uSrc,uDst) \
-{ \
-	u32 st,dt,out; \
-	asm ("and    %[dt],  %[dst],   #0x7C00\n" \
-	     "and    %[st],  %[src],   #0x7C00\n" \
-	     "add    %[out], %[dt],    %[st]  \n" \
-	     "cmp    %[out], #0x7C00          \n" \
-	     "movhi  %[out], #0x7C00          \n" \
-	     "and    %[dt],  %[dst],   #0x03E0\n" \
-	     "and    %[st],  %[src],   #0x03E0\n" \
-	     "add    %[dt],  %[dt],    %[st]  \n" \
-	     "cmp    %[dt],  #0x03E0          \n" \
-	     "movhi  %[dt],  #0x03E0          \n" \
-	     "orr    %[out], %[out],   %[dt]  \n" \
-	     "and    %[dt],  %[dst],   #0x001F\n" \
-	     "and    %[st],  %[src],   #0x001F\n" \
-	     "add    %[dt],  %[dt],    %[st]  \n" \
-	     "cmp    %[dt],  #0x001F          \n" \
-	     "movhi  %[dt],  #0x001F          \n" \
-	     "orr    %[src], %[out],  %[dt]  \n" \
-	 : [src] "=r" (uSrc), [st] "=&r" (st), [dt] "=&r" (dt), [out] "=&r" (out) \
-	 : [dst] "r" (uDst), "0" (uSrc) : "cc"); \
-}
+	u16 mix;
+
+	// 0.5 x Back + 0.5 x Forward
+	if (BLENDMODE==0) {
+#ifdef GPU_UNAI_USE_ACCURATE_BLENDING
+		// Slower, but more accurate (doesn't lose LSB data)
+		uDst &= 0x7fff;
+		if (!SKIP_USRC_MSB_MASK)
+			uSrc &= 0x7fff;
+		mix = ((uSrc + uDst) - ((uSrc ^ uDst) & 0x0421)) >> 1;
 #else
-#define gpuBlending01(uSrc,uDst) \
-{ \
-	u16 rr, gg, bb; \
-	bb = (uDst & 0x7C00) + (uSrc & 0x7C00);   if (bb > 0x7C00)  bb = 0x7C00; \
-	gg = (uDst & 0x03E0) + (uSrc & 0x03E0);   if (gg > 0x03E0)  gg = 0x03E0;  bb |= gg; \
-	rr = (uDst & 0x001F) + (uSrc & 0x001F);   if (rr > 0x001F)  rr = 0x001F;  bb |= rr; \
-	uSrc = bb; \
-}
+		mix = ((uDst & 0x7bde) + (uSrc & 0x7bde)) >> 1;
 #endif
+	}
+
+	// 1.0 x Back + 1.0 x Forward
+	if (BLENDMODE==1) {
+		uDst &= 0x7fff;
+		if (!SKIP_USRC_MSB_MASK)
+			uSrc &= 0x7fff;
+		u32 sum      = uSrc + uDst;
+		u32 low_bits = (uSrc ^ uDst) & 0x0421;
+		u32 carries  = (sum - low_bits) & 0x8420;
+		u32 modulo   = sum - carries;
+		u32 clamp    = carries - (carries >> 5);
+		mix = modulo | clamp;
+	}
+
+	// 1.0 x Back - 1.0 x Forward
+	if (BLENDMODE==2) {
+		uDst &= 0x7fff;
+		if (!SKIP_USRC_MSB_MASK)
+			uSrc &= 0x7fff;
+		u32 diff     = uDst - uSrc + 0x8420;
+		u32 low_bits = (uDst ^ uSrc) & 0x8420;
+		u32 borrows  = (diff - low_bits) & 0x8420;
+		u32 modulo   = diff - borrows;
+		u32 clamp    = borrows - (borrows >> 5);
+		mix = modulo & clamp;
+	}
 
-//	1.0 x Back - 1.0 x Forward	*/
-#ifdef __arm__
-#define gpuBlending02(uSrc,uDst) \
-{ \
-	u32 st,dt,out; \
-	asm ("and    %[dt],  %[dst],   #0x7C00\n" \
-	     "and    %[st],  %[src],   #0x7C00\n" \
-	     "subs   %[out], %[dt],    %[st]  \n" \
-	     "movmi  %[out], #0x0000          \n" \
-	     "and    %[dt],  %[dst],   #0x03E0\n" \
-	     "and    %[st],  %[src],   #0x03E0\n" \
-	     "subs   %[dt],  %[dt],    %[st]  \n" \
-	     "orrpl  %[out], %[out],   %[dt]  \n" \
-	     "and    %[dt],  %[dst],   #0x001F\n" \
-	     "and    %[st],  %[src],   #0x001F\n" \
-	     "subs   %[dt],  %[dt],    %[st]  \n" \
-	     "orrpl  %[out], %[out],   %[dt]  \n" \
-	     "mov    %[src], %[out]           \n" \
-	 : [src] "=r" (uSrc), [st] "=&r" (st), [dt] "=&r" (dt), [out] "=&r" (out) \
-	 : [dst] "r" (uDst), "0" (uSrc) : "cc"); \
+	// 1.0 x Back + 0.25 x Forward
+	if (BLENDMODE==3) {
+		uDst &= 0x7fff;
+		uSrc = ((uSrc >> 2) & 0x1ce7);
+		u32 sum      = uSrc + uDst;
+		u32 low_bits = (uSrc ^ uDst) & 0x0421;
+		u32 carries  = (sum - low_bits) & 0x8420;
+		u32 modulo   = sum - carries;
+		u32 clamp    = carries - (carries >> 5);
+		mix = modulo | clamp;
+	}
+
+	return mix;
 }
 
-int btest(int s, int d)
+
+////////////////////////////////////////////////////////////////////////////////
+// Convert bgr555 color in uSrc to padded u32 5.4:5.4:5.4 bgr fixed-pt
+//  color triplet suitable for use with HQ 24-bit quantization.
+//
+// INPUT:
+//       'uDst' input: -bbbbbgggggrrrrr
+//                     ^ bit 16
+// RETURNS:
+//         u32 output: 000bbbbbXXXX0gggggXXXX0rrrrrXXXX
+//                     ^ bit 31
+// Where 'X' are fixed-pt bits, '0' is zero-padding, and '-' is don't care
+////////////////////////////////////////////////////////////////////////////////
+GPU_INLINE u32 gpuGetRGB24(u16 uSrc)
 {
-	gpuBlending02(s, d);
-	return s;
-}
-#else
-#define gpuBlending02(uSrc,uDst) \
-{ \
-	s32 rr, gg, bb; \
-	bb = (uDst & 0x7C00) - (uSrc & 0x7C00);   if (bb < 0)  bb  =  0; \
-	gg = (uDst & 0x03E0) - (uSrc & 0x03E0);   if (gg > 0)  bb |= gg; \
-	rr = (uDst & 0x001F) - (uSrc & 0x001F);   if (rr > 0)  bb |= rr; \
-	uSrc = bb; \
+	return ((uSrc & 0x7C00)<<14)
+	     | ((uSrc & 0x03E0)<< 9)
+	     | ((uSrc & 0x001F)<< 4);
 }
-#endif
 
-//	1.0 x Back + 0.25 x Forward	*/
-#ifdef __arm__
-#define gpuBlending03(uSrc,uDst) \
-{ \
-	u32 st,dt,out; \
-	asm ("mov    %[src], %[src],   lsr #2 \n" \
-	     "and    %[dt],  %[dst],   #0x7C00\n" \
-	     "and    %[st],  %[src],   #0x1C00\n" \
-	     "add    %[out], %[dt],    %[st]  \n" \
-	     "cmp    %[out], #0x7C00          \n" \
-	     "movhi  %[out], #0x7C00          \n" \
-	     "and    %[dt],  %[dst],   #0x03E0\n" \
-	     "and    %[st],  %[src],   #0x00E0\n" \
-	     "add    %[dt],  %[dt],    %[st]  \n" \
-	     "cmp    %[dt],  #0x03E0          \n" \
-	     "movhi  %[dt],  #0x03E0          \n" \
-	     "orr    %[out], %[out],   %[dt]  \n" \
-	     "and    %[dt],  %[dst],   #0x001F\n" \
-	     "and    %[st],  %[src],   #0x0007\n" \
-	     "add    %[dt],  %[dt],    %[st]  \n" \
-	     "cmp    %[dt],  #0x001F          \n" \
-	     "movhi  %[dt],  #0x001F          \n" \
-	     "orr    %[src], %[out],   %[dt]  \n" \
-	 : [src] "=r" (uSrc), [st] "=&r" (st), [dt] "=&r" (dt), [out] "=&r" (out) \
-	 : [dst] "r" (uDst), "0" (uSrc) : "cc"); \
-}
-#else
-#define gpuBlending03(uSrc,uDst) \
-{ \
-	u16 rr, gg, bb; \
-	uSrc >>= 2; \
-	bb = (uDst & 0x7C00) + (uSrc & 0x1C00);   if (bb > 0x7C00)  bb = 0x7C00; \
-	gg = (uDst & 0x03E0) + (uSrc & 0x00E0);   if (gg > 0x03E0)  gg = 0x03E0;  bb |= gg; \
-	rr = (uDst & 0x001F) + (uSrc & 0x0007);   if (rr > 0x001F)  rr = 0x001F;  bb |= rr; \
-	uSrc = bb; \
+
+////////////////////////////////////////////////////////////////////////////////
+// Blend padded u32 5.4:5.4:5.4 bgr fixed-pt color triplet in 'uSrc24'
+//  (foreground color) with bgr555 color in 'uDst' (background color),
+//  returning the resulting u32 5.4:5.4:5.4 color.
+//
+// INPUT:
+//     'uSrc24' input: 000bbbbbXXXX0gggggXXXX0rrrrrXXXX
+//                     ^ bit 31
+//       'uDst' input: -bbbbbgggggrrrrr
+//                     ^ bit 16
+// RETURNS:
+//         u32 output: 000bbbbbXXXX0gggggXXXX0rrrrrXXXX
+//                     ^ bit 31
+// Where 'X' are fixed-pt bits, '0' is zero-padding, and '-' is don't care
+////////////////////////////////////////////////////////////////////////////////
+template <int BLENDMODE>
+GPU_INLINE u32 gpuBlending24(u32 uSrc24, u16 uDst)
+{
+	// These use techniques adapted from Blargg's techniques mentioned in
+	//  in gpuBlending() comments above. Not as much bitwise trickery is
+	//  necessary because of presence of 0 padding in uSrc24 format.
+
+	u32 uDst24 = gpuGetRGB24(uDst);
+	u32 mix;
+
+	// 0.5 x Back + 0.5 x Forward
+	if (BLENDMODE==0) {
+		const u32 uMsk = 0x1FE7F9FE;
+		// Only need to mask LSBs of uSrc24, uDst24's LSBs are 0 already
+		mix = (uDst24 + (uSrc24 & uMsk)) >> 1;
+	}
+
+	// 1.0 x Back + 1.0 x Forward
+	if (BLENDMODE==1) {
+		u32 sum     = uSrc24 + uDst24;
+		u32 carries = sum & 0x20080200;
+		u32 modulo  = sum - carries;
+		u32 clamp   = carries - (carries >> 9);
+		mix = modulo | clamp;
+	}
+
+	// 1.0 x Back - 1.0 x Forward
+	if (BLENDMODE==2) {
+		// Insert ones in 0-padded borrow slot of color to be subtracted from
+		uDst24 |= 0x20080200;
+		u32 diff    = uDst24 - uSrc24;
+		u32 borrows = diff & 0x20080200;
+		u32 clamp   = borrows - (borrows >> 9);
+		mix = diff & clamp;
+	}
+
+	// 1.0 x Back + 0.25 x Forward
+	if (BLENDMODE==3) {
+		uSrc24 = (uSrc24 & 0x1FC7F1FC) >> 2;
+		u32 sum     = uSrc24 + uDst24;
+		u32 carries = sum & 0x20080200;
+		u32 modulo  = sum - carries;
+		u32 clamp   = carries - (carries >> 9);
+		mix = modulo | clamp;
+	}
+
+	return mix;
 }
-#endif
 
 #endif  //_OP_BLEND_H_
diff --git a/plugins/gpu_unai/gpu_inner_blend_arm5.h b/plugins/gpu_unai/gpu_inner_blend_arm5.h
new file mode 100644
index 00000000..0e9b74f1
--- /dev/null
+++ b/plugins/gpu_unai/gpu_inner_blend_arm5.h
@@ -0,0 +1,100 @@
+/***************************************************************************
+*   Copyright (C) 2010 PCSX4ALL Team                                      *
+*   Copyright (C) 2010 Unai                                               *
+*                                                                         *
+*   This program is free software; you can redistribute it and/or modify  *
+*   it under the terms of the GNU General Public License as published by  *
+*   the Free Software Foundation; either version 2 of the License, or     *
+*   (at your option) any later version.                                   *
+*                                                                         *
+*   This program is distributed in the hope that it will be useful,       *
+*   but WITHOUT ANY WARRANTY; without even the implied warranty of        *
+*   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the         *
+*   GNU General Public License for more details.                          *
+*                                                                         *
+*   You should have received a copy of the GNU General Public License     *
+*   along with this program; if not, write to the                         *
+*   Free Software Foundation, Inc.,                                       *
+*   51 Franklin Street, Fifth Floor, Boston, MA 02111-1307 USA.           *
+***************************************************************************/
+
+#ifndef _OP_BLEND_H_
+#define _OP_BLEND_H_
+
+//  GPU Blending operations functions
+
+#define gpuBlending00(uSrc,uDst) \
+{ \
+	asm ("and  %[src], %[src], %[msk]  " : [src] "=r" (uSrc) : "0" (uSrc), [msk] "r" (uMsk)                  ); \
+	asm ("and  %[dst], %[dst], %[msk]  " : [dst] "=r" (uDst) : "0" (uDst), [msk] "r" (uMsk)                  ); \
+	asm ("add  %[src], %[dst], %[src]  " : [src] "=r" (uSrc) :             [dst] "r" (uDst), "0" (uSrc)      ); \
+	asm ("mov  %[src], %[src], lsr #1  " : [src] "=r" (uSrc) : "0" (uSrc)                                    ); \
+}
+
+//	1.0 x Back + 1.0 x Forward
+#define gpuBlending01(uSrc,uDst) \
+{ \
+	u16 st,dt,out; \
+	asm ("and    %[dt],  %[dst],   #0x7C00  " : [dt]  "=r" (dt)   :             [dst] "r" (uDst)                    ); \
+	asm ("and    %[st],  %[src],   #0x7C00  " : [st]  "=r" (st)   :             [src] "r" (uSrc)                    ); \
+	asm ("add    %[out], %[dt],    %[st]    " : [out] "=r" (out)  :             [dt]  "r" (dt),   [st]  "r" (st)    ); \
+	asm ("cmp    %[out], #0x7C00            " :                   :             [out] "r" (out) : "cc"              ); \
+	asm ("movhi  %[out], #0x7C00            " : [out] "=r" (out)  : "0" (out)                                       ); \
+	asm ("and    %[dt],  %[dst],   #0x03E0  " : [dt]  "=r" (dt)   :             [dst] "r" (uDst)                    ); \
+	asm ("and    %[st],  %[src],   #0x03E0  " : [st]  "=r" (st)   :             [src] "r" (uSrc)                    ); \
+	asm ("add    %[dt],  %[dt],    %[st]    " : [dt]  "=r" (dt)   : "0" (dt),   [st]  "r" (st)                      ); \
+	asm ("cmp    %[dt],  #0x03E0            " :                   :             [dt]  "r" (dt) : "cc"               ); \
+	asm ("movhi  %[dt],  #0x03E0            " : [dt]  "=r" (dt)   : "0" (dt)                                        ); \
+	asm ("orr    %[out], %[out],   %[dt]    " : [out] "=r" (out)  : "0" (out),  [dt]  "r" (dt)                      ); \
+	asm ("and    %[dt],  %[dst],   #0x001F  " : [dt]  "=r" (dt)   :             [dst] "r" (uDst)                    ); \
+	asm ("and    %[st],  %[src],   #0x001F  " : [st]  "=r" (st)   :             [src] "r" (uSrc)                    ); \
+	asm ("add    %[dt],  %[dt],    %[st]    " : [dt]  "=r" (dt)   : "0" (dt),   [st]  "r" (st)                      ); \
+	asm ("cmp    %[dt],  #0x001F            " :                   :             [dt]  "r" (dt) : "cc"               ); \
+	asm ("movhi  %[dt],  #0x001F            " : [dt]  "=r" (dt)   : "0" (dt)                                        ); \
+	asm ("orr    %[uSrc], %[out],   %[dt]   " : [uSrc] "=r" (uSrc)  : [out] "r" (out),  [dt]  "r" (dt)              ); \
+}
+
+//	1.0 x Back - 1.0 x Forward	*/
+#define gpuBlending02(uSrc,uDst) \
+{ \
+	u16 st,dt,out; \
+	asm ("and    %[dt],  %[dst],   #0x7C00  " : [dt]  "=r" (dt)   :             [dst] "r" (uDst)                    ); \
+	asm ("and    %[st],  %[src],   #0x7C00  " : [st]  "=r" (st)   :             [src] "r" (uSrc)                    ); \
+	asm ("subs   %[out], %[dt],    %[st]    " : [out] "=r" (out)  : [dt]  "r" (dt),   [st]  "r" (st) : "cc"         ); \
+	asm ("movmi  %[out], #0x0000            " : [out] "=r" (out)  : "0" (out)                                       ); \
+	asm ("and    %[dt],  %[dst],   #0x03E0  " : [dt]  "=r" (dt)   :             [dst] "r" (uDst)                    ); \
+	asm ("and    %[st],  %[src],   #0x03E0  " : [st]  "=r" (st)   :             [src] "r" (uSrc)                    ); \
+	asm ("subs   %[dt],  %[dt],    %[st]    " : [dt]  "=r" (dt)   : "0" (dt),   [st]  "r" (st) : "cc"               ); \
+	asm ("orrpl  %[out], %[out],   %[dt]    " : [out] "=r" (out)  : "0" (out),  [dt]  "r" (dt)                      ); \
+	asm ("and    %[dt],  %[dst],   #0x001F  " : [dt]  "=r" (dt)   :             [dst] "r" (uDst)                    ); \
+	asm ("and    %[st],  %[src],   #0x001F  " : [st]  "=r" (st)   :             [src] "r" (uSrc)                    ); \
+	asm ("subs   %[dt],  %[dt],    %[st]    " : [dt]  "=r" (dt)   : "0" (dt),   [st]  "r" (st) : "cc"               ); \
+	asm ("orrpl  %[out], %[out],   %[dt]    " : [out] "=r" (out)  : "0" (out),  [dt]  "r" (dt)                      ); \
+	asm ("mov %[uSrc], %[out]" : [uSrc] "=r" (uSrc) : [out] "r" (out) ); \
+}
+
+//	1.0 x Back + 0.25 x Forward	*/
+#define gpuBlending03(uSrc,uDst) \
+{ \
+		u16 st,dt,out; \
+		asm ("mov    %[src], %[src],   lsr #2   " : [src] "=r" (uSrc) : "0" (uSrc)                                      ); \
+		asm ("and    %[dt],  %[dst],   #0x7C00  " : [dt]  "=r" (dt)   :             [dst] "r" (uDst)                    ); \
+		asm ("and    %[st],  %[src],   #0x1C00  " : [st]  "=r" (st)   :             [src] "r" (uSrc)                    ); \
+		asm ("add    %[out], %[dt],    %[st]    " : [out] "=r" (out)  :             [dt]  "r" (dt),   [st]  "r" (st)    ); \
+		asm ("cmp    %[out], #0x7C00            " :                   :             [out] "r" (out) : "cc"              ); \
+		asm ("movhi  %[out], #0x7C00            " : [out] "=r" (out)  : "0" (out)                                       ); \
+		asm ("and    %[dt],  %[dst],   #0x03E0  " : [dt]  "=r" (dt)   :             [dst] "r" (uDst)                    ); \
+		asm ("and    %[st],  %[src],   #0x00E0  " : [st]  "=r" (st)   :             [src] "r" (uSrc)                    ); \
+		asm ("add    %[dt],  %[dt],    %[st]    " : [dt]  "=r" (dt)   : "0" (dt),   [st]  "r" (st)                      ); \
+		asm ("cmp    %[dt],  #0x03E0            " :                   :             [dt]  "r" (dt) : "cc"               ); \
+		asm ("movhi  %[dt],  #0x03E0            " : [dt]  "=r" (dt)   : "0" (dt)                                        ); \
+		asm ("orr    %[out], %[out],   %[dt]    " : [out] "=r" (out)  : "0" (out),  [dt]  "r" (dt)                      ); \
+		asm ("and    %[dt],  %[dst],   #0x001F  " : [dt]  "=r" (dt)   :             [dst] "r" (uDst)                    ); \
+		asm ("and    %[st],  %[src],   #0x0007  " : [st]  "=r" (st)   :             [src] "r" (uSrc)                    ); \
+		asm ("add    %[dt],  %[dt],    %[st]    " : [dt]  "=r" (dt)   : "0" (dt),   [st]  "r" (st)                      ); \
+		asm ("cmp    %[dt],  #0x001F            " :                   :             [dt]  "r" (dt) : "cc"               ); \
+		asm ("movhi  %[dt],  #0x001F            " : [dt]  "=r" (dt)   : "0" (dt)                                        ); \
+		asm ("orr    %[uSrc], %[out],   %[dt]   " : [uSrc] "=r" (uSrc)  : [out] "r" (out),  [dt]  "r" (dt)              ); \
+}
+
+#endif  //_OP_BLEND_H_
diff --git a/plugins/gpu_unai/gpu_inner_blend_arm7.h b/plugins/gpu_unai/gpu_inner_blend_arm7.h
new file mode 100644
index 00000000..083e62d8
--- /dev/null
+++ b/plugins/gpu_unai/gpu_inner_blend_arm7.h
@@ -0,0 +1,107 @@
+/***************************************************************************
+*   Copyright (C) 2010 PCSX4ALL Team                                      *
+*   Copyright (C) 2010 Unai                                               *
+*                                                                         *
+*   This program is free software; you can redistribute it and/or modify  *
+*   it under the terms of the GNU General Public License as published by  *
+*   the Free Software Foundation; either version 2 of the License, or     *
+*   (at your option) any later version.                                   *
+*                                                                         *
+*   This program is distributed in the hope that it will be useful,       *
+*   but WITHOUT ANY WARRANTY; without even the implied warranty of        *
+*   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the         *
+*   GNU General Public License for more details.                          *
+*                                                                         *
+*   You should have received a copy of the GNU General Public License     *
+*   along with this program; if not, write to the                         *
+*   Free Software Foundation, Inc.,                                       *
+*   51 Franklin Street, Fifth Floor, Boston, MA 02111-1307 USA.           *
+***************************************************************************/
+
+#ifndef _OP_BLEND_H_
+#define _OP_BLEND_H_
+
+//  GPU Blending operations functions
+
+#define gpuBlending00(uSrc,uDst) \
+{ \
+	asm ("and  %[src], %[src], %[msk]\n" \
+	     "and  %[dst], %[dst], %[msk]\n" \
+	     "add  %[src], %[dst], %[src]\n" \
+	     "mov  %[src], %[src], lsr #1\n" \
+	 : [src] "=&r" (uSrc), [dst] "=&r" (uDst) : "0" (uSrc), "1" (uDst), [msk] "r" (uMsk)); \
+}
+
+//	1.0 x Back + 1.0 x Forward
+#define gpuBlending01(uSrc,uDst) \
+{ \
+	u32 st,dt,out; \
+	asm ("and    %[dt],  %[dst],   #0x7C00\n" \
+	     "and    %[st],  %[src],   #0x7C00\n" \
+	     "add    %[out], %[dt],    %[st]  \n" \
+	     "cmp    %[out], #0x7C00          \n" \
+	     "movhi  %[out], #0x7C00          \n" \
+	     "and    %[dt],  %[dst],   #0x03E0\n" \
+	     "and    %[st],  %[src],   #0x03E0\n" \
+	     "add    %[dt],  %[dt],    %[st]  \n" \
+	     "cmp    %[dt],  #0x03E0          \n" \
+	     "movhi  %[dt],  #0x03E0          \n" \
+	     "orr    %[out], %[out],   %[dt]  \n" \
+	     "and    %[dt],  %[dst],   #0x001F\n" \
+	     "and    %[st],  %[src],   #0x001F\n" \
+	     "add    %[dt],  %[dt],    %[st]  \n" \
+	     "cmp    %[dt],  #0x001F          \n" \
+	     "movhi  %[dt],  #0x001F          \n" \
+	     "orr    %[src], %[out],  %[dt]  \n" \
+	 : [src] "=r" (uSrc), [st] "=&r" (st), [dt] "=&r" (dt), [out] "=&r" (out) \
+	 : [dst] "r" (uDst), "0" (uSrc) : "cc"); \
+}
+
+//	1.0 x Back - 1.0 x Forward	*/
+#define gpuBlending02(uSrc,uDst) \
+{ \
+	u32 st,dt,out; \
+	asm ("and    %[dt],  %[dst],   #0x7C00\n" \
+	     "and    %[st],  %[src],   #0x7C00\n" \
+	     "subs   %[out], %[dt],    %[st]  \n" \
+	     "movmi  %[out], #0x0000          \n" \
+	     "and    %[dt],  %[dst],   #0x03E0\n" \
+	     "and    %[st],  %[src],   #0x03E0\n" \
+	     "subs   %[dt],  %[dt],    %[st]  \n" \
+	     "orrpl  %[out], %[out],   %[dt]  \n" \
+	     "and    %[dt],  %[dst],   #0x001F\n" \
+	     "and    %[st],  %[src],   #0x001F\n" \
+	     "subs   %[dt],  %[dt],    %[st]  \n" \
+	     "orrpl  %[out], %[out],   %[dt]  \n" \
+	     "mov    %[src], %[out]           \n" \
+	 : [src] "=r" (uSrc), [st] "=&r" (st), [dt] "=&r" (dt), [out] "=&r" (out) \
+	 : [dst] "r" (uDst), "0" (uSrc) : "cc"); \
+}
+
+//	1.0 x Back + 0.25 x Forward	*/
+#define gpuBlending03(uSrc,uDst) \
+{ \
+	u32 st,dt,out; \
+	asm ("mov    %[src], %[src],   lsr #2 \n" \
+	     "and    %[dt],  %[dst],   #0x7C00\n" \
+	     "and    %[st],  %[src],   #0x1C00\n" \
+	     "add    %[out], %[dt],    %[st]  \n" \
+	     "cmp    %[out], #0x7C00          \n" \
+	     "movhi  %[out], #0x7C00          \n" \
+	     "and    %[dt],  %[dst],   #0x03E0\n" \
+	     "and    %[st],  %[src],   #0x00E0\n" \
+	     "add    %[dt],  %[dt],    %[st]  \n" \
+	     "cmp    %[dt],  #0x03E0          \n" \
+	     "movhi  %[dt],  #0x03E0          \n" \
+	     "orr    %[out], %[out],   %[dt]  \n" \
+	     "and    %[dt],  %[dst],   #0x001F\n" \
+	     "and    %[st],  %[src],   #0x0007\n" \
+	     "add    %[dt],  %[dt],    %[st]  \n" \
+	     "cmp    %[dt],  #0x001F          \n" \
+	     "movhi  %[dt],  #0x001F          \n" \
+	     "orr    %[src], %[out],   %[dt]  \n" \
+	 : [src] "=r" (uSrc), [st] "=&r" (st), [dt] "=&r" (dt), [out] "=&r" (out) \
+	 : [dst] "r" (uDst), "0" (uSrc) : "cc"); \
+}
+
+#endif  //_OP_BLEND_H_
diff --git a/plugins/gpu_unai/gpu_inner_light.h b/plugins/gpu_unai/gpu_inner_light.h
index d291418c..b041dc35 100644
--- a/plugins/gpu_unai/gpu_inner_light.h
+++ b/plugins/gpu_unai/gpu_inner_light.h
@@ -1,5 +1,5 @@
 /***************************************************************************
-*   Copyright (C) 2010 PCSX4ALL Team                                      *
+*   Copyright (C) 2016 PCSX4ALL Team                                      *
 *   Copyright (C) 2010 Unai                                               *
 *                                                                         *
 *   This program is free software; you can redistribute it and/or modify  *
@@ -23,60 +23,249 @@
 
 //  GPU color operations for lighting calculations
 
-#ifdef __arm__
-#define gpuLightingRGB(uSrc,lCol) \
-{ \
-	u32 cb,cg; \
-	asm ("and %[cb],  %[lCol], #0x7C00/32      \n" \
-	     "and %[cg],  %[lCol], #0x03E0*2048    \n" \
-	     "mov %[res], %[lCol],          lsr #27\n" \
-	     "orr %[res], %[res], %[cb],    lsl #5 \n" \
-	     "orr %[res], %[res], %[cg],    lsr #11\n" \
-	 : [res] "=&r" (uSrc), [cb] "=&r" (cb), [cg] "=&r" (cg) \
-	 : [lCol] "r" (lCol)); \
+static void SetupLightLUT()
+{
+	// 1024-entry lookup table that modulates 5-bit texture + 5-bit light value.
+	// A light value of 15 does not modify the incoming texture color.
+	// LightLUT[32*32] array is initialized to following values:
+	//  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
+	//  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
+	//  0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3,
+	//  0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5,
+	//  0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7,
+	//  0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9,
+	//  0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 9, 9, 9,10,10,10,11,11,
+	//  0, 0, 0, 1, 1, 2, 2, 3, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 7, 8, 8, 9, 9,10,10,10,11,11,12,12,13,13,
+	//  0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,10,10,11,11,12,12,13,13,14,14,15,15,
+	//  0, 0, 1, 1, 2, 2, 3, 3, 4, 5, 5, 6, 6, 7, 7, 8, 9, 9,10,10,11,11,12,12,13,14,14,15,15,16,16,17,
+	//  0, 0, 1, 1, 2, 3, 3, 4, 5, 5, 6, 6, 7, 8, 8, 9,10,10,11,11,12,13,13,14,15,15,16,16,17,18,18,19,
+	//  0, 0, 1, 2, 2, 3, 4, 4, 5, 6, 6, 7, 8, 8, 9,10,11,11,12,13,13,14,15,15,16,17,17,18,19,19,20,21,
+	//  0, 0, 1, 2, 3, 3, 4, 5, 6, 6, 7, 8, 9, 9,10,11,12,12,13,14,15,15,16,17,18,18,19,20,21,21,22,23,
+	//  0, 0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 8, 9,10,11,12,13,13,14,15,16,17,17,18,19,20,21,21,22,23,24,25,
+	//  0, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9,10,11,12,13,14,14,15,16,17,18,19,20,21,21,22,23,24,25,26,27,
+	//  0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9,10,11,12,13,14,15,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,
+	//  0, 1, 2, 3, 4, 5, 6, 7, 8, 9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,
+	//  0, 1, 2, 3, 4, 5, 6, 7, 8, 9,10,11,12,13,14,15,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,31,
+	//  0, 1, 2, 3, 4, 5, 6, 7, 9,10,11,12,13,14,15,16,18,19,20,21,22,23,24,25,27,28,29,30,31,31,31,31,
+	//  0, 1, 2, 3, 4, 5, 7, 8, 9,10,11,13,14,15,16,17,19,20,21,22,23,24,26,27,28,29,30,31,31,31,31,31,
+	//  0, 1, 2, 3, 5, 6, 7, 8,10,11,12,13,15,16,17,18,20,21,22,23,25,26,27,28,30,31,31,31,31,31,31,31,
+	//  0, 1, 2, 3, 5, 6, 7, 9,10,11,13,14,15,17,18,19,21,22,23,24,26,27,28,30,31,31,31,31,31,31,31,31,
+	//  0, 1, 2, 4, 5, 6, 8, 9,11,12,13,15,16,17,19,20,22,23,24,26,27,28,30,31,31,31,31,31,31,31,31,31,
+	//  0, 1, 2, 4, 5, 7, 8,10,11,12,14,15,17,18,20,21,23,24,25,27,28,30,31,31,31,31,31,31,31,31,31,31,
+	//  0, 1, 3, 4, 6, 7, 9,10,12,13,15,16,18,19,21,22,24,25,27,28,30,31,31,31,31,31,31,31,31,31,31,31,
+	//  0, 1, 3, 4, 6, 7, 9,10,12,14,15,17,18,20,21,23,25,26,28,29,31,31,31,31,31,31,31,31,31,31,31,31,
+	//  0, 1, 3, 4, 6, 8, 9,11,13,14,16,17,19,21,22,24,26,27,29,30,31,31,31,31,31,31,31,31,31,31,31,31,
+	//  0, 1, 3, 5, 6, 8,10,11,13,15,16,18,20,21,23,25,27,28,30,31,31,31,31,31,31,31,31,31,31,31,31,31,
+	//  0, 1, 3, 5, 7, 8,10,12,14,15,17,19,21,22,24,26,28,29,31,31,31,31,31,31,31,31,31,31,31,31,31,31,
+	//  0, 1, 3, 5, 7, 9,10,12,14,16,18,19,21,23,25,27,29,30,31,31,31,31,31,31,31,31,31,31,31,31,31,31,
+	//  0, 1, 3, 5, 7, 9,11,13,15,16,18,20,22,24,26,28,30,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,
+	//  0, 1, 3, 5, 7, 9,11,13,15,17,19,21,23,25,27,29,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31
+
+	for (int j=0; j < 32; ++j) {
+		for (int i=0; i < 32; ++i) {
+			int val = i * j / 16;
+			if (val > 31) val = 31;
+			gpu_unai.LightLUT[(j*32) + i] = val;
+		}
+	}
+}
+
+
+////////////////////////////////////////////////////////////////////////////////
+// Create packed Gouraud fixed-pt 8.3:8.3:8.2 rgb triplet
+//
+// INPUT:
+// 'r','g','b' are 8.10 fixed-pt color components (r shown here)
+//     'r' input:  --------------rrrrrrrrXXXXXXXXXX
+//                 ^ bit 31
+// RETURNS:
+//    u32 output:  rrrrrrrrXXXggggggggXXXbbbbbbbbXX
+//                 ^ bit 31
+// Where 'r,g,b' are integer bits of colors, 'X' fixed-pt, and '-' don't care
+////////////////////////////////////////////////////////////////////////////////
+GPU_INLINE u32 gpuPackGouraudCol(u32 r, u32 g, u32 b)
+{
+	return ((u32)(b>> 8)&(0x03ff    ))
+	     | ((u32)(g<< 3)&(0x07ff<<10))
+	     | ((u32)(r<<14)&(0x07ff<<21));
+}
+
+
+////////////////////////////////////////////////////////////////////////////////
+// Create packed increment for Gouraud fixed-pt 8.3:8.3:8.2 rgb triplet
+//
+// INPUT:
+//  Sign-extended 8.10 fixed-pt r,g,b color increment values (only dr is shown)
+//   'dr' input:  ssssssssssssssrrrrrrrrXXXXXXXXXX
+//                ^ bit 31
+// RETURNS:
+//   u32 output:  rrrrrrrrXXXggggggggXXXbbbbbbbbXX
+//                ^ bit 31
+// Where 'r,g,b' are integer bits of colors, 'X' fixed-pt, and 's' sign bits
+//
+// NOTE: The correctness of this code/method has not been fully verified,
+//       having been merely factored out from original code in
+//       poly-drawing functions. Feel free to check/improve it -senquack
+////////////////////////////////////////////////////////////////////////////////
+GPU_INLINE u32 gpuPackGouraudColInc(s32 dr, s32 dg, s32 db)
+{
+	u32 dr_tmp = (u32)(dr << 14)&(0xffffffff<<21);  if (dr < 0) dr_tmp += 1<<21;
+	u32 dg_tmp = (u32)(dg <<  3)&(0xffffffff<<10);  if (dg < 0) dg_tmp += 1<<10;
+	u32 db_tmp = (u32)(db >>  8)&(0xffffffff    );  if (db < 0) db_tmp += 1<< 0;
+	return db_tmp + dg_tmp + dr_tmp;
 }
-#else
-#define gpuLightingRGB(uSrc,lCol) uSrc=((lCol<<5)&0x7C00) | ((lCol>>11)&0x3E0) | (lCol>>27)
-#endif
 
-INLINE void gpuLightingTXT(u16 &uSrc, u32 &lCol)
+
+////////////////////////////////////////////////////////////////////////////////
+// Extract bgr555 color from Gouraud u32 fixed-pt 8.3:8.3:8.2 rgb triplet
+//
+// INPUT:
+//  'gCol' input:  rrrrrrrrXXXggggggggXXXbbbbbbbbXX
+//                 ^ bit 31
+// RETURNS:
+//    u16 output:  0bbbbbgggggrrrrr
+//                 ^ bit 16
+// Where 'r,g,b' are integer bits of colors, 'X' fixed-pt, and '0' zero
+////////////////////////////////////////////////////////////////////////////////
+GPU_INLINE u16 gpuLightingRGB(u32 gCol)
+{
+	return ((gCol<< 5)&0x7C00) |
+	       ((gCol>>11)&0x03E0) |
+	        (gCol>>27);
+}
+
+
+////////////////////////////////////////////////////////////////////////////////
+// Convert packed Gouraud u32 fixed-pt 8.3:8.3:8.2 rgb triplet in 'gCol'
+//  to padded u32 5.4:5.4:5.4 bgr fixed-pt triplet, suitable for use
+//  with HQ 24-bit lighting/quantization.
+//
+// INPUT:
+//       'gCol' input:  rrrrrrrrXXXggggggggXXXbbbbbbbbXX
+//                      ^ bit 31
+// RETURNS:
+//         u32 output:  000bbbbbXXXX0gggggXXXX0rrrrrXXXX
+//                      ^ bit 31
+//  Where 'X' are fixed-pt bits, '0' zero-padding, and '-' is don't care
+////////////////////////////////////////////////////////////////////////////////
+GPU_INLINE u32 gpuLightingRGB24(u32 gCol)
+{
+	return ((gCol<<19) & (0x1FF<<20)) |
+	       ((gCol>> 2) & (0x1FF<<10)) |
+	        (gCol>>23);
+}
+
+
+////////////////////////////////////////////////////////////////////////////////
+// Apply fast (low-precision) 5-bit lighting to bgr555 texture color:
+//
+// INPUT:
+//        'r5','g5','b5' are unsigned 5-bit color values, value of 15
+//          is midpoint that doesn't modify that component of texture
+//        'uSrc' input:  -bbbbbgggggrrrrr
+//                       ^ bit 16
+// RETURNS:
+//          u16 output:  0bbbbbgggggrrrrr
+// Where 'X' are fixed-pt bits, '0' is zero-padding, and '-' is don't care
+////////////////////////////////////////////////////////////////////////////////
+GPU_INLINE u16 gpuLightingTXT(u16 uSrc, u8 r5, u8 g5, u8 b5)
 {
-	//  Pixelops Table
-	static const u8 _gpuLitT[32*32] = {
-		 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
-		 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
-		 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3,
-		 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5,
-		 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7,
-		 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9,
-		 0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 9, 9, 9,10,10,10,11,11,
-		 0, 0, 0, 1, 1, 2, 2, 3, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 7, 8, 8, 9, 9,10,10,10,11,11,12,12,13,13,
-		 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,10,10,11,11,12,12,13,13,14,14,15,15,
-		 0, 0, 1, 1, 2, 2, 3, 3, 4, 5, 5, 6, 6, 7, 7, 8, 9, 9,10,10,11,11,12,12,13,14,14,15,15,16,16,17,
-		 0, 0, 1, 1, 2, 3, 3, 4, 5, 5, 6, 6, 7, 8, 8, 9,10,10,11,11,12,13,13,14,15,15,16,16,17,18,18,19,
-		 0, 0, 1, 2, 2, 3, 4, 4, 5, 6, 6, 7, 8, 8, 9,10,11,11,12,13,13,14,15,15,16,17,17,18,19,19,20,21,
-		 0, 0, 1, 2, 3, 3, 4, 5, 6, 6, 7, 8, 9, 9,10,11,12,12,13,14,15,15,16,17,18,18,19,20,21,21,22,23,
-		 0, 0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 8, 9,10,11,12,13,13,14,15,16,17,17,18,19,20,21,21,22,23,24,25,
-		 0, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9,10,11,12,13,14,14,15,16,17,18,19,20,21,21,22,23,24,25,26,27,
-		 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9,10,11,12,13,14,15,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,
-		 0, 1, 2, 3, 4, 5, 6, 7, 8, 9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,
-		 0, 1, 2, 3, 4, 5, 6, 7, 8, 9,10,11,12,13,14,15,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,31,
-		 0, 1, 2, 3, 4, 5, 6, 7, 9,10,11,12,13,14,15,16,18,19,20,21,22,23,24,25,27,28,29,30,31,31,31,31,
-		 0, 1, 2, 3, 4, 5, 7, 8, 9,10,11,13,14,15,16,17,19,20,21,22,23,24,26,27,28,29,30,31,31,31,31,31,
-		 0, 1, 2, 3, 5, 6, 7, 8,10,11,12,13,15,16,17,18,20,21,22,23,25,26,27,28,30,31,31,31,31,31,31,31,
-		 0, 1, 2, 3, 5, 6, 7, 9,10,11,13,14,15,17,18,19,21,22,23,24,26,27,28,30,31,31,31,31,31,31,31,31,
-		 0, 1, 2, 4, 5, 6, 8, 9,11,12,13,15,16,17,19,20,22,23,24,26,27,28,30,31,31,31,31,31,31,31,31,31,
-		 0, 1, 2, 4, 5, 7, 8,10,11,12,14,15,17,18,20,21,23,24,25,27,28,30,31,31,31,31,31,31,31,31,31,31,
-		 0, 1, 3, 4, 6, 7, 9,10,12,13,15,16,18,19,21,22,24,25,27,28,30,31,31,31,31,31,31,31,31,31,31,31,
-		 0, 1, 3, 4, 6, 7, 9,10,12,14,15,17,18,20,21,23,25,26,28,29,31,31,31,31,31,31,31,31,31,31,31,31,
-		 0, 1, 3, 4, 6, 8, 9,11,13,14,16,17,19,21,22,24,26,27,29,30,31,31,31,31,31,31,31,31,31,31,31,31,
-		 0, 1, 3, 5, 6, 8,10,11,13,15,16,18,20,21,23,25,27,28,30,31,31,31,31,31,31,31,31,31,31,31,31,31,
-		 0, 1, 3, 5, 7, 8,10,12,14,15,17,19,21,22,24,26,28,29,31,31,31,31,31,31,31,31,31,31,31,31,31,31,
-		 0, 1, 3, 5, 7, 9,10,12,14,16,18,19,21,23,25,27,29,30,31,31,31,31,31,31,31,31,31,31,31,31,31,31,
-		 0, 1, 3, 5, 7, 9,11,13,15,16,18,20,22,24,26,28,30,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,
-		 0, 1, 3, 5, 7, 9,11,13,15,17,19,21,23,25,27,29,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31
-	};
-	uSrc  = (_gpuLitT[((uSrc&0x7C00)>>5)|((lCol>>5)&0x1f)]<<10)|(_gpuLitT[(uSrc&0x03E0)|((lCol>>16)&0x1f)]<<5)|(_gpuLitT[((uSrc&0x001F)<<5)|(lCol>>27)]);
+	return (gpu_unai.LightLUT[((uSrc&0x7C00)>>5) | b5] << 10) |
+	       (gpu_unai.LightLUT[ (uSrc&0x03E0)     | g5] <<  5) |
+	       (gpu_unai.LightLUT[((uSrc&0x001F)<<5) | r5]      );
+}
+
+
+////////////////////////////////////////////////////////////////////////////////
+// Apply fast (low-precision) 5-bit Gouraud lighting to bgr555 texture color:
+//
+// INPUT:
+//  'gCol' is a packed Gouraud u32 fixed-pt 8.3:8.3:8.2 rgb triplet, value of
+//     15.0 is midpoint that does not modify color of texture
+//         gCol input :  rrrrrXXXXXXgggggXXXXXXbbbbbXXXXX
+//                       ^ bit 31
+//        'uSrc' input:  -bbbbbgggggrrrrr
+//                       ^ bit 16
+// RETURNS:
+//          u16 output:  0bbbbbgggggrrrrr
+// Where 'X' are fixed-pt bits, '0' is zero-padding, and '-' is don't care
+////////////////////////////////////////////////////////////////////////////////
+GPU_INLINE u16 gpuLightingTXTGouraud(u16 uSrc, u32 gCol)
+{
+	return (gpu_unai.LightLUT[((uSrc&0x7C00)>>5) | ((gCol>> 5)&0x1F)]<<10) |
+	       (gpu_unai.LightLUT[ (uSrc&0x03E0)     | ((gCol>>16)&0x1F)]<< 5) |
+	       (gpu_unai.LightLUT[((uSrc&0x001F)<<5) |  (gCol>>27)      ]    );
+}
+
+
+////////////////////////////////////////////////////////////////////////////////
+// Apply high-precision 8-bit lighting to bgr555 texture color,
+//  returning a padded u32 5.4:5.4:5.4 bgr fixed-pt triplet
+//  suitable for use with HQ 24-bit lighting/quantization.
+//
+// INPUT:
+//        'r8','g8','b8' are unsigned 8-bit color component values, value of
+//          127 is midpoint that doesn't modify that component of texture
+//
+//         uSrc input: -bbbbbgggggrrrrr
+//                     ^ bit 16
+// RETURNS:
+//         u32 output: 000bbbbbXXXX0gggggXXXX0rrrrrXXXX
+//                     ^ bit 31
+// Where 'X' are fixed-pt bits, '0' is zero-padding, and '-' is don't care
+////////////////////////////////////////////////////////////////////////////////
+GPU_INLINE u32 gpuLightingTXT24(u16 uSrc, u8 r8, u8 g8, u8 b8)
+{
+	u16 r1 = uSrc&0x001F;
+	u16 g1 = uSrc&0x03E0;
+	u16 b1 = uSrc&0x7C00;
+
+	u16 r2 = r8;
+	u16 g2 = g8;
+	u16 b2 = b8;
+
+	u32 r3 = r1 * r2; if (r3 & 0xFFFFF000) r3 = ~0xFFFFF000;
+	u32 g3 = g1 * g2; if (g3 & 0xFFFE0000) g3 = ~0xFFFE0000;
+	u32 b3 = b1 * b2; if (b3 & 0xFFC00000) b3 = ~0xFFC00000;
+
+	return ((r3>> 3)    ) |
+	       ((g3>> 8)<<10) |
+	       ((b3>>13)<<20);
+}
+
+
+////////////////////////////////////////////////////////////////////////////////
+// Apply high-precision 8-bit lighting to bgr555 texture color in 'uSrc',
+//  returning a padded u32 5.4:5.4:5.4 bgr fixed-pt triplet
+//  suitable for use with HQ 24-bit lighting/quantization.
+//
+// INPUT:
+//       'uSrc' input: -bbbbbgggggrrrrr
+//                     ^ bit 16
+//       'gCol' input: rrrrrrrrXXXggggggggXXXbbbbbbbbXX
+//                     ^ bit 31
+// RETURNS:
+//         u32 output: 000bbbbbXXXX0gggggXXXX0rrrrrXXXX
+//                     ^ bit 31
+// Where 'X' are fixed-pt bits, '0' is zero-padding, and '-' is don't care
+////////////////////////////////////////////////////////////////////////////////
+GPU_INLINE u32 gpuLightingTXT24Gouraud(u16 uSrc, u32 gCol)
+{
+	u16 r1 = uSrc&0x001F;
+	u16 g1 = uSrc&0x03E0;
+	u16 b1 = uSrc&0x7C00;
+
+	u16 r2 = (gCol>>24) & 0xFF;
+	u16 g2 = (gCol>>13) & 0xFF;
+	u16 b2 = (gCol>> 2) & 0xFF;
+
+	u32 r3 = r1 * r2; if (r3 & 0xFFFFF000) r3 = ~0xFFFFF000;
+	u32 g3 = g1 * g2; if (g3 & 0xFFFE0000) g3 = ~0xFFFE0000;
+	u32 b3 = b1 * b2; if (b3 & 0xFFC00000) b3 = ~0xFFC00000;
+
+	return ((r3>> 3)    ) |
+	       ((g3>> 8)<<10) |
+	       ((b3>>13)<<20);
 }
 
 #endif  //_OP_LIGHT_H_
diff --git a/plugins/gpu_unai/gpu_inner_quantization.h b/plugins/gpu_unai/gpu_inner_quantization.h
new file mode 100644
index 00000000..0e7e3e8a
--- /dev/null
+++ b/plugins/gpu_unai/gpu_inner_quantization.h
@@ -0,0 +1,108 @@
+/***************************************************************************
+*   Copyright (C) 2016 PCSX4ALL Team                                      *
+*                                                                         *
+*   This program is free software; you can redistribute it and/or modify  *
+*   it under the terms of the GNU General Public License as published by  *
+*   the Free Software Foundation; either version 2 of the License, or     *
+*   (at your option) any later version.                                   *
+*                                                                         *
+*   This program is distributed in the hope that it will be useful,       *
+*   but WITHOUT ANY WARRANTY; without even the implied warranty of        *
+*   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the         *
+*   GNU General Public License for more details.                          *
+*                                                                         *
+*   You should have received a copy of the GNU General Public License     *
+*   along with this program; if not, write to the                         *
+*   Free Software Foundation, Inc.,                                       *
+*   51 Franklin Street, Fifth Floor, Boston, MA 02111-1307 USA.           *
+***************************************************************************/
+
+#ifndef _OP_DITHER_H_
+#define _OP_DITHER_H_
+
+static void SetupDitheringConstants()
+{
+	// Initialize Dithering Constants
+	// The screen is divided into 8x8 chunks and sub-unitary noise is applied
+	// using the following matrix. This ensures that data lost in color
+	// quantization will be added back to the image 'by chance' in predictable
+	// patterns that are naturally 'smoothed' by your sight when viewed from a
+	// certain distance.
+	//
+	// http://caca.zoy.org/study/index.html
+	//
+	// Shading colors are encoded in 4.5, and then are quantitized to 5.0,
+	// DitherMatrix constants reflect that.
+
+	static const u8 DitherMatrix[] = {
+		 0, 32,  8, 40,  2, 34, 10, 42,
+		48, 16, 56, 24, 50, 18, 58, 26,
+		12, 44,  4, 36, 14, 46,  6, 38,
+		60, 28, 52, 20, 62, 30, 54, 22,
+		 3, 35, 11, 43,  1, 33,  9, 41,
+		51, 19, 59, 27, 49, 17, 57, 25,
+		15, 47,  7, 39, 13, 45,  5, 37,
+		63, 31, 55, 23, 61, 29, 53, 21
+	};
+
+	int i, j;
+	for (i = 0; i < 8; i++)
+	{
+		for (j = 0; j < 8; j++)
+		{
+			u16 offset = (i << 3) | j;
+
+			u32 component = ((DitherMatrix[offset] + 1) << 4) / 65; //[5.5] -> [5]
+
+			// XXX - senquack - hack Dec 2016
+			//  Until JohnnyF gets the time to work further on dithering,
+			//   force lower bit of component to 0. This fixes grid pattern
+			//   affecting quality of dithered image, as well as loss of
+			//   detail in dark areas. With lower bit unset like this, existing
+			//   27-bit accuracy of dithering math is unneeded, could be 24-bit.
+			//   Is 8x8 matrix overkill as a result, can we use 4x4?
+			component &= ~1;
+
+			gpu_unai.DitherMatrix[offset] = (component)
+			                              | (component << 10)
+			                              | (component << 20);
+		}
+	}
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// Convert padded u32 5.4:5.4:5.4 bgr fixed-pt triplet to final bgr555 color,
+//  applying dithering if specified by template parameter.
+//
+// INPUT:
+//     'uSrc24' input: 000bbbbbXXXX0gggggXXXX0rrrrrXXXX
+//                     ^ bit 31
+//       'pDst' is a pointer to destination framebuffer pixel, used
+//         to determine which DitherMatrix[] entry to apply.
+// RETURNS:
+//         u16 output: 0bbbbbgggggrrrrr
+//                     ^ bit 16
+// Where 'X' are fixed-pt bits, '0' is zero-padding, and '-' is don't care
+////////////////////////////////////////////////////////////////////////////////
+template <int DITHER>
+GPU_INLINE u16 gpuColorQuantization24(u32 uSrc24, const u16 *pDst)
+{
+	if (DITHER)
+	{
+		u16 fbpos  = (u32)(pDst - gpu_unai.vram);
+		u16 offset = ((fbpos & (0x7 << 10)) >> 7) | (fbpos & 0x7);
+
+		//clean overflow flags and add
+		uSrc24 = (uSrc24 & 0x1FF7FDFF) + gpu_unai.DitherMatrix[offset];
+
+		if (uSrc24 & (1<< 9)) uSrc24 |= (0x1FF    );
+		if (uSrc24 & (1<<19)) uSrc24 |= (0x1FF<<10);
+		if (uSrc24 & (1<<29)) uSrc24 |= (0x1FF<<20);
+	}
+
+	return ((uSrc24>> 4) & (0x1F    ))
+	     | ((uSrc24>> 9) & (0x1F<<5 ))
+	     | ((uSrc24>>14) & (0x1F<<10));
+}
+
+#endif //_OP_DITHER_H_
diff --git a/plugins/gpu_unai/gpu_raster_image.h b/plugins/gpu_unai/gpu_raster_image.h
index 0c82aa97..87d21515 100644
--- a/plugins/gpu_unai/gpu_raster_image.h
+++ b/plugins/gpu_unai/gpu_raster_image.h
@@ -19,71 +19,79 @@
  ***************************************************************************/
 
 ///////////////////////////////////////////////////////////////////////////////
-INLINE void gpuLoadImage(void)
+#ifndef USE_GPULIB
+void gpuLoadImage(PtrUnion packet)
 {
 	u16 x0, y0, w0, h0;
-	x0 = PacketBuffer.U2[2] & 1023;
-	y0 = PacketBuffer.U2[3] & 511;
-	w0 = PacketBuffer.U2[4];
-	h0 = PacketBuffer.U2[5];
+	x0 = packet.U2[2] & 1023;
+	y0 = packet.U2[3] & 511;
+	w0 = packet.U2[4];
+	h0 = packet.U2[5];
 
 	if ((y0 + h0) > FRAME_HEIGHT)
 	{
 		h0 = FRAME_HEIGHT - y0;
 	}
 
-	FrameToWrite = ((w0)&&(h0));
+	gpu_unai.dma.FrameToWrite = ((w0)&&(h0));
 
-	px = 0;
-	py = 0;
-	x_end = w0;
-	y_end = h0;
-	pvram = &((u16*)GPU_FrameBuffer)[x0+(y0*1024)];
+	gpu_unai.dma.px = 0;
+	gpu_unai.dma.py = 0;
+	gpu_unai.dma.x_end = w0;
+	gpu_unai.dma.y_end = h0;
+	gpu_unai.dma.pvram = &((u16*)gpu_unai.vram)[x0+(y0*1024)];
 
-	GPU_GP1 |= 0x08000000;
+	gpu_unai.GPU_GP1 |= 0x08000000;
 }
+#endif // !USE_GPULIB
 
 ///////////////////////////////////////////////////////////////////////////////
-INLINE void gpuStoreImage(void)
+#ifndef USE_GPULIB
+void gpuStoreImage(PtrUnion packet)
 {
 	u16 x0, y0, w0, h0;
-	x0 = PacketBuffer.U2[2] & 1023;
-	y0 = PacketBuffer.U2[3] & 511;
-	w0 = PacketBuffer.U2[4];
-	h0 = PacketBuffer.U2[5];
+	x0 = packet.U2[2] & 1023;
+	y0 = packet.U2[3] & 511;
+	w0 = packet.U2[4];
+	h0 = packet.U2[5];
 
 	if ((y0 + h0) > FRAME_HEIGHT)
 	{
 		h0 = FRAME_HEIGHT - y0;
 	}
-	FrameToRead = ((w0)&&(h0));
+	gpu_unai.dma.FrameToRead = ((w0)&&(h0));
 
-	px = 0;
-	py = 0;
-	x_end = w0;
-	y_end = h0;
-	pvram = &((u16*)GPU_FrameBuffer)[x0+(y0*1024)];
+	gpu_unai.dma.px = 0;
+	gpu_unai.dma.py = 0;
+	gpu_unai.dma.x_end = w0;
+	gpu_unai.dma.y_end = h0;
+	gpu_unai.dma.pvram = &((u16*)gpu_unai.vram)[x0+(y0*1024)];
 	
-	GPU_GP1 |= 0x08000000;
+	gpu_unai.GPU_GP1 |= 0x08000000;
 }
+#endif // !USE_GPULIB
 
-INLINE void gpuMoveImage(void)
+void gpuMoveImage(PtrUnion packet)
 {
 	u32 x0, y0, x1, y1;
 	s32 w0, h0;
-	x0 = PacketBuffer.U2[2] & 1023;
-	y0 = PacketBuffer.U2[3] & 511;
-	x1 = PacketBuffer.U2[4] & 1023;
-	y1 = PacketBuffer.U2[5] & 511;
-	w0 = PacketBuffer.U2[6];
-	h0 = PacketBuffer.U2[7];
+	x0 = packet.U2[2] & 1023;
+	y0 = packet.U2[3] & 511;
+	x1 = packet.U2[4] & 1023;
+	y1 = packet.U2[5] & 511;
+	w0 = packet.U2[6];
+	h0 = packet.U2[7];
 
 	if( (x0==x1) && (y0==y1) ) return;
 	if ((w0<=0) || (h0<=0)) return;
 	
+	#ifdef ENABLE_GPU_LOG_SUPPORT
+		fprintf(stdout,"gpuMoveImage(x0=%u,y0=%u,x1=%u,y1=%u,w0=%d,h0=%d)\n",x0,y0,x1,y1,w0,h0);
+	#endif
+	
 	if (((y0+h0)>512)||((x0+w0)>1024)||((y1+h0)>512)||((x1+w0)>1024))
 	{
-		u16 *psxVuw=GPU_FrameBuffer;
+		u16 *psxVuw=gpu_unai.vram;
 		s32 i,j;
 	    for(j=0;j<h0;j++)
 		 for(i=0;i<w0;i++)
@@ -93,7 +101,7 @@ INLINE void gpuMoveImage(void)
 	else if ((x0&1)||(x1&1))
 	{
 		u16 *lpDst, *lpSrc;
-		lpDst = lpSrc = (u16*)GPU_FrameBuffer;
+		lpDst = lpSrc = (u16*)gpu_unai.vram;
 		lpSrc += FRAME_OFFSET(x0, y0);
 		lpDst += FRAME_OFFSET(x1, y1);
 		x1 = FRAME_WIDTH - w0;
@@ -107,7 +115,7 @@ INLINE void gpuMoveImage(void)
 	else
 	{
 		u32 *lpDst, *lpSrc;
-		lpDst = lpSrc = (u32*)(void*)GPU_FrameBuffer;
+		lpDst = lpSrc = (u32*)(void*)gpu_unai.vram;
 		lpSrc += ((FRAME_OFFSET(x0, y0))>>1);
 		lpDst += ((FRAME_OFFSET(x1, y1))>>1);
 		if (w0&1)
@@ -143,13 +151,13 @@ INLINE void gpuMoveImage(void)
 	}
 }
 
-INLINE void gpuClearImage(void)
+void gpuClearImage(PtrUnion packet)
 {
 	s32   x0, y0, w0, h0;
-	x0 = PacketBuffer.S2[2];
-	y0 = PacketBuffer.S2[3];
-	w0 = PacketBuffer.S2[4] & 0x3ff;
-	h0 = PacketBuffer.S2[5] & 0x3ff;
+	x0 = packet.S2[2];
+	y0 = packet.S2[3];
+	w0 = packet.S2[4] & 0x3ff;
+	h0 = packet.S2[5] & 0x3ff;
 	 
 	w0 += x0;
 	if (x0 < 0) x0 = 0;
@@ -162,10 +170,14 @@ INLINE void gpuClearImage(void)
 	h0 -= y0;
 	if (h0 <= 0) return;
 
+	#ifdef ENABLE_GPU_LOG_SUPPORT
+		fprintf(stdout,"gpuClearImage(x0=%d,y0=%d,w0=%d,h0=%d)\n",x0,y0,w0,h0);
+	#endif
+	
 	if (x0&1)
 	{
-		u16* pixel = (u16*)GPU_FrameBuffer + FRAME_OFFSET(x0, y0);
-		u16 rgb = GPU_RGB16(PacketBuffer.S4[0]);
+		u16* pixel = (u16*)gpu_unai.vram + FRAME_OFFSET(x0, y0);
+		u16 rgb = GPU_RGB16(packet.U4[0]);
 		y0 = FRAME_WIDTH - w0;
 		do {
 			x0=w0;
@@ -175,8 +187,8 @@ INLINE void gpuClearImage(void)
 	}
 	else
 	{
-		u32* pixel = (u32*)(void*)GPU_FrameBuffer + ((FRAME_OFFSET(x0, y0))>>1);
-		u32 rgb = GPU_RGB16(PacketBuffer.S4[0]);
+		u32* pixel = (u32*)gpu_unai.vram + ((FRAME_OFFSET(x0, y0))>>1);
+		u32 rgb = GPU_RGB16(packet.U4[0]);
 		rgb |= (rgb<<16);
 		if (w0&1)
 		{
diff --git a/plugins/gpu_unai/gpu_raster_line.h b/plugins/gpu_unai/gpu_raster_line.h
index fc59b797..28ea074e 100644
--- a/plugins/gpu_unai/gpu_raster_line.h
+++ b/plugins/gpu_unai/gpu_raster_line.h
@@ -1,6 +1,7 @@
 /***************************************************************************
 *   Copyright (C) 2010 PCSX4ALL Team                                      *
 *   Copyright (C) 2010 Unai                                               *
+*   Copyright (C) 2016 Senquack (dansilsby <AT> gmail <DOT> com)          *
 *                                                                         *
 *   This program is free software; you can redistribute it and/or modify  *
 *   it under the terms of the GNU General Public License as published by  *
@@ -18,240 +19,697 @@
 *   51 Franklin Street, Fifth Floor, Boston, MA 02111-1307 USA.           *
 ***************************************************************************/
 
-#define	GPU_TESTRANGE(x)      { if((u32)(x+1024) > 2047) return; }
-
 ///////////////////////////////////////////////////////////////////////////////
 //  GPU internal line drawing functions
+//
+// Rewritten October 2016 by senquack:
+//  Instead of one pixel at a time, lines are now drawn in runs of pixels,
+//  whether vertical, horizontal, or diagonal. A new inner driver
+//  'gpuPixelSpanFn' is used, as well as an enhanced Bresenham run-slice
+//  algorithm. For more information, see the following:
+//
+//  Michael Abrash - Graphics Programming Black Book
+//  Chapters 35 - 36 (does not implement diagonal runs)
+//  http://www.drdobbs.com/parallel/graphics-programming-black-book/184404919
+//  http://www.jagregory.com/abrash-black-book/
+//
+//  Article by Andrew Delong (does not implement diagonal runs)
+//  http://timetraces.ca/nw/drawline.htm
+//
+//  'Run-Based Multi-Point Line Drawing' by Eun Jae Lee & Larry F. Hodges
+//  https://smartech.gatech.edu/bitstream/handle/1853/3632/93-22.pdf
+//  Provided the idea of doing a half-octant transform allowing lines with
+//  slopes between 0.5 and 2.0 (diagonal runs of pixels) to be handled
+//  identically to the traditional horizontal/vertical run-slice method.
 
-#define GPU_DIGITS  16
-#define GPU_DIGITSC (GPU_DIGITS+3)
+// Use 16.16 fixed point precision for line math.
+// NOTE: Gouraud colors used by gpuPixelSpanFn can use a different precision.
+#define GPU_LINE_FIXED_BITS 16
 
-INLINE s32 GPU_DIV(s32 rs, s32 rt)
-{
-	return rt ? (rs / rt) : (0);
-}
+// If defined, Gouraud lines will use fixed-point multiply-by-inverse to
+// do most divisions. With enough accuracy, this should be OK.
+#define USE_LINES_ALL_FIXED_PT_MATH
 
-///////////////////////////////////////////////////////////////////////////////
-void gpuDrawLF(const PD gpuPixelDriver)
+//////////////////////
+// Flat-shaded line //
+//////////////////////
+void gpuDrawLineF(PtrUnion packet, const PSD gpuPixelSpanDriver)
 {
-	s32 temp;
-	s32 xmin, xmax;
-	s32 ymin, ymax;
-	s32 x0, x1, dx;
-	s32 y0, y1, dy;
-
-	x0 = PacketBuffer.S2[2] + DrawingOffset[0]; 	GPU_TESTRANGE(x0);
-	y0 = PacketBuffer.S2[3] + DrawingOffset[1]; 	GPU_TESTRANGE(y0);
-	x1 = PacketBuffer.S2[4] + DrawingOffset[0]; 	GPU_TESTRANGE(x1);
-	y1 = PacketBuffer.S2[5] + DrawingOffset[1]; 	GPU_TESTRANGE(y1);
-
-	xmin = DrawingArea[0];	xmax = DrawingArea[2];
-	ymin = DrawingArea[1];	ymax = DrawingArea[3];
-	const u16 pixeldata = GPU_RGB16(PacketBuffer.U4[0]);
-
-	dy = (y1 - y0);
-	if (dy < 0) dy = -dy;
-	dx = (x1 - x0);
-	if (dx < 0) dx = -dx;
-	if (dx > dy) {
-		if (x0 > x1) {
-			GPU_SWAP(x0, x1, temp);
-			GPU_SWAP(y0, y1, temp);
+	int x0, y0, x1, y1;
+	int dx, dy;
+
+	// All three of these variables should be signed (so multiplication works)
+	ptrdiff_t sx;  // Sign of x delta, positive when x0 < x1
+	const ptrdiff_t dst_depth  = FRAME_BYTES_PER_PIXEL; // PSX: 2 bytes per pixel
+	const ptrdiff_t dst_stride = FRAME_BYTE_STRIDE;     // PSX: 2048 bytes per framebuffer line
+
+	// Clip region: xmax/ymax seem to normally be one *past* the rightmost/
+	//  bottommost pixels of the draw area. Since we render every pixel between
+	//  and including both line endpoints, subtract one from xmax/ymax.
+	const int xmin = gpu_unai.DrawingArea[0];
+	const int ymin = gpu_unai.DrawingArea[1];
+	const int xmax = gpu_unai.DrawingArea[2] - 1;
+	const int ymax = gpu_unai.DrawingArea[3] - 1;
+
+	x0 = GPU_EXPANDSIGN(packet.S2[2]) + gpu_unai.DrawingOffset[0];
+	y0 = GPU_EXPANDSIGN(packet.S2[3]) + gpu_unai.DrawingOffset[1];
+	x1 = GPU_EXPANDSIGN(packet.S2[4]) + gpu_unai.DrawingOffset[0];
+	y1 = GPU_EXPANDSIGN(packet.S2[5]) + gpu_unai.DrawingOffset[1];
+
+	// Always draw top to bottom, so ensure y0 <= y1
+	if (y0 > y1) {
+		SwapValues(y0, y1);
+		SwapValues(x0, x1);
+	}
+
+	// Is line totally outside Y clipping range?
+	if (y0 > ymax || y1 < ymin) return;
+
+	dx = x1 - x0;
+	dy = y1 - y0;
+
+	// X-axis range check : max distance between any two X coords is 1023
+	// (PSX hardware will not render anything violating this rule)
+	// NOTE: We'll check y coord range further below
+	if (dx >= CHKMAX_X || dx <= -CHKMAX_X)
+		return;
+
+	// Y-axis range check and clipping
+	if (dy) {
+		// Y-axis range check : max distance between any two Y coords is 511
+		// (PSX hardware will not render anything violating this rule)
+		if (dy >= CHKMAX_Y)
+			return;
+
+		// We already know y0 < y1
+		if (y0 < ymin) {
+			x0 += GPU_FAST_DIV(((ymin - y0) * dx), dy);
+			y0 = ymin;
 		}
-		y1 = GPU_DIV((y1 - y0) << GPU_DIGITS, dx);
-		y0 <<= GPU_DIGITS;
-		temp = xmin - x0;
-		if (temp > 0) {
-			x0 = xmin;
-			y0 += (y1 * temp);
+		if (y1 > ymax) {
+			x1 += GPU_FAST_DIV(((ymax - y1) * dx), dy);
+			y1 = ymax;
 		}
-		if (x1 > xmax) x1 = xmax;
-		x1 -= x0;
-		if (x1 < 0) x1 = 0;
-
-		const int li=linesInterlace;
-		for (; x1; x1--) {
-			temp = y0 >> GPU_DIGITS;
-			if( 0 == (temp&li) )  {
-				if ((u32) (temp - ymin) < (u32) (ymax - ymin)) {
-					gpuPixelDriver(&((u16*)GPU_FrameBuffer)[FRAME_OFFSET(x0, temp)],pixeldata);
-				}
+
+		// Recompute in case clipping occurred:
+		dx = x1 - x0;
+		dy = y1 - y0;
+	}
+
+	// Check X clipping range, set 'sx' x-direction variable
+	if (dx == 0) {
+		// Is vertical line totally outside X clipping range?
+		if (x0 < xmin || x0 > xmax)
+			return;
+		sx = 0;
+	} else {
+		if (dx > 0) {
+			// x0 is leftmost coordinate
+			if (x0 > xmax) return; // Both points outside X clip range
+
+			if (x0 < xmin) {
+				if (x1 < xmin) return; // Both points outside X clip range
+				y0 += GPU_FAST_DIV(((xmin - x0) * dy), dx);
+				x0 = xmin;
+			}
+
+			if (x1 > xmax) {
+				y1 += GPU_FAST_DIV(((xmax - x1) * dy), dx);
+				x1 = xmax;
+			}
+
+			sx = +1;
+			dx = x1 - x0; // Get final value, which should also be absolute value
+		} else {
+			// x1 is leftmost coordinate
+			if (x1 > xmax) return; // Both points outside X clip range
+
+			if (x1 < xmin) {
+				if (x0 < xmin) return; // Both points outside X clip range
+
+				y1 += GPU_FAST_DIV(((xmin - x1) * dy), dx);
+				x1 = xmin;
 			}
-			x0++;
-			y0 += y1;
+
+			if (x0 > xmax) {
+				y0 += GPU_FAST_DIV(((xmax - x0) * dy), dx);
+				x0 = xmax;
+			}
+
+			sx = -1;
+			dx = x0 - x1; // Get final value, which should also be absolute value
+		}
+
+		// Recompute in case clipping occurred:
+		dy = y1 - y0;
+	}
+
+	// IMPORTANT: dx,dy should now contain their absolute values
+
+	int min_length,    // Minimum length of a pixel run
+	    start_length,  // Length of first run
+	    end_length,    // Length of last run
+	    err_term,      // Cumulative error to determine when to draw longer run
+	    err_adjup,     // Increment to err_term for each run drawn
+	    err_adjdown;   // Subract this from err_term after drawing longer run
+
+	// Color to draw with (16 bits, highest of which is unset mask bit)
+	uintptr_t col16 = GPU_RGB16(packet.U4[0]);
+
+	// We use u8 pointers even though PS1 has u16 framebuffer.
+	//  This allows pixel-drawing functions to increment dst pointer
+	//  directly by the passed 'incr' value, not having to shift it first.
+	u8 *dst = (u8*)gpu_unai.vram + y0 * dst_stride + x0 * dst_depth;
+
+	// SPECIAL CASE: Vertical line
+	if (dx == 0) {
+		gpuPixelSpanDriver(dst, col16, dst_stride, dy+1);
+		return;
+	}
+
+	// SPECIAL CASE: Horizontal line
+	if (dy == 0) {
+		gpuPixelSpanDriver(dst, col16, sx * dst_depth, dx+1);
+		return;
+	}
+
+	// SPECIAL CASE: Diagonal line
+	if (dx == dy) {
+		gpuPixelSpanDriver(dst, col16, dst_stride + (sx * dst_depth), dy+1);
+		return;
+	}
+
+	int       major, minor;             // Major axis, minor axis
+	ptrdiff_t incr_major, incr_minor;   // Ptr increment for each step along axis
+
+	if (dx > dy) {
+		major = dx;
+		minor = dy;
+	} else {
+		major = dy;
+		minor = dx;
+	}
+
+	// Determine if diagonal or horizontal runs
+	if (major < (2 * minor)) {
+		// Diagonal runs, so perform half-octant transformation
+		minor = major - minor;
+
+		// Advance diagonally when drawing runs
+		incr_major = dst_stride + (sx * dst_depth);
+
+		// After drawing each run, correct for over-advance along minor axis
+		if (dx > dy)
+			incr_minor = -dst_stride;
+		else
+			incr_minor = -sx * dst_depth;
+	} else {
+		// Horizontal or vertical runs
+		if (dx > dy) {
+			incr_major = sx * dst_depth;
+			incr_minor = dst_stride;
+		} else {
+			incr_major = dst_stride;
+			incr_minor = sx * dst_depth;
 		}
-	} else if (dy) {
-		if (y0 > y1) {
-			GPU_SWAP(x0, x1, temp);
-			GPU_SWAP(y0, y1, temp);
+	}
+
+	if (minor > 1) {
+		// Minimum number of pixels each run
+		min_length = major / minor;
+
+		// Initial error term; reflects an initial step of 0.5 along minor axis
+		err_term = (major % minor) - (minor * 2);
+
+		// Increment err_term this much each step along minor axis; when
+		//  err_term crosses zero, draw longer pixel run.
+		err_adjup = (major % minor) * 2;
+	} else {
+		min_length = major;
+		err_term = 0;
+		err_adjup = 0;
+	}
+
+	// Error term adjustment when err_term turns over; used to factor
+	//  out the major-axis step made at that time
+	err_adjdown = minor * 2;
+
+	// The initial and last runs are partial, because minor axis advances
+	//  only 0.5 for these runs, rather than 1. Each is half a full run,
+	//  plus the initial pixel.
+	start_length = end_length = (min_length / 2) + 1;
+
+	if (min_length & 1) {
+		// If there're an odd number of pixels per run, we have 1 pixel that
+		//  can't be allocated to either the initial or last partial run, so
+		//  we'll add 0.5 to err_term so that this pixel will be handled
+		//  by the normal full-run loop
+		err_term += minor;
+	} else {
+		// If the minimum run length is even and there's no fractional advance,
+		// we have one pixel that could go to either the initial or last
+		// partial run, which we arbitrarily allocate to the last run
+		if (err_adjup == 0)
+			start_length--; // Leave out the extra pixel at the start
+	}
+
+	// First run of pixels
+	dst = gpuPixelSpanDriver(dst, col16, incr_major, start_length);
+	dst += incr_minor;
+
+	// Middle runs of pixels
+	while (--minor > 0) {
+		int run_length = min_length;
+		err_term += err_adjup;
+
+		// If err_term passed 0, reset it and draw longer run
+		if (err_term > 0) {
+			err_term -= err_adjdown;
+			run_length++;
 		}
-		x1 = GPU_DIV((x1 - x0) << GPU_DIGITS, dy);
-		x0 <<= GPU_DIGITS;
-		temp = ymin - y0;
-		if (temp > 0) {
+
+		dst = gpuPixelSpanDriver(dst, col16, incr_major, run_length);
+		dst += incr_minor;
+	}
+
+	// Final run of pixels
+	gpuPixelSpanDriver(dst, col16, incr_major, end_length);
+}
+
+/////////////////////////
+// Gouraud-shaded line //
+/////////////////////////
+void gpuDrawLineG(PtrUnion packet, const PSD gpuPixelSpanDriver)
+{
+	int x0, y0, x1, y1;
+	int dx, dy, dr, dg, db;
+	u32 r0, g0, b0, r1, g1, b1;
+
+	// All three of these variables should be signed (so multiplication works)
+	ptrdiff_t sx;  // Sign of x delta, positive when x0 < x1
+	const ptrdiff_t dst_depth  = FRAME_BYTES_PER_PIXEL; // PSX: 2 bytes per pixel
+	const ptrdiff_t dst_stride = FRAME_BYTE_STRIDE;     // PSX: 2048 bytes per framebuffer line
+
+	// Clip region: xmax/ymax seem to normally be one *past* the rightmost/
+	//  bottommost pixels of the draw area. We'll render every pixel between
+	//  and including both line endpoints, so subtract one from xmax/ymax.
+	const int xmin = gpu_unai.DrawingArea[0];
+	const int ymin = gpu_unai.DrawingArea[1];
+	const int xmax = gpu_unai.DrawingArea[2] - 1;
+	const int ymax = gpu_unai.DrawingArea[3] - 1;
+
+	x0 = GPU_EXPANDSIGN(packet.S2[2]) + gpu_unai.DrawingOffset[0];
+	y0 = GPU_EXPANDSIGN(packet.S2[3]) + gpu_unai.DrawingOffset[1];
+	x1 = GPU_EXPANDSIGN(packet.S2[6]) + gpu_unai.DrawingOffset[0];
+	y1 = GPU_EXPANDSIGN(packet.S2[7]) + gpu_unai.DrawingOffset[1];
+
+	u32 col0 = packet.U4[0];
+	u32 col1 = packet.U4[2];
+
+	// Always draw top to bottom, so ensure y0 <= y1
+	if (y0 > y1) {
+		SwapValues(y0, y1);
+		SwapValues(x0, x1);
+		SwapValues(col0, col1);
+	}
+
+	// Is line totally outside Y clipping range?
+	if (y0 > ymax || y1 < ymin) return;
+
+	// If defined, Gouraud colors are fixed-point 5.11, otherwise they are 8.16
+	// (This is only beneficial if using SIMD-optimized pixel driver)
+#ifdef GPU_GOURAUD_LOW_PRECISION
+	r0 = (col0 >> 3) & 0x1f;  g0 = (col0 >> 11) & 0x1f;  b0 = (col0 >> 19) & 0x1f;
+	r1 = (col1 >> 3) & 0x1f;  g1 = (col1 >> 11) & 0x1f;  b1 = (col1 >> 19) & 0x1f;
+#else
+	r0 = col0 & 0xff;  g0 = (col0 >> 8) & 0xff;  b0 = (col0 >> 16) & 0xff;
+	r1 = col1 & 0xff;  g1 = (col1 >> 8) & 0xff;  b1 = (col1 >> 16) & 0xff;
+#endif
+
+	dx = x1 - x0;
+	dy = y1 - y0;
+	dr = r1 - r0;
+	dg = g1 - g0;
+	db = b1 - b0;
+
+	// X-axis range check : max distance between any two X coords is 1023
+	// (PSX hardware will not render anything violating this rule)
+	// NOTE: We'll check y coord range further below
+	if (dx >= CHKMAX_X || dx <= -CHKMAX_X)
+		return;
+
+	// Y-axis range check and clipping
+	if (dy) {
+		// Y-axis range check : max distance between any two Y coords is 511
+		// (PSX hardware will not render anything violating this rule)
+		if (dy >= CHKMAX_Y)
+			return;
+
+		// We already know y0 < y1
+		if (y0 < ymin) {
+#ifdef USE_LINES_ALL_FIXED_PT_MATH
+			s32 factor = GPU_FAST_DIV(((ymin - y0) << GPU_LINE_FIXED_BITS), dy);
+			x0 += (dx * factor) >> GPU_LINE_FIXED_BITS;
+			r0 += (dr * factor) >> GPU_LINE_FIXED_BITS;
+			g0 += (dg * factor) >> GPU_LINE_FIXED_BITS;
+			b0 += (db * factor) >> GPU_LINE_FIXED_BITS;
+#else
+			x0 += (ymin - y0) * dx / dy;
+			r0 += (ymin - y0) * dr / dy;
+			g0 += (ymin - y0) * dg / dy;
+			b0 += (ymin - y0) * db / dy;
+#endif
 			y0 = ymin;
-			x0 += (x1 * temp);
 		}
-		if (y1 > ymax) y1 = ymax;
-		y1 -= y0;
-		if (y1 < 0) y1 = 0;
-		
-		const int li=linesInterlace;
-		for (; y1; y1--) {
-			if( 0 == (y0&li) )  {
-				temp = x0 >> GPU_DIGITS;
-				if ((u32) (temp - xmin) < (u32) (xmax - xmin)) {
-					gpuPixelDriver(&((u16*)GPU_FrameBuffer)[FRAME_OFFSET(temp, y0)],pixeldata);
-				}
-			}
-			y0++;
-			x0 += x1;
+
+		if (y1 > ymax) {
+#ifdef USE_LINES_ALL_FIXED_PT_MATH
+			s32 factor = GPU_FAST_DIV(((ymax - y1) << GPU_LINE_FIXED_BITS), dy);
+			x1 += (dx * factor) >> GPU_LINE_FIXED_BITS;
+			r1 += (dr * factor) >> GPU_LINE_FIXED_BITS;
+			g1 += (dg * factor) >> GPU_LINE_FIXED_BITS;
+			b1 += (db * factor) >> GPU_LINE_FIXED_BITS;
+#else
+			x1 += (ymax - y1) * dx / dy;
+			r1 += (ymax - y1) * dr / dy;
+			g1 += (ymax - y1) * dg / dy;
+			b1 += (ymax - y1) * db / dy;
+#endif
+			y1 = ymax;
 		}
-		
+
+		// Recompute in case clipping occurred:
+		dx = x1 - x0;
+		dy = y1 - y0;
+		dr = r1 - r0;
+		dg = g1 - g0;
+		db = b1 - b0;
+	}
+
+	// Check X clipping range, set 'sx' x-direction variable
+	if (dx == 0) {
+		// Is vertical line totally outside X clipping range?
+		if (x0 < xmin || x0 > xmax)
+			return;
+		sx = 0;
 	} else {
-		if( 0 == (y0&linesInterlace) )  {
-			if ((u32) (x0 - xmin) < (u32) (xmax - xmin)) {
-				if ((u32) (y0 - ymin) < (u32) (ymax - ymin)) {
-					gpuPixelDriver(&((u16*)GPU_FrameBuffer)[FRAME_OFFSET(x0, y0)],pixeldata);
-				}
+		if (dx > 0) {
+			// x0 is leftmost coordinate
+			if (x0 > xmax) return; // Both points outside X clip range
+
+			if (x0 < xmin) {
+				if (x1 < xmin) return; // Both points outside X clip range
+
+#ifdef USE_LINES_ALL_FIXED_PT_MATH
+				s32 factor = GPU_FAST_DIV(((xmin - x0) << GPU_LINE_FIXED_BITS), dx);
+				y0 += (dy * factor) >> GPU_LINE_FIXED_BITS;
+				r0 += (dr * factor) >> GPU_LINE_FIXED_BITS;
+				g0 += (dg * factor) >> GPU_LINE_FIXED_BITS;
+				b0 += (db * factor) >> GPU_LINE_FIXED_BITS;
+#else
+				y0 += (xmin - x0) * dy / dx;
+				r0 += (xmin - x0) * dr / dx;
+				g0 += (xmin - x0) * dg / dx;
+				b0 += (xmin - x0) * db / dx;
+#endif
+				x0 = xmin;
 			}
+
+			if (x1 > xmax) {
+#ifdef USE_LINES_ALL_FIXED_PT_MATH
+				s32 factor = GPU_FAST_DIV(((xmax - x1) << GPU_LINE_FIXED_BITS), dx);
+				y1 += (dy * factor) >> GPU_LINE_FIXED_BITS;
+				r1 += (dr * factor) >> GPU_LINE_FIXED_BITS;
+				g1 += (dg * factor) >> GPU_LINE_FIXED_BITS;
+				b1 += (db * factor) >> GPU_LINE_FIXED_BITS;
+#else
+				y1 += (xmax - x1) * dy / dx;
+				r1 += (xmax - x1) * dr / dx;
+				g1 += (xmax - x1) * dg / dx;
+				b1 += (xmax - x1) * db / dx;
+#endif
+				x1 = xmax;
+			}
+
+			sx = +1;
+			dx = x1 - x0; // Get final value, which should also be absolute value
+		} else {
+			// x1 is leftmost coordinate
+			if (x1 > xmax) return; // Both points outside X clip range
+
+			if (x1 < xmin) {
+				if (x0 < xmin) return; // Both points outside X clip range
+
+#ifdef USE_LINES_ALL_FIXED_PT_MATH
+				s32 factor = GPU_FAST_DIV(((xmin - x1) << GPU_LINE_FIXED_BITS), dx);
+				y1 += (dy * factor) >> GPU_LINE_FIXED_BITS;
+				r1 += (dr * factor) >> GPU_LINE_FIXED_BITS;
+				g1 += (dg * factor) >> GPU_LINE_FIXED_BITS;
+				b1 += (db * factor) >> GPU_LINE_FIXED_BITS;
+#else
+				y1 += (xmin - x1) * dy / dx;
+				r1 += (xmin - x1) * dr / dx;
+				g1 += (xmin - x1) * dg / dx;
+				b1 += (xmin - x1) * db / dx;
+#endif
+				x1 = xmin;
+			}
+
+			if (x0 > xmax) {
+#ifdef USE_LINES_ALL_FIXED_PT_MATH
+				s32 factor = GPU_FAST_DIV(((xmax - x0) << GPU_LINE_FIXED_BITS), dx);
+				y0 += (dy * factor) >> GPU_LINE_FIXED_BITS;
+				r0 += (dr * factor) >> GPU_LINE_FIXED_BITS;
+				g0 += (dg * factor) >> GPU_LINE_FIXED_BITS;
+				b0 += (db * factor) >> GPU_LINE_FIXED_BITS;
+#else
+				y0 += (xmax - x0) * dy / dx;
+				r0 += (xmax - x0) * dr / dx;
+				g0 += (xmax - x0) * dg / dx;
+				b0 += (xmax - x0) * db / dx;
+#endif
+				x0 = xmax;
+			}
+
+			sx = -1;
+			dx = x0 - x1; // Get final value, which should also be absolute value
 		}
+
+		// Recompute in case clipping occurred:
+		dy = y1 - y0;
+		dr = r1 - r0;
+		dg = g1 - g0;
+		db = b1 - b0;
 	}
-}
 
-/*----------------------------------------------------------------------
-GF
-----------------------------------------------------------------------*/
+	// IMPORTANT: dx,dy should now contain their absolute values
 
-///////////////////////////////////////////////////////////////////////////////
-void gpuDrawLG(const PD gpuPixelDriver)
-{
-	s32 temp;
-	s32 xmin, xmax;
-	s32 ymin, ymax;
-	s32 x0, x1, dx;
-	s32 y0, y1, dy;
-	s32 r0, r1;
-	s32 g0, g1;
-	s32 b0, b1;
-
-	x0 = PacketBuffer.S2[2] + DrawingOffset[0];	GPU_TESTRANGE(x0);
-	y0 = PacketBuffer.S2[3] + DrawingOffset[1];	GPU_TESTRANGE(y0);
-	x1 = PacketBuffer.S2[6] + DrawingOffset[0];	GPU_TESTRANGE(x1);
-	y1 = PacketBuffer.S2[7] + DrawingOffset[1];	GPU_TESTRANGE(y1);
-
-	r0 = PacketBuffer.U1[0];  g0 = PacketBuffer.U1[1];  b0 = PacketBuffer.U1[2];
-	r1 = PacketBuffer.U1[8];  g1 = PacketBuffer.U1[9];	b1 = PacketBuffer.U1[10];
-
-	xmin = DrawingArea[0];	xmax = DrawingArea[2];
-	ymin = DrawingArea[1];	ymax = DrawingArea[3];
-
-	dy = (y1 - y0);
-	if (dy < 0)
-	dy = -dy;
-	dx = (x1 - x0);
-	if (dx < 0)
-	dx = -dx;
-	if (dx > dy) {
-		if (x0 > x1) {
-			GPU_SWAP(x0, x1, temp);
-			GPU_SWAP(y0, y1, temp);
-			GPU_SWAP(r0, r1, temp);
-			GPU_SWAP(g0, g1, temp);
-			GPU_SWAP(b0, b1, temp);
-		}
-		y1 = GPU_DIV((y1 - y0) << GPU_DIGITS, dx);
-		r1 = GPU_DIV((r1 - r0) << GPU_DIGITS, dx);
-		g1 = GPU_DIV((g1 - g0) << GPU_DIGITS, dx);
-		b1 = GPU_DIV((b1 - b0) << GPU_DIGITS, dx);
-		y0 <<= GPU_DIGITS;
-		r0 <<= GPU_DIGITS;
-		g0 <<= GPU_DIGITS;
-		b0 <<= GPU_DIGITS;
-		temp = xmin - x0;
-		if (temp > 0) {
-			x0 = xmin;
-			y0 += (y1 * temp);
-			r0 += (r1 * temp);
-			g0 += (g1 * temp);
-			b0 += (b1 * temp);
+	int min_length,    // Minimum length of a pixel run
+	    start_length,  // Length of first run
+	    end_length,    // Length of last run
+	    err_term,      // Cumulative error to determine when to draw longer run
+	    err_adjup,     // Increment to err_term for each run drawn
+	    err_adjdown;   // Subract this from err_term after drawing longer run
+
+	GouraudColor gcol;
+	gcol.r = r0 << GPU_GOURAUD_FIXED_BITS;
+	gcol.g = g0 << GPU_GOURAUD_FIXED_BITS;
+	gcol.b = b0 << GPU_GOURAUD_FIXED_BITS;
+
+	// We use u8 pointers even though PS1 has u16 framebuffer.
+	//  This allows pixel-drawing functions to increment dst pointer
+	//  directly by the passed 'incr' value, not having to shift it first.
+	u8 *dst = (u8*)gpu_unai.vram + y0 * dst_stride + x0 * dst_depth;
+
+	// SPECIAL CASE: Vertical line
+	if (dx == 0) {
+#ifdef USE_LINES_ALL_FIXED_PT_MATH
+		// Get dy fixed-point inverse
+		s32 inv_factor = 1 << GPU_GOURAUD_FIXED_BITS;
+		if (dy > 1) inv_factor = GPU_FAST_DIV(inv_factor, dy);
+
+		// Simultaneously divide and convert integer to Gouraud fixed point:
+		gcol.r_incr = dr * inv_factor;
+		gcol.g_incr = dg * inv_factor;
+		gcol.b_incr = db * inv_factor;
+#else
+		// First, convert to Gouraud fixed point
+		gcol.r_incr = dr << GPU_GOURAUD_FIXED_BITS;
+		gcol.g_incr = dg << GPU_GOURAUD_FIXED_BITS;
+		gcol.b_incr = db << GPU_GOURAUD_FIXED_BITS;
+
+		if (dy > 1) {
+			if (dr) gcol.r_incr /= dy;
+			if (dg) gcol.g_incr /= dy;
+			if (db) gcol.b_incr /= dy;
 		}
-		if (x1 > xmax) x1 = xmax;
-		x1 -= x0;
-		if (x1 < 0) x1 = 0;
+#endif
 		
-		const int li=linesInterlace;
-		for (; x1; x1--) {
-			temp = y0 >> GPU_DIGITS;
-			if( 0 == (temp&li) )  {
-				if ((u32) (temp - ymin) < (u32) (ymax - ymin)) {
-					gpuPixelDriver (
-						&((u16*)GPU_FrameBuffer)[FRAME_OFFSET(x0, temp)],
-						(((b0>>GPU_DIGITSC)&0x1F)<<10) | (((g0>>GPU_DIGITSC)&0x1F)<< 5) | ((r0>>GPU_DIGITSC)&0x1F)
-					);
-				}
-			}
-			x0++;
-			y0 += y1;
-			r0 += r1;
-			g0 += g1;
-			b0 += b1;
-		}
-	} else if (dy) {
-		if (y0 > y1) {
-			GPU_SWAP(x0, x1, temp);
-			GPU_SWAP(y0, y1, temp);
-			GPU_SWAP(r0, r1, temp);
-			GPU_SWAP(g0, g1, temp);
-			GPU_SWAP(b0, b1, temp);
+		gpuPixelSpanDriver(dst, (uintptr_t)&gcol, dst_stride, dy+1);
+		return;
+	}
+
+	// SPECIAL CASE: Horizontal line
+	if (dy == 0) {
+#ifdef USE_LINES_ALL_FIXED_PT_MATH
+		// Get dx fixed-point inverse
+		s32 inv_factor = (1 << GPU_GOURAUD_FIXED_BITS);
+		if (dx > 1) inv_factor = GPU_FAST_DIV(inv_factor, dx);
+
+		// Simultaneously divide and convert integer to Gouraud fixed point:
+		gcol.r_incr = dr * inv_factor;
+		gcol.g_incr = dg * inv_factor;
+		gcol.b_incr = db * inv_factor;
+#else
+		gcol.r_incr = dr << GPU_GOURAUD_FIXED_BITS;
+		gcol.g_incr = dg << GPU_GOURAUD_FIXED_BITS;
+		gcol.b_incr = db << GPU_GOURAUD_FIXED_BITS;
+
+		if (dx > 1) {
+			if (dr) gcol.r_incr /= dx;
+			if (dg) gcol.g_incr /= dx;
+			if (db) gcol.b_incr /= dx;
 		}
-		x1 = GPU_DIV((x1 - x0) << GPU_DIGITS, dy);
-		r1 = GPU_DIV((r1 - r0) << GPU_DIGITS, dy);
-		g1 = GPU_DIV((g1 - g0) << GPU_DIGITS, dy);
-		b1 = GPU_DIV((b1 - b0) << GPU_DIGITS, dy);
-		x0 <<= GPU_DIGITS;
-		r0 <<= GPU_DIGITS;
-		g0 <<= GPU_DIGITS;
-		b0 <<= GPU_DIGITS;
-		temp = ymin - y0;
-		if (temp > 0) {
-			y0 = ymin;
-			x0 += (x1 * temp);
-			r0 += (r1 * temp);
-			g0 += (g1 * temp);
-			b0 += (b1 * temp);
+#endif
+
+		gpuPixelSpanDriver(dst, (uintptr_t)&gcol, sx * dst_depth, dx+1);
+		return;
+	}
+
+	// SPECIAL CASE: Diagonal line
+	if (dx == dy) {
+#ifdef USE_LINES_ALL_FIXED_PT_MATH
+		// Get dx fixed-point inverse
+		s32 inv_factor = (1 << GPU_GOURAUD_FIXED_BITS);
+		if (dx > 1) inv_factor = GPU_FAST_DIV(inv_factor, dx);
+
+		// Simultaneously divide and convert integer to Gouraud fixed point:
+		gcol.r_incr = dr * inv_factor;
+		gcol.g_incr = dg * inv_factor;
+		gcol.b_incr = db * inv_factor;
+#else
+		// First, convert to Gouraud fixed point
+		gcol.r_incr = dr << GPU_GOURAUD_FIXED_BITS;
+		gcol.g_incr = dg << GPU_GOURAUD_FIXED_BITS;
+		gcol.b_incr = db << GPU_GOURAUD_FIXED_BITS;
+
+		if (dx > 1) {
+			if (dr) gcol.r_incr /= dx;
+			if (dg) gcol.g_incr /= dx;
+			if (db) gcol.b_incr /= dx;
 		}
-		if (y1 > ymax) y1 = ymax;
-		y1 -= y0;
-		if (y1 < 0) y1 = 0;
-		
-		const int li=linesInterlace;
-		for (; y1; y1--) {
-			if( 0 == (y0&li) )  {
-				temp = x0 >> GPU_DIGITS;
-				if ((u32) (temp - xmin) < (u32) (xmax - xmin)) {
-					gpuPixelDriver (
-						&((u16*)GPU_FrameBuffer)[FRAME_OFFSET(temp, y0)],
-						(((b0>>GPU_DIGITSC)&0x1F)<<10) | (((g0>>GPU_DIGITSC)&0x1F)<< 5) | ((r0>>GPU_DIGITSC)&0x1F)
-					);
-				}
-			}
-			y0++;
-			x0 += x1;
-			r0 += r1;
-			g0 += g1;
-			b0 += b1;
+#endif
+
+		gpuPixelSpanDriver(dst, (uintptr_t)&gcol, dst_stride + (sx * dst_depth), dy+1);
+		return;
+	}
+
+	int       major, minor;             // Absolute val of major,minor axis delta
+	ptrdiff_t incr_major, incr_minor;   // Ptr increment for each step along axis
+
+	if (dx > dy) {
+		major = dx;
+		minor = dy;
+	} else {
+		major = dy;
+		minor = dx;
+	}
+
+	// Determine if diagonal or horizontal runs
+	if (major < (2 * minor)) {
+		// Diagonal runs, so perform half-octant transformation
+		minor = major - minor;
+
+		// Advance diagonally when drawing runs
+		incr_major = dst_stride + (sx * dst_depth);
+
+		// After drawing each run, correct for over-advance along minor axis
+		if (dx > dy)
+			incr_minor = -dst_stride;
+		else
+			incr_minor = -sx * dst_depth;
+	} else {
+		// Horizontal or vertical runs
+		if (dx > dy) {
+			incr_major = sx * dst_depth;
+			incr_minor = dst_stride;
+		} else {
+			incr_major = dst_stride;
+			incr_minor = sx * dst_depth;
 		}
+	}
+
+#ifdef USE_LINES_ALL_FIXED_PT_MATH
+	s32 major_inv = GPU_FAST_DIV((1 << GPU_GOURAUD_FIXED_BITS), major);
+
+	// Simultaneously divide and convert from integer to Gouraud fixed point:
+	gcol.r_incr = dr * major_inv;
+	gcol.g_incr = dg * major_inv;
+	gcol.b_incr = db * major_inv;
+#else
+	gcol.r_incr = dr ? ((dr << GPU_GOURAUD_FIXED_BITS) / major) : 0;
+	gcol.g_incr = dg ? ((dg << GPU_GOURAUD_FIXED_BITS) / major) : 0;
+	gcol.b_incr = db ? ((db << GPU_GOURAUD_FIXED_BITS) / major) : 0;
+#endif
+
+	if (minor > 1) {
+		// Minimum number of pixels each run
+		min_length = major / minor;
+
+		// Initial error term; reflects an initial step of 0.5 along minor axis
+		err_term = (major % minor) - (minor * 2);
+
+		// Increment err_term this much each step along minor axis; when
+		//  err_term crosses zero, draw longer pixel run.
+		err_adjup = (major % minor) * 2;
 	} else {
-		if( 0 == (y0&linesInterlace) )  {
-			if ((u32) (x0 - xmin) < (u32) (xmax - xmin)) {
-				if ((u32) (y0 - ymin) < (u32) (ymax - ymin)) {
-					gpuPixelDriver (
-						&((u16*)GPU_FrameBuffer)[FRAME_OFFSET(x0, y0)],
-						(((b0>>GPU_DIGITSC)&0x1F)<<10) | (((g0>>GPU_DIGITSC)&0x1F)<< 5) | ((r0>>GPU_DIGITSC)&0x1F)
-					);
-				}
-			}
+		min_length = major;
+		err_term = 0;
+		err_adjup = 0;
+	}
+
+	// Error term adjustment when err_term turns over; used to factor
+	//  out the major-axis step made at that time
+	err_adjdown = minor * 2;
+
+	// The initial and last runs are partial, because minor axis advances
+	//  only 0.5 for these runs, rather than 1. Each is half a full run,
+	//  plus the initial pixel.
+	start_length = end_length = (min_length / 2) + 1;
+
+	if (min_length & 1) {
+		// If there're an odd number of pixels per run, we have 1 pixel that
+		//  can't be allocated to either the initial or last partial run, so
+		//  we'll add 0.5 to err_term so that this pixel will be handled
+		//  by the normal full-run loop
+		err_term += minor;
+	} else {
+		// If the minimum run length is even and there's no fractional advance,
+		// we have one pixel that could go to either the initial or last
+		// partial run, which we'll arbitrarily allocate to the last run
+		if (err_adjup == 0)
+			start_length--; // Leave out the extra pixel at the start
+	}
+
+	// First run of pixels
+	dst = gpuPixelSpanDriver(dst, (uintptr_t)&gcol, incr_major, start_length);
+	dst += incr_minor;
+
+	// Middle runs of pixels
+	while (--minor > 0) {
+		int run_length = min_length;
+		err_term += err_adjup;
+
+		// If err_term passed 0, reset it and draw longer run
+		if (err_term > 0) {
+			err_term -= err_adjdown;
+			run_length++;
 		}
+
+		dst = gpuPixelSpanDriver(dst, (uintptr_t)&gcol, incr_major, run_length);
+		dst += incr_minor;
 	}
+
+	// Final run of pixels
+	gpuPixelSpanDriver(dst, (uintptr_t)&gcol, incr_major, end_length);
 }
diff --git a/plugins/gpu_unai/gpu_raster_polygon.h b/plugins/gpu_unai/gpu_raster_polygon.h
index c4b03509..f66a9e20 100644
--- a/plugins/gpu_unai/gpu_raster_polygon.h
+++ b/plugins/gpu_unai/gpu_raster_polygon.h
@@ -18,732 +18,1431 @@
 *   51 Franklin Street, Fifth Floor, Boston, MA 02111-1307 USA.           *
 ***************************************************************************/
 
-#define GPU_TESTRANGE3() \
-{ \
-	if(x0<0) { if((x1-x0)>CHKMAX_X) return; if((x2-x0)>CHKMAX_X) return; } \
-	if(x1<0) { if((x0-x1)>CHKMAX_X) return; if((x2-x1)>CHKMAX_X) return; } \
-	if(x2<0) { if((x0-x2)>CHKMAX_X) return; if((x1-x2)>CHKMAX_X) return; } \
-	if(y0<0) { if((y1-y0)>CHKMAX_Y) return; if((y2-y0)>CHKMAX_Y) return; } \
-	if(y1<0) { if((y0-y1)>CHKMAX_Y) return; if((y2-y1)>CHKMAX_Y) return; } \
-	if(y2<0) { if((y0-y2)>CHKMAX_Y) return; if((y1-y2)>CHKMAX_Y) return; } \
-}
+//senquack - NOTE: GPU Unai poly routines have been rewritten/adapted
+// from DrHell routines to fix multiple issues. See README_senquack.txt
 
 ///////////////////////////////////////////////////////////////////////////////
-//  GPU internal polygon drawing functions
+// Shared poly vertex buffer, able to handle 3 or 4-pt polys of any type.
+///////////////////////////////////////////////////////////////////////////////
 
+struct PolyVertex {
+	s32 x, y; // Sign-extended 11-bit X,Y coords
+	union {
+		struct { u8 u, v, pad[2]; } tex; // Texture coords (if used)
+		u32 tex_word;
+	};
+	union {
+		struct { u8 r, g, b, pad; } col; // 24-bit RGB color (if used)
+		u32 col_word;
+	};
+};
+
+enum PolyAttribute {
+	POLYATTR_TEXTURE = (1 << 0),
+	POLYATTR_GOURAUD = (1 << 1)
+};
+
+enum PolyType {
+	POLYTYPE_F  = 0,
+	POLYTYPE_FT = (POLYATTR_TEXTURE),
+	POLYTYPE_G  = (POLYATTR_GOURAUD),
+	POLYTYPE_GT = (POLYATTR_TEXTURE | POLYATTR_GOURAUD)
+};
+
+///////////////////////////////////////////////////////////////////////////////
+// polyInitVertexBuffer()
+// Fills vbuf[] array with data from any type of poly draw-command packet.
 ///////////////////////////////////////////////////////////////////////////////
-void gpuDrawF3(const PP gpuPolySpanDriver)
+static void polyInitVertexBuffer(PolyVertex *vbuf, const PtrUnion packet, PolyType ptype, u32 is_quad)
 {
-	const int li=linesInterlace;
-	s32 temp;
-	s32 xa, xb, xmin, xmax;
-	s32 ya, yb, ymin, ymax;
-	s32 x0, x1, x2, x3, dx3=0, x4, dx4=0, dx;
-	s32 y0, y1, y2;
+	bool texturing = ptype & POLYATTR_TEXTURE;
+	bool gouraud   = ptype & POLYATTR_GOURAUD;
+
+	int vert_stride = 1; // Stride of vertices in cmd packet, in 32-bit words
+	if (texturing)
+		vert_stride++;
+	if (gouraud)
+		vert_stride++;
+
+	int num_verts = (is_quad) ? 4 : 3;
+	u32 *ptr;
+
+	// X,Y coords, adjusted by draw offsets
+	s32 x_off = gpu_unai.DrawingOffset[0];
+	s32 y_off = gpu_unai.DrawingOffset[1];
+	ptr = &packet.U4[1];
+	for (int i=0;  i < num_verts; ++i, ptr += vert_stride) {
+		s16* coord_ptr = (s16*)ptr;
+		vbuf[i].x = GPU_EXPANDSIGN(coord_ptr[0]) + x_off;
+		vbuf[i].y = GPU_EXPANDSIGN(coord_ptr[1]) + y_off;
+	}
 
-	x0 = GPU_EXPANDSIGN(PacketBuffer.S2[2]);
-	y0 = GPU_EXPANDSIGN(PacketBuffer.S2[3]);
-	x1 = GPU_EXPANDSIGN(PacketBuffer.S2[4]);
-	y1 = GPU_EXPANDSIGN(PacketBuffer.S2[5]);
-	x2 = GPU_EXPANDSIGN(PacketBuffer.S2[6]);
-	y2 = GPU_EXPANDSIGN(PacketBuffer.S2[7]);
+	// U,V texture coords (if applicable)
+	if (texturing) {
+		ptr = &packet.U4[2];
+		for (int i=0;  i < num_verts; ++i, ptr += vert_stride)
+			vbuf[i].tex_word = *ptr;
+	}
 
-	GPU_TESTRANGE3();
+	// Colors (if applicable)
+	if (gouraud) {
+		ptr = &packet.U4[0];
+		for (int i=0;  i < num_verts; ++i, ptr += vert_stride)
+			vbuf[i].col_word = *ptr;
+	}
+}
 
-	x0 += DrawingOffset[0];   x1 += DrawingOffset[0];   x2 += DrawingOffset[0];
-	y0 += DrawingOffset[1];   y1 += DrawingOffset[1];   y2 += DrawingOffset[1];
+///////////////////////////////////////////////////////////////////////////////
+//  Helper functions to determine which vertex in a 2 or 3 vertex array
+//   has the highest/lowest X/Y coordinate.
+//   Note: the comparison logic is such that, given a set of vertices with
+//    identical values for a given coordinate, a different index will be
+//    returned from vertIdxOfLeast..() than a call to vertIdxOfHighest..().
+//    This ensures that, during the vertex-ordering phase of rasterization,
+//    all three vertices remain unique.
+///////////////////////////////////////////////////////////////////////////////
 
-	xmin = DrawingArea[0];  xmax = DrawingArea[2];
-	ymin = DrawingArea[1];  ymax = DrawingArea[3];
+template<typename T>
+static inline int vertIdxOfLeastXCoord2(const T *Tptr)
+{
+	return (Tptr[0].x <= Tptr[1].x) ? 0 : 1;
+}
 
-	{
-		int rx0 = Max2(xmin,Min3(x0,x1,x2));
-		int ry0 = Max2(ymin,Min3(y0,y1,y2));
-		int rx1 = Min2(xmax,Max3(x0,x1,x2));
-		int ry1 = Min2(ymax,Max3(y0,y1,y2));
-		if( rx0>=rx1 || ry0>=ry1) return;
-	}
-	
-	PixelData = GPU_RGB16(PacketBuffer.U4[0]);
+template<typename T>
+static inline int vertIdxOfLeastXCoord3(const T *Tptr)
+{
+	int least_of_v0_v1 = vertIdxOfLeastXCoord2(Tptr);
+	return (Tptr[least_of_v0_v1].x <= Tptr[2].x) ? least_of_v0_v1 : 2;
+}
 
-	if (y0 >= y1)
-	{
-		if( y0!=y1 || x0>x1 )
-		{
-			GPU_SWAP(x0, x1, temp);
-			GPU_SWAP(y0, y1, temp);
-		}
-	}
-	if (y1 >= y2)
-	{
-		if( y1!=y2 || x1>x2 )
-		{
-			GPU_SWAP(x1, x2, temp);
-			GPU_SWAP(y1, y2, temp);
-		}
-	}
-	if (y0 >= y1)
-	{
-		if( y0!=y1 || x0>x1 )
-		{
-			GPU_SWAP(x0, x1, temp);
-			GPU_SWAP(y0, y1, temp);
-		}
-	}
+template<typename T>
+static inline int vertIdxOfLeastYCoord2(const T *Tptr)
+{
+	return (Tptr[0].y <= Tptr[1].y) ? 0 : 1;
+}
 
-	ya = y2 - y0;
-	yb = y2 - y1;
-	dx =(x2 - x1) * ya - (x2 - x0) * yb;
+template<typename T>
+static inline int vertIdxOfLeastYCoord3(const T *Tptr)
+{
+	int least_of_v0_v1 = vertIdxOfLeastYCoord2(Tptr);
+	return (Tptr[least_of_v0_v1].y <= Tptr[2].y) ? least_of_v0_v1 : 2;
+}
+
+template<typename T>
+static inline int vertIdxOfHighestXCoord2(const T *Tptr)
+{
+	return (Tptr[1].x >= Tptr[0].x) ? 1 : 0;
+}
+
+template<typename T>
+static inline int vertIdxOfHighestXCoord3(const T *Tptr)
+{
+	int highest_of_v0_v1 = vertIdxOfHighestXCoord2(Tptr);
+	return (Tptr[2].x >= Tptr[highest_of_v0_v1].x) ? 2 : highest_of_v0_v1;
+}
+
+template<typename T>
+static inline int vertIdxOfHighestYCoord2(const T *Tptr)
+{
+	return (Tptr[1].y >= Tptr[0].y) ? 1 : 0;
+}
+
+template<typename T>
+static inline int vertIdxOfHighestYCoord3(const T *Tptr)
+{
+	int highest_of_v0_v1 = vertIdxOfHighestYCoord2(Tptr);
+	return (Tptr[2].y >= Tptr[highest_of_v0_v1].y) ? 2 : highest_of_v0_v1;
+}
 
-	for (s32 loop0 = 2; loop0; --loop0)
+///////////////////////////////////////////////////////////////////////////////
+// polyUseTriangle()
+//  Determines if the specified triangle should be rendered. If so, it
+//  fills the given array of vertex pointers, vert_ptrs, in order of
+//  increasing Y coordinate values, as required by rasterization algorithm.
+//  Parameter 'tri_num' is 0 for first triangle (idx 0,1,2 of vbuf[]),
+//   or 1 for second triangle of a quad (idx 1,2,3 of vbuf[]).
+//  Returns true if triangle should be rendered, false if not.
+///////////////////////////////////////////////////////////////////////////////
+static bool polyUseTriangle(const PolyVertex *vbuf, int tri_num, const PolyVertex **vert_ptrs)
+{
+	// Using verts 0,1,2 or is this the 2nd pass of a quad (verts 1,2,3)?
+	const PolyVertex *tri_ptr = &vbuf[(tri_num == 0) ? 0 : 1];
+
+	// Get indices of highest/lowest X,Y coords within triangle
+	int idx_lowest_x  = vertIdxOfLeastXCoord3(tri_ptr);
+	int idx_highest_x = vertIdxOfHighestXCoord3(tri_ptr);
+	int idx_lowest_y  = vertIdxOfLeastYCoord3(tri_ptr);
+	int idx_highest_y = vertIdxOfHighestYCoord3(tri_ptr);
+
+	// Maximum absolute distance between any two X coordinates is 1023,
+	//  and for Y coordinates is 511 (PS1 hardware limitation)
+	int lowest_x  = tri_ptr[idx_lowest_x].x;
+	int highest_x = tri_ptr[idx_highest_x].x;
+	int lowest_y  = tri_ptr[idx_lowest_y].y;
+	int highest_y = tri_ptr[idx_highest_y].y;
+	if ((highest_x - lowest_x) >= CHKMAX_X ||
+	    (highest_y - lowest_y) >= CHKMAX_Y)
+		return false;
+
+	// Determine if triangle is completely outside clipping range
+	int xmin, xmax, ymin, ymax;
+	xmin = gpu_unai.DrawingArea[0];  xmax = gpu_unai.DrawingArea[2];
+	ymin = gpu_unai.DrawingArea[1];  ymax = gpu_unai.DrawingArea[3];
+	int clipped_lowest_x  = Max2(xmin,lowest_x);
+	int clipped_lowest_y  = Max2(ymin,lowest_y);
+	int clipped_highest_x = Min2(xmax,highest_x);
+	int clipped_highest_y = Min2(ymax,highest_y);
+	if (clipped_lowest_x >= clipped_highest_x ||
+	    clipped_lowest_y >= clipped_highest_y)
+		return false;
+
+	// Order vertex ptrs by increasing y value (draw routines need this).
+	// The middle index is deduced by a binary math trick that depends
+	//  on index range always being between 0..2
+	vert_ptrs[0] = tri_ptr + idx_lowest_y;
+	vert_ptrs[1] = tri_ptr + ((idx_lowest_y + idx_highest_y) ^ 3);
+	vert_ptrs[2] = tri_ptr + idx_highest_y;
+	return true;
+}
+
+///////////////////////////////////////////////////////////////////////////////
+//  GPU internal polygon drawing functions
+///////////////////////////////////////////////////////////////////////////////
+
+/*----------------------------------------------------------------------
+gpuDrawPolyF - Flat-shaded, untextured poly
+----------------------------------------------------------------------*/
+void gpuDrawPolyF(const PtrUnion packet, const PP gpuPolySpanDriver, u32 is_quad)
+{
+	// Set up bgr555 color to be used across calls in inner driver
+	gpu_unai.PixelData = GPU_RGB16(packet.U4[0]);
+
+	PolyVertex vbuf[4];
+	polyInitVertexBuffer(vbuf, packet, POLYTYPE_F, is_quad);
+
+	int total_passes = is_quad ? 2 : 1;
+	int cur_pass = 0;
+	do
 	{
-		if (loop0 == 2)
-		{
-			ya = y0;
-			yb = y1;
-			x3 = i2x(x0);
-			x4 = y0!=y1 ? x3 : i2x(x1);
-			if (dx < 0)
-			{
-				dx3 = xLoDivx((x2 - x0), (y2 - y0));
-				dx4 = xLoDivx((x1 - x0), (y1 - y0));
-			}
-			else
-			{
-				dx3 = xLoDivx((x1 - x0), (y1 - y0));
-				dx4 = xLoDivx((x2 - x0), (y2 - y0));
+		const PolyVertex* vptrs[3];
+		if (polyUseTriangle(vbuf, cur_pass, vptrs) == false)
+			continue;
+
+		s32 xa, xb, ya, yb;
+		s32 x3, dx3, x4, dx4, dx;
+		s32 x0, x1, x2, y0, y1, y2;
+
+		x0 = vptrs[0]->x;  y0 = vptrs[0]->y;
+		x1 = vptrs[1]->x;  y1 = vptrs[1]->y;
+		x2 = vptrs[2]->x;  y2 = vptrs[2]->y;
+
+		ya = y2 - y0;
+		yb = y2 - y1;
+		dx = (x2 - x1) * ya - (x2 - x0) * yb;
+
+		for (int loop0 = 2; loop0; loop0--) {
+			if (loop0 == 2) {
+				ya = y0;  yb = y1;
+				x3 = x4 = i2x(x0);
+				if (dx < 0) {
+#ifdef GPU_UNAI_USE_FLOATMATH
+#ifdef GPU_UNAI_USE_FLOAT_DIV_MULTINV
+					dx3 = ((y2 - y0) != 0) ? (fixed)(((x2 - x0) << FIXED_BITS) * FloatInv(y2 - y0)) : 0;
+					dx4 = ((y1 - y0) != 0) ? (fixed)(((x1 - x0) << FIXED_BITS) * FloatInv(y1 - y0)) : 0;
+#else
+					dx3 = ((y2 - y0) != 0) ? (fixed)(((x2 - x0) << FIXED_BITS) / (float)(y2 - y0)) : 0;
+					dx4 = ((y1 - y0) != 0) ? (fixed)(((x1 - x0) << FIXED_BITS) / (float)(y1 - y0)) : 0;
+#endif
+#else  // Integer Division:
+#ifdef GPU_UNAI_USE_INT_DIV_MULTINV
+					dx3 = ((y2 - y0) != 0) ? xLoDivx((x2 - x0), (y2 - y0)) : 0;
+					dx4 = ((y1 - y0) != 0) ? xLoDivx((x1 - x0), (y1 - y0)) : 0;
+#else
+					dx3 = ((y2 - y0) != 0) ? GPU_FAST_DIV((x2 - x0) << FIXED_BITS, (y2 - y0)) : 0;
+					dx4 = ((y1 - y0) != 0) ? GPU_FAST_DIV((x1 - x0) << FIXED_BITS, (y1 - y0)) : 0;
+#endif
+#endif
+				} else {
+#ifdef GPU_UNAI_USE_FLOATMATH
+#ifdef GPU_UNAI_USE_FLOAT_DIV_MULTINV
+					dx3 = ((y1 - y0) != 0) ? (fixed)(((x1 - x0) << FIXED_BITS) * FloatInv(y1 - y0)) : 0;
+					dx4 = ((y2 - y0) != 0) ? (fixed)(((x2 - x0) << FIXED_BITS) * FloatInv(y2 - y0)) : 0;
+#else
+					dx3 = ((y1 - y0) != 0) ? (fixed)(((x1 - x0) << FIXED_BITS) / (float)(y1 - y0)) : 0;
+					dx4 = ((y2 - y0) != 0) ? (fixed)(((x2 - x0) << FIXED_BITS) / (float)(y2 - y0)) : 0;
+#endif
+#else  // Integer Division:
+#ifdef GPU_UNAI_USE_INT_DIV_MULTINV
+					dx3 = ((y1 - y0) != 0) ? xLoDivx((x1 - x0), (y1 - y0)) : 0;
+					dx4 = ((y2 - y0) != 0) ? xLoDivx((x2 - x0), (y2 - y0)) : 0;
+#else
+					dx3 = ((y1 - y0) != 0) ? GPU_FAST_DIV((x1 - x0) << FIXED_BITS, (y1 - y0)) : 0;
+					dx4 = ((y2 - y0) != 0) ? GPU_FAST_DIV((x2 - x0) << FIXED_BITS, (y2 - y0)) : 0;
+#endif
+#endif
+				}
+			} else {
+				//senquack - break out of final loop if nothing to be drawn (1st loop
+				//           must always be taken to setup dx3/dx4)
+				if (y1 == y2) break;
+
+				ya = y1;  yb = y2;
+
+				if (dx < 0) {
+					x3 = i2x(x0) + (dx3 * (y1 - y0));
+					x4 = i2x(x1);
+#ifdef GPU_UNAI_USE_FLOATMATH
+#ifdef GPU_UNAI_USE_FLOAT_DIV_MULTINV
+					dx4 = ((y2 - y1) != 0) ? (fixed)(((x2 - x1) << FIXED_BITS) * FloatInv(y2 - y1)) : 0;
+#else
+					dx4 = ((y2 - y1) != 0) ? (fixed)(((x2 - x1) << FIXED_BITS) / (float)(y2 - y1)) : 0;
+#endif
+#else  // Integer Division:
+#ifdef GPU_UNAI_USE_INT_DIV_MULTINV
+					dx4 = ((y2 - y1) != 0) ? xLoDivx ((x2 - x1), (y2 - y1)) : 0;
+#else
+					dx4 = ((y2 - y1) != 0) ? GPU_FAST_DIV((x2 - x1) << FIXED_BITS, (y2 - y1)) : 0;
+#endif
+#endif
+				} else {
+					x3 = i2x(x1);
+					x4 = i2x(x0) + (dx4 * (y1 - y0));
+#ifdef GPU_UNAI_USE_FLOATMATH
+#ifdef GPU_UNAI_USE_FLOAT_DIV_MULTINV
+					dx3 = ((y2 - y1) != 0) ? (fixed)(((x2 - x1) << FIXED_BITS) * FloatInv(y2 - y1)) : 0;
+#else
+					dx3 = ((y2 - y1) != 0) ? (fixed)(((x2 - x1) << FIXED_BITS) / (float)(y2 - y1)) : 0;
+#endif
+#else  // Integer Division:
+#ifdef GPU_UNAI_USE_INT_DIV_MULTINV
+					dx3 = ((y2 - y1) != 0) ? xLoDivx ((x2 - x1), (y2 - y1)) : 0;
+#else
+					dx3 = ((y2 - y1) != 0) ? GPU_FAST_DIV((x2 - x1) << FIXED_BITS, (y2 - y1)) : 0;
+#endif
+#endif
+				}
 			}
-		}
-		else
-		{
-			ya = y1;
-			yb = y2;
-			if (dx < 0)
-			{
-				x4  = i2x(x1);
-				x3  = i2x(x0) + (dx3 * (y1 - y0));
-				dx4 = xLoDivx((x2 - x1), (y2 - y1));
+
+			s32 xmin, xmax, ymin, ymax;
+			xmin = gpu_unai.DrawingArea[0];  xmax = gpu_unai.DrawingArea[2];
+			ymin = gpu_unai.DrawingArea[1];  ymax = gpu_unai.DrawingArea[3];
+
+			if ((ymin - ya) > 0) {
+				x3 += (dx3 * (ymin - ya));
+				x4 += (dx4 * (ymin - ya));
+				ya = ymin;
 			}
-			else
+
+			if (yb > ymax) yb = ymax;
+
+			int loop1 = yb - ya;
+			if (loop1 <= 0)
+				continue;
+
+			u16* PixelBase = &((u16*)gpu_unai.vram)[FRAME_OFFSET(0, ya)];
+			int li=gpu_unai.ilace_mask;
+			int pi=(ProgressiveInterlaceEnabled()?(gpu_unai.ilace_mask+1):0);
+			int pif=(ProgressiveInterlaceEnabled()?(gpu_unai.prog_ilace_flag?(gpu_unai.ilace_mask+1):0):1);
+
+			for (; loop1; --loop1, ya++, PixelBase += FRAME_WIDTH,
+					x3 += dx3, x4 += dx4 )
 			{
-				x3  = i2x(x1);
-				x4  = i2x(x0) + (dx4 * (y1 - y0));
-				dx3 = xLoDivx((x2 - x1), (y2 - y1));
+				if (ya&li) continue;
+				if ((ya&pi)==pif) continue;
+
+				xa = FixedCeilToInt(x3);  xb = FixedCeilToInt(x4);
+				if ((xmin - xa) > 0) xa = xmin;
+				if (xb > xmax) xb = xmax;
+				if ((xb - xa) > 0)
+					gpuPolySpanDriver(gpu_unai, PixelBase + xa, (xb - xa));
 			}
 		}
-
-		temp = ymin - ya;
-		if (temp > 0)
-		{
-			ya  = ymin;
-			x3 += dx3*temp;
-			x4 += dx4*temp;
-		}
-		if (yb > ymax) yb = ymax;
-		if (ya>=yb) continue;
-
-		x3+= fixed_HALF;
-		x4+= fixed_HALF;
-
-		u16* PixelBase  = &((u16*)GPU_FrameBuffer)[FRAME_OFFSET(0, ya)];
-		
-		for(;ya<yb;++ya, PixelBase += FRAME_WIDTH, x3+=dx3, x4+=dx4)
-		{
-			if (ya&li) continue;
-			xa = x2i(x3);
-			xb = x2i(x4);
-			if( (xa>xmax) || (xb<xmin) ) continue;
-			if(xa < xmin) xa = xmin;
-			if(xb > xmax) xb = xmax;
-			xb-=xa;
-			if(xb>0) gpuPolySpanDriver(PixelBase + xa,xb);
-		}
-	}
+	} while (++cur_pass < total_passes);
 }
 
 /*----------------------------------------------------------------------
-FT3
+gpuDrawPolyFT - Flat-shaded, textured poly
 ----------------------------------------------------------------------*/
-
-void gpuDrawFT3(const PP gpuPolySpanDriver)
+void gpuDrawPolyFT(const PtrUnion packet, const PP gpuPolySpanDriver, u32 is_quad)
 {
-	const int li=linesInterlace;
-	s32 temp;
-	s32 xa, xb, xmin, xmax;
-	s32 ya, yb, ymin, ymax;
-	s32 x0, x1, x2, x3, dx3=0, x4, dx4=0, dx;
-	s32 y0, y1, y2;
-	s32 u0, u1, u2, u3, du3=0;
-	s32 v0, v1, v2, v3, dv3=0;
-
-	x0 = GPU_EXPANDSIGN(PacketBuffer.S2[2] );
-	y0 = GPU_EXPANDSIGN(PacketBuffer.S2[3] );
-	x1 = GPU_EXPANDSIGN(PacketBuffer.S2[6] );
-	y1 = GPU_EXPANDSIGN(PacketBuffer.S2[7] );
-	x2 = GPU_EXPANDSIGN(PacketBuffer.S2[10]);
-	y2 = GPU_EXPANDSIGN(PacketBuffer.S2[11]);
-
-	GPU_TESTRANGE3();
-
-	x0 += DrawingOffset[0];   x1 += DrawingOffset[0];   x2 += DrawingOffset[0];
-	y0 += DrawingOffset[1];   y1 += DrawingOffset[1];   y2 += DrawingOffset[1];
-
-	xmin = DrawingArea[0];  xmax = DrawingArea[2];
-	ymin = DrawingArea[1];  ymax = DrawingArea[3];
-
+	// r8/g8/b8 used if texture-blending & dithering is applied (24-bit light)
+	gpu_unai.r8 = packet.U1[0];
+	gpu_unai.g8 = packet.U1[1];
+	gpu_unai.b8 = packet.U1[2];
+	// r5/g5/b5 used if just texture-blending is applied (15-bit light)
+	gpu_unai.r5 = packet.U1[0] >> 3;
+	gpu_unai.g5 = packet.U1[1] >> 3;
+	gpu_unai.b5 = packet.U1[2] >> 3;
+
+	PolyVertex vbuf[4];
+	polyInitVertexBuffer(vbuf, packet, POLYTYPE_FT, is_quad);
+
+	int total_passes = is_quad ? 2 : 1;
+	int cur_pass = 0;
+	do
 	{
-		int rx0 = Max2(xmin,Min3(x0,x1,x2));
-		int ry0 = Max2(ymin,Min3(y0,y1,y2));
-		int rx1 = Min2(xmax,Max3(x0,x1,x2));
-		int ry1 = Min2(ymax,Max3(y0,y1,y2));
-		if( rx0>=rx1 || ry0>=ry1) return;
-	}
-	
-	u0 = PacketBuffer.U1[8];  v0 = PacketBuffer.U1[9];
-	u1 = PacketBuffer.U1[16]; v1 = PacketBuffer.U1[17];
-	u2 = PacketBuffer.U1[24]; v2 = PacketBuffer.U1[25];
-
-	r4 = s32(PacketBuffer.U1[0]);
-	g4 = s32(PacketBuffer.U1[1]);
-	b4 = s32(PacketBuffer.U1[2]);
-	dr4 = dg4 = db4 = 0;
+		const PolyVertex* vptrs[3];
+		if (polyUseTriangle(vbuf, cur_pass, vptrs) == false)
+			continue;
+
+		s32 xa, xb, ya, yb;
+		s32 x3, dx3, x4, dx4, dx;
+		s32 u3, du3, v3, dv3;
+		s32 x0, x1, x2, y0, y1, y2;
+		s32 u0, u1, u2, v0, v1, v2;
+		s32 du4, dv4;
+
+		x0 = vptrs[0]->x;      y0 = vptrs[0]->y;
+		u0 = vptrs[0]->tex.u;  v0 = vptrs[0]->tex.v;
+		x1 = vptrs[1]->x;      y1 = vptrs[1]->y;
+		u1 = vptrs[1]->tex.u;  v1 = vptrs[1]->tex.v;
+		x2 = vptrs[2]->x;      y2 = vptrs[2]->y;
+		u2 = vptrs[2]->tex.u;  v2 = vptrs[2]->tex.v;
+
+		ya = y2 - y0;
+		yb = y2 - y1;
+		dx4 = (x2 - x1) * ya - (x2 - x0) * yb;
+		du4 = (u2 - u1) * ya - (u2 - u0) * yb;
+		dv4 = (v2 - v1) * ya - (v2 - v0) * yb;
+		dx = dx4;
+		if (dx4 < 0) {
+			dx4 = -dx4;
+			du4 = -du4;
+			dv4 = -dv4;
+		}
 
-	if (y0 >= y1)
-	{
-		if( y0!=y1 || x0>x1 )
-		{
-			GPU_SWAP(x0, x1, temp);
-			GPU_SWAP(y0, y1, temp);
-			GPU_SWAP(u0, u1, temp);
-			GPU_SWAP(v0, v1, temp);
+#ifdef GPU_UNAI_USE_FLOATMATH
+#ifdef GPU_UNAI_USE_FLOAT_DIV_MULTINV
+		if (dx4 != 0) {
+			float finv = FloatInv(dx4);
+			du4 = (fixed)((du4 << FIXED_BITS) * finv);
+			dv4 = (fixed)((dv4 << FIXED_BITS) * finv);
+		} else {
+			du4 = dv4 = 0;
 		}
-	}
-	if (y1 >= y2)
-	{
-		if( y1!=y2 || x1>x2 )
-		{
-			GPU_SWAP(x1, x2, temp);
-			GPU_SWAP(y1, y2, temp);
-			GPU_SWAP(u1, u2, temp);
-			GPU_SWAP(v1, v2, temp);
+#else
+		if (dx4 != 0) {
+			float fdiv = dx4;
+			du4 = (fixed)((du4 << FIXED_BITS) / fdiv);
+			dv4 = (fixed)((dv4 << FIXED_BITS) / fdiv);
+		} else {
+			du4 = dv4 = 0;
 		}
-	}
-	if (y0 >= y1)
-	{
-		if( y0!=y1 || x0>x1 )
-		{
-			GPU_SWAP(x0, x1, temp);
-			GPU_SWAP(y0, y1, temp);
-			GPU_SWAP(u0, u1, temp);
-			GPU_SWAP(v0, v1, temp);
+#endif
+#else  // Integer Division:
+#ifdef GPU_UNAI_USE_INT_DIV_MULTINV
+		if (dx4 != 0) {
+			int iF, iS;
+			xInv(dx4, iF, iS);
+			du4 = xInvMulx(du4, iF, iS);
+			dv4 = xInvMulx(dv4, iF, iS);
+		} else {
+			du4 = dv4 = 0;
 		}
-	}
-
-	ya  = y2 - y0;
-	yb  = y2 - y1;
-	dx  = (x2 - x1) * ya - (x2 - x0) * yb;
-	du4 = (u2 - u1) * ya - (u2 - u0) * yb;
-	dv4 = (v2 - v1) * ya - (v2 - v0) * yb;
+#else
+		if (dx4 != 0) {
+			du4 = GPU_FAST_DIV(du4 << FIXED_BITS, dx4);
+			dv4 = GPU_FAST_DIV(dv4 << FIXED_BITS, dx4);
+		} else {
+			du4 = dv4 = 0;
+		}
+#endif
+#endif
+		// Set u,v increments for inner driver
+		gpu_unai.u_inc = du4;
+		gpu_unai.v_inc = dv4;
+
+		//senquack - TODO: why is it always going through 2 iterations when sometimes one would suffice here?
+		//			 (SAME ISSUE ELSEWHERE)
+		for (s32 loop0 = 2; loop0; loop0--) {
+			if (loop0 == 2) {
+				ya = y0;  yb = y1;
+				x3 = x4 = i2x(x0);
+				u3 = i2x(u0);  v3 = i2x(v0);
+				if (dx < 0) {
+#ifdef GPU_UNAI_USE_FLOATMATH
+#ifdef GPU_UNAI_USE_FLOAT_DIV_MULTINV
+					if ((y2 - y0) != 0) {
+						float finv = FloatInv(y2 - y0);
+						dx3 = (fixed)(((x2 - x0) << FIXED_BITS) * finv);
+						du3 = (fixed)(((u2 - u0) << FIXED_BITS) * finv);
+						dv3 = (fixed)(((v2 - v0) << FIXED_BITS) * finv);
+					} else {
+						dx3 = du3 = dv3 = 0;
+					}
+					dx4 = ((y1 - y0) != 0) ? (fixed)(((x1 - x0) << FIXED_BITS) * FloatInv(y1 - y0)) : 0;
+#else
+					if ((y2 - y0) != 0) {
+						float fdiv = y2 - y0;
+						dx3 = (fixed)(((x2 - x0) << FIXED_BITS) / fdiv);
+						du3 = (fixed)(((u2 - u0) << FIXED_BITS) / fdiv);
+						dv3 = (fixed)(((v2 - v0) << FIXED_BITS) / fdiv);
+					} else {
+						dx3 = du3 = dv3 = 0;
+					}
+					dx4 = ((y1 - y0) != 0) ? (fixed)(((x1 - x0) << FIXED_BITS) / (float)(y1 - y0)) : 0;
+#endif
+#else  // Integer Division:
+#ifdef GPU_UNAI_USE_INT_DIV_MULTINV
+					if ((y2 - y0) != 0) {
+						int iF, iS;
+						xInv((y2 - y0), iF, iS);
+						dx3 = xInvMulx((x2 - x0), iF, iS);
+						du3 = xInvMulx((u2 - u0), iF, iS);
+						dv3 = xInvMulx((v2 - v0), iF, iS);
+					} else {
+						dx3 = du3 = dv3 = 0;
+					}
+					dx4 = ((y1 - y0) != 0) ? xLoDivx((x1 - x0), (y1 - y0)) : 0;
+#else
+					if ((y2 - y0) != 0) {
+						dx3 = GPU_FAST_DIV((x2 - x0) << FIXED_BITS, (y2 - y0));
+						du3 = GPU_FAST_DIV((u2 - u0) << FIXED_BITS, (y2 - y0));
+						dv3 = GPU_FAST_DIV((v2 - v0) << FIXED_BITS, (y2 - y0));
+					} else {
+						dx3 = du3 = dv3 = 0;
+					}
+					dx4 = ((y1 - y0) != 0) ? GPU_FAST_DIV((x1 - x0) << FIXED_BITS, (y1 - y0)) : 0;
+#endif
+#endif
+				} else {
+#ifdef GPU_UNAI_USE_FLOATMATH
+#ifdef GPU_UNAI_USE_FLOAT_DIV_MULTINV
+					if ((y1 - y0) != 0) {
+						float finv = FloatInv(y1 - y0);
+						dx3 = (fixed)(((x1 - x0) << FIXED_BITS) * finv);
+						du3 = (fixed)(((u1 - u0) << FIXED_BITS) * finv);
+						dv3 = (fixed)(((v1 - v0) << FIXED_BITS) * finv);
+					} else {
+						dx3 = du3 = dv3 = 0;
+					}
+					dx4 = ((y2 - y0) != 0) ? (fixed)(((x2 - x0) << FIXED_BITS) * FloatInv(y2 - y0)) : 0;
+#else
+					if ((y1 - y0) != 0) {
+						float fdiv = y1 - y0;
+						dx3 = (fixed)(((x1 - x0) << FIXED_BITS) / fdiv);
+						du3 = (fixed)(((u1 - u0) << FIXED_BITS) / fdiv);
+						dv3 = (fixed)(((v1 - v0) << FIXED_BITS) / fdiv);
+					} else {
+						dx3 = du3 = dv3 = 0;
+					}
+					dx4 = ((y2 - y0) != 0) ? (fixed)(((x2 - x0) << FIXED_BITS) / (float)(y2 - y0)) : 0;
+#endif
+#else  // Integer Division:
+#ifdef GPU_UNAI_USE_INT_DIV_MULTINV
+					if ((y1 - y0) != 0) {
+						int iF, iS;
+						xInv((y1 - y0), iF, iS);
+						dx3 = xInvMulx((x1 - x0), iF, iS);
+						du3 = xInvMulx((u1 - u0), iF, iS);
+						dv3 = xInvMulx((v1 - v0), iF, iS);
+					} else {
+						dx3 = du3 = dv3 = 0;
+					}
+					dx4 = ((y2 - y0) != 0) ? xLoDivx((x2 - x0), (y2 - y0)) : 0;
+#else
+					if ((y1 - y0) != 0) {
+						dx3 = GPU_FAST_DIV((x1 - x0) << FIXED_BITS, (y1 - y0));
+						du3 = GPU_FAST_DIV((u1 - u0) << FIXED_BITS, (y1 - y0));
+						dv3 = GPU_FAST_DIV((v1 - v0) << FIXED_BITS, (y1 - y0));
+					} else {
+						dx3 = du3 = dv3 = 0;
+					}
+					dx4 = ((y2 - y0) != 0) ? GPU_FAST_DIV((x2 - x0) << FIXED_BITS, (y2 - y0)) : 0;
+#endif
+#endif
+				}
+			} else {
+				//senquack - break out of final loop if nothing to be drawn (1st loop
+				//           must always be taken to setup dx3/dx4)
+				if (y1 == y2) break;
+
+				ya = y1;  yb = y2;
+
+				if (dx < 0) {
+					x3 = i2x(x0);
+					x4 = i2x(x1);
+					u3 = i2x(u0);
+					v3 = i2x(v0);
+					if ((y1 - y0) != 0) {
+						x3 += (dx3 * (y1 - y0));
+						u3 += (du3 * (y1 - y0));
+						v3 += (dv3 * (y1 - y0));
+					}
+#ifdef GPU_UNAI_USE_FLOATMATH
+#ifdef GPU_UNAI_USE_FLOAT_DIV_MULTINV
+					dx4 = ((y2 - y1) != 0) ? (fixed)(((x2 - x1) << FIXED_BITS) * FloatInv(y2 - y1)) : 0;
+#else
+					dx4 = ((y2 - y1) != 0) ? (fixed)(((x2 - x1) << FIXED_BITS) / (float)(y2 - y1)) : 0;
+#endif
+#else  // Integer Division:
+#ifdef GPU_UNAI_USE_INT_DIV_MULTINV
+					dx4 = ((y2 - y1) != 0) ? xLoDivx((x2 - x1), (y2 - y1)) : 0;
+#else
+					dx4 = ((y2 - y1) != 0) ? GPU_FAST_DIV((x2 - x1) << FIXED_BITS, (y2 - y1)) : 0;
+#endif
+#endif
+				} else {
+					x3 = i2x(x1);
+					x4 = i2x(x0) + (dx4 * (y1 - y0));
+					u3 = i2x(u1);
+					v3 = i2x(v1);
+#ifdef GPU_UNAI_USE_FLOATMATH
+#ifdef GPU_UNAI_USE_FLOAT_DIV_MULTINV
+					if ((y2 - y1) != 0) {
+						float finv = FloatInv(y2 - y1);
+						dx3 = (fixed)(((x2 - x1) << FIXED_BITS) * finv);
+						du3 = (fixed)(((u2 - u1) << FIXED_BITS) * finv);
+						dv3 = (fixed)(((v2 - v1) << FIXED_BITS) * finv);
+					} else {
+						dx3 = du3 = dv3 = 0;
+					}
+#else
+					if ((y2 - y1) != 0) {
+						float fdiv = y2 - y1;
+						dx3 = (fixed)(((x2 - x1) << FIXED_BITS) / fdiv);
+						du3 = (fixed)(((u2 - u1) << FIXED_BITS) / fdiv);
+						dv3 = (fixed)(((v2 - v1) << FIXED_BITS) / fdiv);
+					} else {
+						dx3 = du3 = dv3 = 0;
+					}
+#endif
+#else  // Integer Division:
+#ifdef GPU_UNAI_USE_INT_DIV_MULTINV
+					if ((y2 - y1) != 0) {
+						int iF, iS;
+						xInv((y2 - y1), iF, iS);
+						dx3 = xInvMulx((x2 - x1), iF, iS);
+						du3 = xInvMulx((u2 - u1), iF, iS);
+						dv3 = xInvMulx((v2 - v1), iF, iS);
+					} else {
+						dx3 = du3 = dv3 = 0;
+					}
+#else 
+					if ((y2 - y1) != 0) {
+						dx3 = GPU_FAST_DIV((x2 - x1) << FIXED_BITS, (y2 - y1));
+						du3 = GPU_FAST_DIV((u2 - u1) << FIXED_BITS, (y2 - y1));
+						dv3 = GPU_FAST_DIV((v2 - v1) << FIXED_BITS, (y2 - y1));
+					} else {
+						dx3 = du3 = dv3 = 0;
+					}
+#endif
+#endif
+				}
+			}
 
-	s32 iF,iS;
-	xInv( dx, iF, iS);
-	du4 = xInvMulx( du4, iF, iS);
-	dv4 = xInvMulx( dv4, iF, iS);
-	tInc = ((u32)(du4<<7)&0x7fff0000) | ((u32)(dv4>>9)&0x00007fff);
-	tMsk = (TextureWindow[2]<<23) | (TextureWindow[3]<<7) | 0x00ff00ff;
+			s32 xmin, xmax, ymin, ymax;
+			xmin = gpu_unai.DrawingArea[0];  xmax = gpu_unai.DrawingArea[2];
+			ymin = gpu_unai.DrawingArea[1];  ymax = gpu_unai.DrawingArea[3];
 
-	for (s32 loop0 = 2; loop0; --loop0)
-	{
-		if (loop0 == 2)
-		{
-			ya = y0;
-			yb = y1;
-			u3 = i2x(u0);
-			v3 = i2x(v0);
-			x3 = i2x(x0);
-			x4 = y0!=y1 ? x3 : i2x(x1);
-			if (dx < 0)
-			{
-				xInv( (y2 - y0), iF, iS);
-				dx3 = xInvMulx( (x2 - x0), iF, iS);
-				du3 = xInvMulx( (u2 - u0), iF, iS);
-				dv3 = xInvMulx( (v2 - v0), iF, iS);
-				dx4 = xLoDivx ( (x1 - x0), (y1 - y0));
-			}
-			else
-			{
-				xInv( (y1 - y0), iF, iS);
-				dx3 = xInvMulx( (x1 - x0), iF, iS);
-				du3 = xInvMulx( (u1 - u0), iF, iS);
-				dv3 = xInvMulx( (v1 - v0), iF, iS);
-				dx4 = xLoDivx ( (x2 - x0), (y2 - y0));
+			if ((ymin - ya) > 0) {
+				x3 += dx3 * (ymin - ya);
+				x4 += dx4 * (ymin - ya);
+				u3 += du3 * (ymin - ya);
+				v3 += dv3 * (ymin - ya);
+				ya = ymin;
 			}
-		}
-		else
-		{
-			ya = y1;
-			yb = y2;
-			if (dx < 0)
-			{
-				temp = y1 - y0;
-				u3 = i2x(u0) + (du3 * temp);
-				v3 = i2x(v0) + (dv3 * temp);
-				x3 = i2x(x0) + (dx3 * temp);
-				x4 = i2x(x1);
-				dx4 = xLoDivx((x2 - x1), (y2 - y1));
-			}
-			else
+
+			if (yb > ymax) yb = ymax;
+
+			int loop1 = yb - ya;
+			if (loop1 <= 0)
+				continue;
+
+			u16* PixelBase = &((u16*)gpu_unai.vram)[FRAME_OFFSET(0, ya)];
+			int li=gpu_unai.ilace_mask;
+			int pi=(ProgressiveInterlaceEnabled()?(gpu_unai.ilace_mask+1):0);
+			int pif=(ProgressiveInterlaceEnabled()?(gpu_unai.prog_ilace_flag?(gpu_unai.ilace_mask+1):0):1);
+
+			for (; loop1; --loop1, ++ya, PixelBase += FRAME_WIDTH,
+					x3 += dx3, x4 += dx4,
+					u3 += du3, v3 += dv3 )
 			{
-				u3 = i2x(u1);
-				v3 = i2x(v1);
-				x3 = i2x(x1);
-				x4 = i2x(x0) + (dx4 * (y1 - y0));
-				xInv( (y2 - y1), iF, iS);
-				dx3 = xInvMulx( (x2 - x1), iF, iS);
-				du3 = xInvMulx( (u2 - u1), iF, iS);
-				dv3 = xInvMulx( (v2 - v1), iF, iS);
-			}
-		}
+				if (ya&li) continue;
+				if ((ya&pi)==pif) continue;
 
-		temp = ymin - ya;
-		if (temp > 0)
-		{
-			ya  = ymin;
-			x3 += dx3*temp;
-			x4 += dx4*temp;
-			u3 += du3*temp;
-			v3 += dv3*temp;
-		}
-		if (yb > ymax) yb = ymax;
-		if (ya>=yb) continue;
+				u32 u4, v4;
 
-		x3+= fixed_HALF;
-		x4+= fixed_HALF;
-		u3+= fixed_HALF;
-		v4+= fixed_HALF;
+				xa = FixedCeilToInt(x3);  xb = FixedCeilToInt(x4);
+				u4 = u3;  v4 = v3;
 
-		u16* PixelBase  = &((u16*)GPU_FrameBuffer)[FRAME_OFFSET(0, ya)];
+				fixed itmp = i2x(xa) - x3;
+				if (itmp != 0) {
+					u4 += (du4 * itmp) >> FIXED_BITS;
+					v4 += (dv4 * itmp) >> FIXED_BITS;
+				}
 
-		for(;ya<yb;++ya, PixelBase += FRAME_WIDTH, x3+=dx3, x4+=dx4, u3+=du3, v3+=dv3)
-		{
-			if (ya&li) continue;
-			xa = x2i(x3);
-			xb = x2i(x4);
-			if( (xa>xmax) || (xb<xmin) ) continue;
+				u4 += fixed_HALF;
+				v4 += fixed_HALF;
 
-			temp = xmin - xa;
-			if(temp > 0)
-			{
-				xa  = xmin;
-				u4 = u3 + du4*temp;
-				v4 = v3 + dv4*temp;
-			}
-			else
-			{
-				u4 = u3;
-				v4 = v3;
+				if ((xmin - xa) > 0) {
+					u4 += du4 * (xmin - xa);
+					v4 += dv4 * (xmin - xa);
+					xa = xmin;
+				}
+
+				// Set u,v coords for inner driver
+				gpu_unai.u = u4;
+				gpu_unai.v = v4;
+
+				if (xb > xmax) xb = xmax;
+				if ((xb - xa) > 0)
+					gpuPolySpanDriver(gpu_unai, PixelBase + xa, (xb - xa));
 			}
-			if(xb > xmax) xb = xmax;
-			xb-=xa;
-			if(xb>0) gpuPolySpanDriver(PixelBase + xa,xb);
 		}
-	}
+	} while (++cur_pass < total_passes);
 }
 
 /*----------------------------------------------------------------------
-G3
+gpuDrawPolyG - Gouraud-shaded, untextured poly
 ----------------------------------------------------------------------*/
-
-void gpuDrawG3(const PP gpuPolySpanDriver)
+void gpuDrawPolyG(const PtrUnion packet, const PP gpuPolySpanDriver, u32 is_quad)
 {
-	const int li=linesInterlace;
-	s32 temp;
-	s32 xa, xb, xmin, xmax;
-	s32 ya, yb, ymin, ymax;
-	s32 x0, x1, x2, x3, dx3=0, x4, dx4=0, dx;
-	s32 y0, y1, y2;
-	s32 r0, r1, r2, r3, dr3=0;
-	s32 g0, g1, g2, g3, dg3=0;
-	s32 b0, b1, b2, b3, db3=0;
-
-	x0 = GPU_EXPANDSIGN(PacketBuffer.S2[2] );
-	y0 = GPU_EXPANDSIGN(PacketBuffer.S2[3] );
-	x1 = GPU_EXPANDSIGN(PacketBuffer.S2[6] );
-	y1 = GPU_EXPANDSIGN(PacketBuffer.S2[7] );
-	x2 = GPU_EXPANDSIGN(PacketBuffer.S2[10]);
-	y2 = GPU_EXPANDSIGN(PacketBuffer.S2[11]);
-
-	GPU_TESTRANGE3();
-
-	x0 += DrawingOffset[0];   x1 += DrawingOffset[0];   x2 += DrawingOffset[0];
-	y0 += DrawingOffset[1];   y1 += DrawingOffset[1];   y2 += DrawingOffset[1];
-
-	xmin = DrawingArea[0];  xmax = DrawingArea[2];
-	ymin = DrawingArea[1];  ymax = DrawingArea[3];
+	PolyVertex vbuf[4];
+	polyInitVertexBuffer(vbuf, packet, POLYTYPE_G, is_quad);
 
+	int total_passes = is_quad ? 2 : 1;
+	int cur_pass = 0;
+	do
 	{
-		int rx0 = Max2(xmin,Min3(x0,x1,x2));
-		int ry0 = Max2(ymin,Min3(y0,y1,y2));
-		int rx1 = Min2(xmax,Max3(x0,x1,x2));
-		int ry1 = Min2(ymax,Max3(y0,y1,y2));
-		if( rx0>=rx1 || ry0>=ry1) return;
-	}
-	
-	r0 = PacketBuffer.U1[0];	g0 = PacketBuffer.U1[1];	b0 = PacketBuffer.U1[2];
-	r1 = PacketBuffer.U1[8];	g1 = PacketBuffer.U1[9];	b1 = PacketBuffer.U1[10];
-	r2 = PacketBuffer.U1[16];	g2 = PacketBuffer.U1[17];	b2 = PacketBuffer.U1[18];
+		const PolyVertex* vptrs[3];
+		if (polyUseTriangle(vbuf, cur_pass, vptrs) == false)
+			continue;
+
+		s32 xa, xb, ya, yb;
+		s32 x3, dx3, x4, dx4, dx;
+		s32 r3, dr3, g3, dg3, b3, db3;
+		s32 x0, x1, x2, y0, y1, y2;
+		s32 r0, r1, r2, g0, g1, g2, b0, b1, b2;
+		s32 dr4, dg4, db4;
+
+		x0 = vptrs[0]->x;      y0 = vptrs[0]->y;
+		r0 = vptrs[0]->col.r;  g0 = vptrs[0]->col.g;  b0 = vptrs[0]->col.b;
+		x1 = vptrs[1]->x;      y1 = vptrs[1]->y;
+		r1 = vptrs[1]->col.r;  g1 = vptrs[1]->col.g;  b1 = vptrs[1]->col.b;
+		x2 = vptrs[2]->x;      y2 = vptrs[2]->y;
+		r2 = vptrs[2]->col.r;  g2 = vptrs[2]->col.g;  b2 = vptrs[2]->col.b;
+
+		ya = y2 - y0;
+		yb = y2 - y1;
+		dx4 = (x2 - x1) * ya - (x2 - x0) * yb;
+		dr4 = (r2 - r1) * ya - (r2 - r0) * yb;
+		dg4 = (g2 - g1) * ya - (g2 - g0) * yb;
+		db4 = (b2 - b1) * ya - (b2 - b0) * yb;
+		dx = dx4;
+		if (dx4 < 0) {
+			dx4 = -dx4;
+			dr4 = -dr4;
+			dg4 = -dg4;
+			db4 = -db4;
+		}
 
-	if (y0 >= y1)
-	{
-		if( y0!=y1 || x0>x1 )
-		{
-			GPU_SWAP(x0, x1, temp);		GPU_SWAP(y0, y1, temp);
-			GPU_SWAP(r0, r1, temp);		GPU_SWAP(g0, g1, temp);		GPU_SWAP(b0, b1, temp);
+#ifdef GPU_UNAI_USE_FLOATMATH
+#ifdef GPU_UNAI_USE_FLOAT_DIV_MULTINV
+		if (dx4 != 0) {
+			float finv = FloatInv(dx4);
+			dr4 = (fixed)((dr4 << FIXED_BITS) * finv);
+			dg4 = (fixed)((dg4 << FIXED_BITS) * finv);
+			db4 = (fixed)((db4 << FIXED_BITS) * finv);
+		} else {
+			dr4 = dg4 = db4 = 0;
 		}
-	}
-	if (y1 >= y2)
-	{
-		if( y1!=y2 || x1>x2 )
-		{
-			GPU_SWAP(x1, x2, temp);		GPU_SWAP(y1, y2, temp);
-			GPU_SWAP(r1, r2, temp);		GPU_SWAP(g1, g2, temp);   GPU_SWAP(b1, b2, temp);
+#else
+		if (dx4 != 0) {
+			float fdiv = dx4;
+			dr4 = (fixed)((dr4 << FIXED_BITS) / fdiv);
+			dg4 = (fixed)((dg4 << FIXED_BITS) / fdiv);
+			db4 = (fixed)((db4 << FIXED_BITS) / fdiv);
+		} else {
+			dr4 = dg4 = db4 = 0;
 		}
-	}
-	if (y0 >= y1)
-	{
-		if( y0!=y1 || x0>x1 )
-		{
-			GPU_SWAP(x0, x1, temp);		GPU_SWAP(y0, y1, temp);
-			GPU_SWAP(r0, r1, temp);   GPU_SWAP(g0, g1, temp);		GPU_SWAP(b0, b1, temp);
+#endif
+#else  // Integer Division:
+#ifdef GPU_UNAI_USE_INT_DIV_MULTINV
+		if (dx4 != 0) {
+			int iF, iS;
+			xInv(dx4, iF, iS);
+			dr4 = xInvMulx(dr4, iF, iS);
+			dg4 = xInvMulx(dg4, iF, iS);
+			db4 = xInvMulx(db4, iF, iS);
+		} else {
+			dr4 = dg4 = db4 = 0;
 		}
-	}
-
-	ya  = y2 - y0;
-	yb  = y2 - y1;
-	dx  = (x2 - x1) * ya - (x2 - x0) * yb;
-	dr4 = (r2 - r1) * ya - (r2 - r0) * yb;
-	dg4 = (g2 - g1) * ya - (g2 - g0) * yb;
-	db4 = (b2 - b1) * ya - (b2 - b0) * yb;
-
-	s32 iF,iS;
-	xInv(            dx, iF, iS);
-	dr4 = xInvMulx( dr4, iF, iS);
-	dg4 = xInvMulx( dg4, iF, iS);
-	db4 = xInvMulx( db4, iF, iS);
-	u32 dr = (u32)(dr4<< 8)&(0xffffffff<<21);   if(dr4<0) dr+= 1<<21;
-	u32 dg = (u32)(dg4>> 3)&(0xffffffff<<10);   if(dg4<0) dg+= 1<<10;
-	u32 db = (u32)(db4>>14)&(0xffffffff    );   if(db4<0) db+= 1<< 0;
-	lInc = db + dg + dr;
-
-	for (s32 loop0 = 2; loop0; --loop0)
-	{
-		if (loop0 == 2)
-		{
-			ya = y0;
-			yb = y1;
-			r3 = i2x(r0);
-			g3 = i2x(g0);
-			b3 = i2x(b0);
-			x3 = i2x(x0);
-			x4 = y0!=y1 ? x3 : i2x(x1);
-			if (dx < 0)
-			{
-				xInv(           (y2 - y0), iF, iS);
-				dx3 = xInvMulx( (x2 - x0), iF, iS);
-				dr3 = xInvMulx( (r2 - r0), iF, iS);
-				dg3 = xInvMulx( (g2 - g0), iF, iS);
-				db3 = xInvMulx( (b2 - b0), iF, iS);
-				dx4 = xLoDivx ( (x1 - x0), (y1 - y0));
-			}
-			else
-			{
-				xInv(           (y1 - y0), iF, iS);
-				dx3 = xInvMulx( (x1 - x0), iF, iS);
-				dr3 = xInvMulx( (r1 - r0), iF, iS);
-				dg3 = xInvMulx( (g1 - g0), iF, iS);
-				db3 = xInvMulx( (b1 - b0), iF, iS);
-				dx4 = xLoDivx ( (x2 - x0), (y2 - y0));
-			}
+#else
+		if (dx4 != 0) {
+			dr4 = GPU_FAST_DIV(dr4 << FIXED_BITS, dx4);
+			dg4 = GPU_FAST_DIV(dg4 << FIXED_BITS, dx4);
+			db4 = GPU_FAST_DIV(db4 << FIXED_BITS, dx4);
+		} else {
+			dr4 = dg4 = db4 = 0;
 		}
-		else
-		{
-			ya = y1;
-			yb = y2;
-			if (dx < 0)
-			{
-				temp = y1 - y0;
-				r3  = i2x(r0) + (dr3 * temp);
-				g3  = i2x(g0) + (dg3 * temp);
-				b3  = i2x(b0) + (db3 * temp);
-				x3  = i2x(x0) + (dx3 * temp);
-				x4  = i2x(x1);
-				dx4 = xLoDivx((x2 - x1), (y2 - y1));
-			}
-			else
-			{
-				r3 = i2x(r1);
-				g3 = i2x(g1);
-				b3 = i2x(b1);
-				x3 = i2x(x1);
-				x4 = i2x(x0) + (dx4 * (y1 - y0));
-
-				xInv(           (y2 - y1), iF, iS);
-				dx3 = xInvMulx( (x2 - x1), iF, iS);
-				dr3 = xInvMulx( (r2 - r1), iF, iS);
-				dg3 = xInvMulx( (g2 - g1), iF, iS);
-				db3 = xInvMulx( (b2 - b1), iF, iS);
+#endif
+#endif
+		// Setup packed Gouraud increment for inner driver
+		gpu_unai.gInc = gpuPackGouraudColInc(dr4, dg4, db4);
+
+		for (s32 loop0 = 2; loop0; loop0--) {
+			if (loop0 == 2) {
+				ya = y0;
+				yb = y1;
+				x3 = x4 = i2x(x0);
+				r3 = i2x(r0);
+				g3 = i2x(g0);
+				b3 = i2x(b0);
+				if (dx < 0) {
+#ifdef GPU_UNAI_USE_FLOATMATH
+#ifdef GPU_UNAI_USE_FLOAT_DIV_MULTINV
+					if ((y2 - y0) != 0) {
+						float finv = FloatInv(y2 - y0);
+						dx3 = (fixed)(((x2 - x0) << FIXED_BITS) * finv);
+						dr3 = (fixed)(((r2 - r0) << FIXED_BITS) * finv);
+						dg3 = (fixed)(((g2 - g0) << FIXED_BITS) * finv);
+						db3 = (fixed)(((b2 - b0) << FIXED_BITS) * finv);
+					} else {
+						dx3 = dr3 = dg3 = db3 = 0;
+					}
+					dx4 = ((y1 - y0) != 0) ? (fixed)(((x1 - x0) << FIXED_BITS) * FloatInv(y1 - y0)) : 0;
+#else
+					if ((y2 - y0) != 0) {
+						float fdiv = y2 - y0;
+						dx3 = (fixed)(((x2 - x0) << FIXED_BITS) / fdiv);
+						dr3 = (fixed)(((r2 - r0) << FIXED_BITS) / fdiv);
+						dg3 = (fixed)(((g2 - g0) << FIXED_BITS) / fdiv);
+						db3 = (fixed)(((b2 - b0) << FIXED_BITS) / fdiv);
+					} else {
+						dx3 = dr3 = dg3 = db3 = 0;
+					}
+					dx4 = ((y1 - y0) != 0) ? (fixed)(((x1 - x0) << FIXED_BITS) / (float)(y1 - y0)) : 0;
+#endif
+#else  // Integer Division:
+#ifdef GPU_UNAI_USE_INT_DIV_MULTINV
+					if ((y2 - y0) != 0) {
+						int iF, iS;
+						xInv((y2 - y0), iF, iS);
+						dx3 = xInvMulx((x2 - x0), iF, iS);
+						dr3 = xInvMulx((r2 - r0), iF, iS);
+						dg3 = xInvMulx((g2 - g0), iF, iS);
+						db3 = xInvMulx((b2 - b0), iF, iS);
+					} else {
+						dx3 = dr3 = dg3 = db3 = 0;
+					}
+					dx4 = ((y1 - y0) != 0) ? xLoDivx((x1 - x0), (y1 - y0)) : 0;
+#else
+					if ((y2 - y0) != 0) {
+						dx3 = GPU_FAST_DIV((x2 - x0) << FIXED_BITS, (y2 - y0));
+						dr3 = GPU_FAST_DIV((r2 - r0) << FIXED_BITS, (y2 - y0));
+						dg3 = GPU_FAST_DIV((g2 - g0) << FIXED_BITS, (y2 - y0));
+						db3 = GPU_FAST_DIV((b2 - b0) << FIXED_BITS, (y2 - y0));
+					} else {
+						dx3 = dr3 = dg3 = db3 = 0;
+					}
+					dx4 = ((y1 - y0) != 0) ? GPU_FAST_DIV((x1 - x0) << FIXED_BITS, (y1 - y0)) : 0;
+#endif
+#endif
+				} else {
+#ifdef GPU_UNAI_USE_FLOATMATH
+#ifdef GPU_UNAI_USE_FLOAT_DIV_MULTINV
+					if ((y1 - y0) != 0) {
+						float finv = FloatInv(y1 - y0);
+						dx3 = (fixed)(((x1 - x0) << FIXED_BITS) * finv);
+						dr3 = (fixed)(((r1 - r0) << FIXED_BITS) * finv);
+						dg3 = (fixed)(((g1 - g0) << FIXED_BITS) * finv);
+						db3 = (fixed)(((b1 - b0) << FIXED_BITS) * finv);
+					} else {
+						dx3 = dr3 = dg3 = db3 = 0;
+					}
+					dx4 = ((y2 - y0) != 0) ? (fixed)(((x2 - x0) << FIXED_BITS) * FloatInv(y2 - y0)) : 0;
+#else
+					if ((y1 - y0) != 0) {
+						float fdiv = y1 - y0;
+						dx3 = (fixed)(((x1 - x0) << FIXED_BITS) / fdiv);
+						dr3 = (fixed)(((r1 - r0) << FIXED_BITS) / fdiv);
+						dg3 = (fixed)(((g1 - g0) << FIXED_BITS) / fdiv);
+						db3 = (fixed)(((b1 - b0) << FIXED_BITS) / fdiv);
+					} else {
+						dx3 = dr3 = dg3 = db3 = 0;
+					}
+					dx4 = ((y2 - y0) != 0) ? (fixed)(((x2 - x0) << FIXED_BITS) / (float)(y2 - y0)) : 0;
+#endif
+#else  // Integer Division:
+#ifdef GPU_UNAI_USE_INT_DIV_MULTINV
+					if ((y1 - y0) != 0) {
+						int iF, iS;
+						xInv((y1 - y0), iF, iS);
+						dx3 = xInvMulx((x1 - x0), iF, iS);
+						dr3 = xInvMulx((r1 - r0), iF, iS);
+						dg3 = xInvMulx((g1 - g0), iF, iS);
+						db3 = xInvMulx((b1 - b0), iF, iS);
+					} else {
+						dx3 = dr3 = dg3 = db3 = 0;
+					}
+					dx4 = ((y2 - y0) != 0) ? xLoDivx((x2 - x0), (y2 - y0)) : 0;
+#else
+					if ((y1 - y0) != 0) {
+						dx3 = GPU_FAST_DIV((x1 - x0) << FIXED_BITS, (y1 - y0));
+						dr3 = GPU_FAST_DIV((r1 - r0) << FIXED_BITS, (y1 - y0));
+						dg3 = GPU_FAST_DIV((g1 - g0) << FIXED_BITS, (y1 - y0));
+						db3 = GPU_FAST_DIV((b1 - b0) << FIXED_BITS, (y1 - y0));
+					} else {
+						dx3 = dr3 = dg3 = db3 = 0;
+					}
+					dx4 = ((y2 - y0) != 0) ? GPU_FAST_DIV((x2 - x0) << FIXED_BITS, (y2 - y0)) : 0;
+#endif
+#endif
+				}
+			} else {
+				//senquack - break out of final loop if nothing to be drawn (1st loop
+				//           must always be taken to setup dx3/dx4)
+				if (y1 == y2) break;
+
+				ya = y1;  yb = y2;
+
+				if (dx < 0) {
+					x3 = i2x(x0);  x4 = i2x(x1);
+					r3 = i2x(r0);  g3 = i2x(g0);  b3 = i2x(b0);
+
+					if ((y1 - y0) != 0) {
+						x3 += (dx3 * (y1 - y0));
+						r3 += (dr3 * (y1 - y0));
+						g3 += (dg3 * (y1 - y0));
+						b3 += (db3 * (y1 - y0));
+					}
+
+#ifdef GPU_UNAI_USE_FLOATMATH
+#ifdef GPU_UNAI_USE_FLOAT_DIV_MULTINV
+					dx4 = ((y2 - y1) != 0) ? (fixed)(((x2 - x1) << FIXED_BITS) * FloatInv(y2 - y1)) : 0;
+#else
+					dx4 = ((y2 - y1) != 0) ? (fixed)(((x2 - x1) << FIXED_BITS) / (float)(y2 - y1)) : 0;
+#endif
+#else  // Integer Division:
+#ifdef GPU_UNAI_USE_INT_DIV_MULTINV
+					dx4 = ((y2 - y1) != 0) ? xLoDivx((x2 - x1), (y2 - y1)) : 0;
+#else
+					dx4 = ((y2 - y1) != 0) ? GPU_FAST_DIV((x2 - x1) << FIXED_BITS, (y2 - y1)) : 0;
+#endif
+#endif
+				} else {
+					x3 = i2x(x1);
+					x4 = i2x(x0) + (dx4 * (y1 - y0));
+
+					r3 = i2x(r1);  g3 = i2x(g1);  b3 = i2x(b1);
+
+#ifdef GPU_UNAI_USE_FLOATMATH
+#ifdef GPU_UNAI_USE_FLOAT_DIV_MULTINV
+					if ((y2 - y1) != 0) {
+						float finv = FloatInv(y2 - y1);
+						dx3 = (fixed)(((x2 - x1) << FIXED_BITS) * finv);
+						dr3 = (fixed)(((r2 - r1) << FIXED_BITS) * finv);
+						dg3 = (fixed)(((g2 - g1) << FIXED_BITS) * finv);
+						db3 = (fixed)(((b2 - b1) << FIXED_BITS) * finv);
+					} else {
+						dx3 = dr3 = dg3 = db3 = 0;
+					}
+#else
+					if ((y2 - y1) != 0) {
+						float fdiv = y2 - y1;
+						dx3 = (fixed)(((x2 - x1) << FIXED_BITS) / fdiv);
+						dr3 = (fixed)(((r2 - r1) << FIXED_BITS) / fdiv);
+						dg3 = (fixed)(((g2 - g1) << FIXED_BITS) / fdiv);
+						db3 = (fixed)(((b2 - b1) << FIXED_BITS) / fdiv);
+					} else {
+						dx3 = dr3 = dg3 = db3 = 0;
+					}
+#endif
+#else  // Integer Division:
+#ifdef GPU_UNAI_USE_INT_DIV_MULTINV
+					if ((y2 - y1) != 0) {
+						int iF, iS;
+						xInv((y2 - y1), iF, iS);
+						dx3 = xInvMulx((x2 - x1), iF, iS);
+						dr3 = xInvMulx((r2 - r1), iF, iS);
+						dg3 = xInvMulx((g2 - g1), iF, iS);
+						db3 = xInvMulx((b2 - b1), iF, iS);
+					} else {
+						dx3 = dr3 = dg3 = db3 = 0;
+					}
+#else
+					if ((y2 - y1) != 0) {
+						dx3 = GPU_FAST_DIV((x2 - x1) << FIXED_BITS, (y2 - y1));
+						dr3 = GPU_FAST_DIV((r2 - r1) << FIXED_BITS, (y2 - y1));
+						dg3 = GPU_FAST_DIV((g2 - g1) << FIXED_BITS, (y2 - y1));
+						db3 = GPU_FAST_DIV((b2 - b1) << FIXED_BITS, (y2 - y1));
+					} else {
+						dx3 = dr3 = dg3 = db3 = 0;
+					}
+#endif
+#endif
+				}
 			}
-		}
 
-		temp = ymin - ya;
-		if (temp > 0)
-		{
-			ya  = ymin;
-			x3 += dx3*temp;   x4 += dx4*temp;
-			r3 += dr3*temp;   g3 += dg3*temp;   b3 += db3*temp;
-		}
-		if (yb > ymax) yb = ymax;
-		if (ya>=yb) continue;
-
-		x3+= fixed_HALF;  x4+= fixed_HALF;
-		r3+= fixed_HALF;  g3+= fixed_HALF;  b3+= fixed_HALF;
-
-		u16* PixelBase  = &((u16*)GPU_FrameBuffer)[FRAME_OFFSET(0, ya)];
-		
-		for(;ya<yb;++ya, PixelBase += FRAME_WIDTH, x3+=dx3, x4+=dx4, r3+=dr3, g3+=dg3, b3+=db3)
-		{
-			if (ya&li) continue;
-			xa = x2i(x3);
-			xb = x2i(x4);
-			if( (xa>xmax) || (xb<xmin) ) continue;
-
-			temp = xmin - xa;
-			if(temp > 0)
-			{
-				xa  = xmin;
-				r4 = r3 + dr4*temp;   g4 = g3 + dg4*temp;   b4 = b3 + db4*temp;
+			s32 xmin, xmax, ymin, ymax;
+			xmin = gpu_unai.DrawingArea[0];  xmax = gpu_unai.DrawingArea[2];
+			ymin = gpu_unai.DrawingArea[1];  ymax = gpu_unai.DrawingArea[3];
+
+			if ((ymin - ya) > 0) {
+				x3 += (dx3 * (ymin - ya));
+				x4 += (dx4 * (ymin - ya));
+				r3 += (dr3 * (ymin - ya));
+				g3 += (dg3 * (ymin - ya));
+				b3 += (db3 * (ymin - ya));
+				ya = ymin;
 			}
-			else
+
+			if (yb > ymax) yb = ymax;
+
+			int loop1 = yb - ya;
+			if (loop1 <= 0)
+				continue;
+
+			u16* PixelBase = &((u16*)gpu_unai.vram)[FRAME_OFFSET(0, ya)];
+			int li=gpu_unai.ilace_mask;
+			int pi=(ProgressiveInterlaceEnabled()?(gpu_unai.ilace_mask+1):0);
+			int pif=(ProgressiveInterlaceEnabled()?(gpu_unai.prog_ilace_flag?(gpu_unai.ilace_mask+1):0):1);
+
+			for (; loop1; --loop1, ++ya, PixelBase += FRAME_WIDTH,
+					x3 += dx3, x4 += dx4,
+					r3 += dr3, g3 += dg3, b3 += db3 )
 			{
+				if (ya&li) continue;
+				if ((ya&pi)==pif) continue;
+
+				u32 r4, g4, b4;
+
+				xa = FixedCeilToInt(x3);
+				xb = FixedCeilToInt(x4);
 				r4 = r3;  g4 = g3;  b4 = b3;
+
+				fixed itmp = i2x(xa) - x3;
+				if (itmp != 0) {
+					r4 += (dr4 * itmp) >> FIXED_BITS;
+					g4 += (dg4 * itmp) >> FIXED_BITS;
+					b4 += (db4 * itmp) >> FIXED_BITS;
+				}
+
+				r4 += fixed_HALF;
+				g4 += fixed_HALF;
+				b4 += fixed_HALF;
+
+				if ((xmin - xa) > 0) {
+					r4 += (dr4 * (xmin - xa));
+					g4 += (dg4 * (xmin - xa));
+					b4 += (db4 * (xmin - xa));
+					xa = xmin;
+				}
+
+				// Setup packed Gouraud color for inner driver
+				gpu_unai.gCol = gpuPackGouraudCol(r4, g4, b4);
+
+				if (xb > xmax) xb = xmax;
+				if ((xb - xa) > 0)
+					gpuPolySpanDriver(gpu_unai, PixelBase + xa, (xb - xa));
 			}
-			if(xb > xmax) xb = xmax;
-			xb-=xa;
-			if(xb>0) gpuPolySpanDriver(PixelBase + xa,xb);
 		}
-	}
+	} while (++cur_pass < total_passes);
 }
 
 /*----------------------------------------------------------------------
-GT3
+gpuDrawPolyGT - Gouraud-shaded, textured poly
 ----------------------------------------------------------------------*/
-
-void gpuDrawGT3(const PP gpuPolySpanDriver)
+void gpuDrawPolyGT(const PtrUnion packet, const PP gpuPolySpanDriver, u32 is_quad)
 {
-	const int li=linesInterlace;
-	s32 temp;
-	s32 xa, xb, xmin, xmax;
-	s32 ya, yb, ymin, ymax;
-	s32 x0, x1, x2, x3, dx3=0, x4, dx4=0, dx;
-	s32 y0, y1, y2;
-	s32 u0, u1, u2, u3, du3=0;
-	s32 v0, v1, v2, v3, dv3=0;
-	s32 r0, r1, r2, r3, dr3=0;
-	s32 g0, g1, g2, g3, dg3=0;
-	s32 b0, b1, b2, b3, db3=0;
-
-	x0 = GPU_EXPANDSIGN(PacketBuffer.S2[2] );
-	y0 = GPU_EXPANDSIGN(PacketBuffer.S2[3] );
-	x1 = GPU_EXPANDSIGN(PacketBuffer.S2[8] );
-	y1 = GPU_EXPANDSIGN(PacketBuffer.S2[9] );
-	x2 = GPU_EXPANDSIGN(PacketBuffer.S2[14]);
-	y2 = GPU_EXPANDSIGN(PacketBuffer.S2[15]);
-
-	GPU_TESTRANGE3();
-
-	x0 += DrawingOffset[0];   x1 += DrawingOffset[0];   x2 += DrawingOffset[0];
-	y0 += DrawingOffset[1];   y1 += DrawingOffset[1];   y2 += DrawingOffset[1];
-
-	xmin = DrawingArea[0];	xmax = DrawingArea[2];
-	ymin = DrawingArea[1];	ymax = DrawingArea[3];
+	PolyVertex vbuf[4];
+	polyInitVertexBuffer(vbuf, packet, POLYTYPE_GT, is_quad);
 
+	int total_passes = is_quad ? 2 : 1;
+	int cur_pass = 0;
+	do
 	{
-		int rx0 = Max2(xmin,Min3(x0,x1,x2));
-		int ry0 = Max2(ymin,Min3(y0,y1,y2));
-		int rx1 = Min2(xmax,Max3(x0,x1,x2));
-		int ry1 = Min2(ymax,Max3(y0,y1,y2));
-		if( rx0>=rx1 || ry0>=ry1) return;
-	}
-
-	r0 = PacketBuffer.U1[0];	g0 = PacketBuffer.U1[1];	b0 = PacketBuffer.U1[2];
-	u0 = PacketBuffer.U1[8];	v0 = PacketBuffer.U1[9];
-	r1 = PacketBuffer.U1[12];	g1 = PacketBuffer.U1[13];	b1 = PacketBuffer.U1[14];
-	u1 = PacketBuffer.U1[20];	v1 = PacketBuffer.U1[21];
-	r2 = PacketBuffer.U1[24];	g2 = PacketBuffer.U1[25];	b2 = PacketBuffer.U1[26];
-	u2 = PacketBuffer.U1[32];	v2 = PacketBuffer.U1[33];
+		const PolyVertex* vptrs[3];
+		if (polyUseTriangle(vbuf, cur_pass, vptrs) == false)
+			continue;
+
+		s32 xa, xb, ya, yb;
+		s32 x3, dx3, x4, dx4, dx;
+		s32 u3, du3, v3, dv3;
+		s32 r3, dr3, g3, dg3, b3, db3;
+		s32 x0, x1, x2, y0, y1, y2;
+		s32 u0, u1, u2, v0, v1, v2;
+		s32 r0, r1, r2, g0, g1, g2, b0, b1, b2;
+		s32 du4, dv4;
+		s32 dr4, dg4, db4;
+
+		x0 = vptrs[0]->x;      y0 = vptrs[0]->y;
+		u0 = vptrs[0]->tex.u;  v0 = vptrs[0]->tex.v;
+		r0 = vptrs[0]->col.r;  g0 = vptrs[0]->col.g;  b0 = vptrs[0]->col.b;
+		x1 = vptrs[1]->x;      y1 = vptrs[1]->y;
+		u1 = vptrs[1]->tex.u;  v1 = vptrs[1]->tex.v;
+		r1 = vptrs[1]->col.r;  g1 = vptrs[1]->col.g;  b1 = vptrs[1]->col.b;
+		x2 = vptrs[2]->x;      y2 = vptrs[2]->y;
+		u2 = vptrs[2]->tex.u;  v2 = vptrs[2]->tex.v;
+		r2 = vptrs[2]->col.r;  g2 = vptrs[2]->col.g;  b2 = vptrs[2]->col.b;
+
+		ya = y2 - y0;
+		yb = y2 - y1;
+		dx4 = (x2 - x1) * ya - (x2 - x0) * yb;
+		du4 = (u2 - u1) * ya - (u2 - u0) * yb;
+		dv4 = (v2 - v1) * ya - (v2 - v0) * yb;
+		dr4 = (r2 - r1) * ya - (r2 - r0) * yb;
+		dg4 = (g2 - g1) * ya - (g2 - g0) * yb;
+		db4 = (b2 - b1) * ya - (b2 - b0) * yb;
+		dx = dx4;
+		if (dx4 < 0) {
+			dx4 = -dx4;
+			du4 = -du4;
+			dv4 = -dv4;
+			dr4 = -dr4;
+			dg4 = -dg4;
+			db4 = -db4;
+		}
 
-	if (y0 >= y1)
-	{
-		if( y0!=y1 || x0>x1 )
-		{
-			GPU_SWAP(x0, x1, temp);		GPU_SWAP(y0, y1, temp);
-			GPU_SWAP(u0, u1, temp);		GPU_SWAP(v0, v1, temp);
-			GPU_SWAP(r0, r1, temp);		GPU_SWAP(g0, g1, temp);   GPU_SWAP(b0, b1, temp);
+#ifdef GPU_UNAI_USE_FLOATMATH
+#ifdef GPU_UNAI_USE_FLOAT_DIV_MULTINV
+		if (dx4 != 0) {
+			float finv = FloatInv(dx4);
+			du4 = (fixed)((du4 << FIXED_BITS) * finv);
+			dv4 = (fixed)((dv4 << FIXED_BITS) * finv);
+			dr4 = (fixed)((dr4 << FIXED_BITS) * finv);
+			dg4 = (fixed)((dg4 << FIXED_BITS) * finv);
+			db4 = (fixed)((db4 << FIXED_BITS) * finv);
+		} else {
+			du4 = dv4 = dr4 = dg4 = db4 = 0;
 		}
-	}
-	if (y1 >= y2)
-	{
-		if( y1!=y2 || x1>x2 )
-		{
-			GPU_SWAP(x1, x2, temp);		GPU_SWAP(y1, y2, temp);
-			GPU_SWAP(u1, u2, temp);		GPU_SWAP(v1, v2, temp);
-			GPU_SWAP(r1, r2, temp);   GPU_SWAP(g1, g2, temp);		GPU_SWAP(b1, b2, temp);
+#else
+		if (dx4 != 0) {
+			float fdiv = dx4;
+			du4 = (fixed)((du4 << FIXED_BITS) / fdiv);
+			dv4 = (fixed)((dv4 << FIXED_BITS) / fdiv);
+			dr4 = (fixed)((dr4 << FIXED_BITS) / fdiv);
+			dg4 = (fixed)((dg4 << FIXED_BITS) / fdiv);
+			db4 = (fixed)((db4 << FIXED_BITS) / fdiv);
+		} else {
+			du4 = dv4 = dr4 = dg4 = db4 = 0;
 		}
-	}
-	if (y0 >= y1)
-	{
-		if( y0!=y1 || x0>x1 )
-		{
-			GPU_SWAP(x0, x1, temp);		GPU_SWAP(y0, y1, temp);
-			GPU_SWAP(u0, u1, temp);		GPU_SWAP(v0, v1, temp);
-			GPU_SWAP(r0, r1, temp);		GPU_SWAP(g0, g1, temp);		GPU_SWAP(b0, b1, temp);
+#endif
+#else  // Integer Division:
+#ifdef GPU_UNAI_USE_INT_DIV_MULTINV
+		if (dx4 != 0) {
+			int iF, iS;
+			xInv(dx4, iF, iS);
+			du4 = xInvMulx(du4, iF, iS);
+			dv4 = xInvMulx(dv4, iF, iS);
+			dr4 = xInvMulx(dr4, iF, iS);
+			dg4 = xInvMulx(dg4, iF, iS);
+			db4 = xInvMulx(db4, iF, iS);
+		} else {
+			du4 = dv4 = dr4 = dg4 = db4 = 0;
 		}
-	}
-
-	ya  = y2 - y0;
-	yb  = y2 - y1;
-	dx  = (x2 - x1) * ya - (x2 - x0) * yb;
-	du4 = (u2 - u1) * ya - (u2 - u0) * yb;
-	dv4 = (v2 - v1) * ya - (v2 - v0) * yb;
-	dr4 = (r2 - r1) * ya - (r2 - r0) * yb;
-	dg4 = (g2 - g1) * ya - (g2 - g0) * yb;
-	db4 = (b2 - b1) * ya - (b2 - b0) * yb;
-
-	s32 iF,iS;
-
-	xInv(            dx, iF, iS);
-	du4 = xInvMulx( du4, iF, iS);
-	dv4 = xInvMulx( dv4, iF, iS);
-	dr4 = xInvMulx( dr4, iF, iS);
-	dg4 = xInvMulx( dg4, iF, iS);
-	db4 = xInvMulx( db4, iF, iS);
-	u32 dr = (u32)(dr4<< 8)&(0xffffffff<<21);   if(dr4<0) dr+= 1<<21;
-	u32 dg = (u32)(dg4>> 3)&(0xffffffff<<10);   if(dg4<0) dg+= 1<<10;
-	u32 db = (u32)(db4>>14)&(0xffffffff    );   if(db4<0) db+= 1<< 0;
-	lInc = db + dg + dr;
-	tInc = ((u32)(du4<<7)&0x7fff0000) | ((u32)(dv4>>9)&0x00007fff);
-	tMsk = (TextureWindow[2]<<23) | (TextureWindow[3]<<7) | 0x00ff00ff;
-
-	for (s32 loop0 = 2; loop0; --loop0)
-	{
-		if (loop0 == 2)
-		{
-			ya = y0;
-			yb = y1;
-			u3 = i2x(u0);
-			v3 = i2x(v0);
-			r3 = i2x(r0);
-			g3 = i2x(g0);
-			b3 = i2x(b0);
-			x3 = i2x(x0);
-			x4 = y0!=y1 ? x3 : i2x(x1);
-			if (dx < 0)
-			{
-				xInv(           (y2 - y0), iF, iS);
-				dx3 = xInvMulx( (x2 - x0), iF, iS);
-				du3 = xInvMulx( (u2 - u0), iF, iS);
-				dv3 = xInvMulx( (v2 - v0), iF, iS);
-				dr3 = xInvMulx( (r2 - r0), iF, iS);
-				dg3 = xInvMulx( (g2 - g0), iF, iS);
-				db3 = xInvMulx( (b2 - b0), iF, iS);
-				dx4 = xLoDivx ( (x1 - x0), (y1 - y0));
-			}
-			else
-			{
-				xInv(           (y1 - y0), iF, iS);
-				dx3 = xInvMulx( (x1 - x0), iF, iS);
-				du3 = xInvMulx( (u1 - u0), iF, iS);
-				dv3 = xInvMulx( (v1 - v0), iF, iS);
-				dr3 = xInvMulx( (r1 - r0), iF, iS);
-				dg3 = xInvMulx( (g1 - g0), iF, iS);
-				db3 = xInvMulx( (b1 - b0), iF, iS);
-				dx4 = xLoDivx ( (x2 - x0), (y2 - y0));
-			}
+#else
+		if (dx4 != 0) {
+			du4 = GPU_FAST_DIV(du4 << FIXED_BITS, dx4);
+			dv4 = GPU_FAST_DIV(dv4 << FIXED_BITS, dx4);
+			dr4 = GPU_FAST_DIV(dr4 << FIXED_BITS, dx4);
+			dg4 = GPU_FAST_DIV(dg4 << FIXED_BITS, dx4);
+			db4 = GPU_FAST_DIV(db4 << FIXED_BITS, dx4);
+		} else {
+			du4 = dv4 = dr4 = dg4 = db4 = 0;
 		}
-		else
-		{
-			ya = y1;
-			yb = y2;
-			if (dx < 0)
-			{
-				temp = y1 - y0;
-				u3  = i2x(u0) + (du3 * temp);
-				v3  = i2x(v0) + (dv3 * temp);
-				r3  = i2x(r0) + (dr3 * temp);
-				g3  = i2x(g0) + (dg3 * temp);
-				b3  = i2x(b0) + (db3 * temp);
-				x3  = i2x(x0) + (dx3 * temp);
-				x4  = i2x(x1);
-				dx4 = xLoDivx((x2 - x1), (y2 - y1));
+#endif
+#endif
+		// Set u,v increments and packed Gouraud increment for inner driver
+		gpu_unai.u_inc = du4;
+		gpu_unai.v_inc = dv4;
+		gpu_unai.gInc = gpuPackGouraudColInc(dr4, dg4, db4);
+
+		for (s32 loop0 = 2; loop0; loop0--) {
+			if (loop0 == 2) {
+				ya = y0;  yb = y1;
+				x3 = x4 = i2x(x0);
+				u3 = i2x(u0);  v3 = i2x(v0);
+				r3 = i2x(r0);  g3 = i2x(g0);  b3 = i2x(b0);
+				if (dx < 0) {
+#ifdef GPU_UNAI_USE_FLOATMATH
+#ifdef GPU_UNAI_USE_FLOAT_DIV_MULTINV
+					if ((y2 - y0) != 0) {
+						float finv = FloatInv(y2 - y0);
+						dx3 = (fixed)(((x2 - x0) << FIXED_BITS) * finv);
+						du3 = (fixed)(((u2 - u0) << FIXED_BITS) * finv);
+						dv3 = (fixed)(((v2 - v0) << FIXED_BITS) * finv);
+						dr3 = (fixed)(((r2 - r0) << FIXED_BITS) * finv);
+						dg3 = (fixed)(((g2 - g0) << FIXED_BITS) * finv);
+						db3 = (fixed)(((b2 - b0) << FIXED_BITS) * finv);
+					} else {
+						dx3 = du3 = dv3 = dr3 = dg3 = db3 = 0;
+					}
+					dx4 = ((y1 - y0) != 0) ? (fixed)(((x1 - x0) << FIXED_BITS) * FloatInv(y1 - y0)) : 0;
+#else
+					if ((y2 - y0) != 0) {
+						float fdiv = y2 - y0;
+						dx3 = (fixed)(((x2 - x0) << FIXED_BITS) / fdiv);
+						du3 = (fixed)(((u2 - u0) << FIXED_BITS) / fdiv);
+						dv3 = (fixed)(((v2 - v0) << FIXED_BITS) / fdiv);
+						dr3 = (fixed)(((r2 - r0) << FIXED_BITS) / fdiv);
+						dg3 = (fixed)(((g2 - g0) << FIXED_BITS) / fdiv);
+						db3 = (fixed)(((b2 - b0) << FIXED_BITS) / fdiv);
+					} else {
+						dx3 = du3 = dv3 = dr3 = dg3 = db3 = 0;
+					}
+					dx4 = ((y1 - y0) != 0) ? (fixed)(((x1 - x0) << FIXED_BITS) / (float)(y1 - y0)) : 0;
+#endif
+#else  // Integer Division:
+#ifdef GPU_UNAI_USE_INT_DIV_MULTINV
+					if ((y2 - y0) != 0) {
+						int iF, iS;
+						xInv((y2 - y0), iF, iS);
+						dx3 = xInvMulx((x2 - x0), iF, iS);
+						du3 = xInvMulx((u2 - u0), iF, iS);
+						dv3 = xInvMulx((v2 - v0), iF, iS);
+						dr3 = xInvMulx((r2 - r0), iF, iS);
+						dg3 = xInvMulx((g2 - g0), iF, iS);
+						db3 = xInvMulx((b2 - b0), iF, iS);
+					} else {
+						dx3 = du3 = dv3 = dr3 = dg3 = db3 = 0;
+					}
+					dx4 = ((y1 - y0) != 0) ? xLoDivx((x1 - x0), (y1 - y0)) : 0;
+#else
+					if ((y2 - y0) != 0) {
+						dx3 = GPU_FAST_DIV((x2 - x0) << FIXED_BITS, (y2 - y0));
+						du3 = GPU_FAST_DIV((u2 - u0) << FIXED_BITS, (y2 - y0));
+						dv3 = GPU_FAST_DIV((v2 - v0) << FIXED_BITS, (y2 - y0));
+						dr3 = GPU_FAST_DIV((r2 - r0) << FIXED_BITS, (y2 - y0));
+						dg3 = GPU_FAST_DIV((g2 - g0) << FIXED_BITS, (y2 - y0));
+						db3 = GPU_FAST_DIV((b2 - b0) << FIXED_BITS, (y2 - y0));
+					} else {
+						dx3 = du3 = dv3 = dr3 = dg3 = db3 = 0;
+					}
+					dx4 = ((y1 - y0) != 0) ? GPU_FAST_DIV((x1 - x0) << FIXED_BITS, (y1 - y0)) : 0;
+#endif
+#endif
+				} else {
+#ifdef GPU_UNAI_USE_FLOATMATH
+#ifdef GPU_UNAI_USE_FLOAT_DIV_MULTINV
+					if ((y1 - y0) != 0) {
+						float finv = FloatInv(y1 - y0);
+						dx3 = (fixed)(((x1 - x0) << FIXED_BITS) * finv);
+						du3 = (fixed)(((u1 - u0) << FIXED_BITS) * finv);
+						dv3 = (fixed)(((v1 - v0) << FIXED_BITS) * finv);
+						dr3 = (fixed)(((r1 - r0) << FIXED_BITS) * finv);
+						dg3 = (fixed)(((g1 - g0) << FIXED_BITS) * finv);
+						db3 = (fixed)(((b1 - b0) << FIXED_BITS) * finv);
+					} else {
+						dx3 = du3 = dv3 = dr3 = dg3 = db3 = 0;
+					}
+					dx4 = ((y2 - y0) != 0) ? (fixed)(((x2 - x0) << FIXED_BITS) * FloatInv(y2 - y0)) : 0;
+#else
+					if ((y1 - y0) != 0) {
+						float fdiv = y1 - y0;
+						dx3 = (fixed)(((x1 - x0) << FIXED_BITS) / fdiv);
+						du3 = (fixed)(((u1 - u0) << FIXED_BITS) / fdiv);
+						dv3 = (fixed)(((v1 - v0) << FIXED_BITS) / fdiv);
+						dr3 = (fixed)(((r1 - r0) << FIXED_BITS) / fdiv);
+						dg3 = (fixed)(((g1 - g0) << FIXED_BITS) / fdiv);
+						db3 = (fixed)(((b1 - b0) << FIXED_BITS) / fdiv);
+					} else {
+						dx3 = du3 = dv3 = dr3 = dg3 = db3 = 0;
+					}
+					dx4 = ((y2 - y0) != 0) ? (fixed)(((x2 - x0) << FIXED_BITS) / float(y2 - y0)) : 0;
+#endif
+#else  // Integer Division:
+#ifdef GPU_UNAI_USE_INT_DIV_MULTINV
+					if ((y1 - y0) != 0) {
+						int iF, iS;
+						xInv((y1 - y0), iF, iS);
+						dx3 = xInvMulx((x1 - x0), iF, iS);
+						du3 = xInvMulx((u1 - u0), iF, iS);
+						dv3 = xInvMulx((v1 - v0), iF, iS);
+						dr3 = xInvMulx((r1 - r0), iF, iS);
+						dg3 = xInvMulx((g1 - g0), iF, iS);
+						db3 = xInvMulx((b1 - b0), iF, iS);
+					} else {
+						dx3 = du3 = dv3 = dr3 = dg3 = db3 = 0;
+					}
+					dx4 = ((y2 - y0) != 0) ? xLoDivx((x2 - x0), (y2 - y0)) : 0;
+#else
+					if ((y1 - y0) != 0) {
+						dx3 = GPU_FAST_DIV((x1 - x0) << FIXED_BITS, (y1 - y0));
+						du3 = GPU_FAST_DIV((u1 - u0) << FIXED_BITS, (y1 - y0));
+						dv3 = GPU_FAST_DIV((v1 - v0) << FIXED_BITS, (y1 - y0));
+						dr3 = GPU_FAST_DIV((r1 - r0) << FIXED_BITS, (y1 - y0));
+						dg3 = GPU_FAST_DIV((g1 - g0) << FIXED_BITS, (y1 - y0));
+						db3 = GPU_FAST_DIV((b1 - b0) << FIXED_BITS, (y1 - y0));
+					} else {
+						dx3 = du3 = dv3 = dr3 = dg3 = db3 = 0;
+					}
+					dx4 = ((y2 - y0) != 0) ? GPU_FAST_DIV((x2 - x0) << FIXED_BITS, (y2 - y0)) : 0;
+#endif
+#endif
+				}
+			} else {
+				//senquack - break out of final loop if nothing to be drawn (1st loop
+				//           must always be taken to setup dx3/dx4)
+				if (y1 == y2) break;
+
+				ya = y1;  yb = y2;
+
+				if (dx < 0) {
+					x3 = i2x(x0);  x4 = i2x(x1);
+					u3 = i2x(u0);  v3 = i2x(v0);
+					r3 = i2x(r0);  g3 = i2x(g0);  b3 = i2x(b0);
+
+					if ((y1 - y0) != 0) {
+						x3 += (dx3 * (y1 - y0));
+						u3 += (du3 * (y1 - y0));
+						v3 += (dv3 * (y1 - y0));
+						r3 += (dr3 * (y1 - y0));
+						g3 += (dg3 * (y1 - y0));
+						b3 += (db3 * (y1 - y0));
+					}
+
+#ifdef GPU_UNAI_USE_FLOATMATH
+#ifdef GPU_UNAI_USE_FLOAT_DIV_MULTINV
+					dx4 = ((y2 - y1) != 0) ? (fixed)(((x2 - x1) << FIXED_BITS) * FloatInv(y2 - y1)) : 0;
+#else
+					dx4 = ((y2 - y1) != 0) ? (fixed)(((x2 - x1) << FIXED_BITS) / (float)(y2 - y1)) : 0;
+#endif
+#else  // Integer Division:
+#ifdef GPU_UNAI_USE_INT_DIV_MULTINV
+					dx4 = ((y2 - y1) != 0) ? xLoDivx((x2 - x1), (y2 - y1)) : 0;
+#else
+					dx4 = ((y2 - y1) != 0) ? GPU_FAST_DIV((x2 - x1) << FIXED_BITS, (y2 - y1)) : 0;
+#endif
+#endif
+				} else {
+					x3 = i2x(x1);
+					x4 = i2x(x0) + (dx4 * (y1 - y0));
+
+					u3 = i2x(u1);  v3 = i2x(v1);
+					r3 = i2x(r1);  g3 = i2x(g1);  b3 = i2x(b1);
+#ifdef GPU_UNAI_USE_FLOATMATH
+#ifdef GPU_UNAI_USE_FLOAT_DIV_MULTINV
+					if ((y2 - y1) != 0) {
+						float finv = FloatInv(y2 - y1);
+						dx3 = (fixed)(((x2 - x1) << FIXED_BITS) * finv);
+						du3 = (fixed)(((u2 - u1) << FIXED_BITS) * finv);
+						dv3 = (fixed)(((v2 - v1) << FIXED_BITS) * finv);
+						dr3 = (fixed)(((r2 - r1) << FIXED_BITS) * finv);
+						dg3 = (fixed)(((g2 - g1) << FIXED_BITS) * finv);
+						db3 = (fixed)(((b2 - b1) << FIXED_BITS) * finv);
+					} else {
+						dx3 = du3 = dv3 = dr3 = dg3 = db3 = 0;
+					}
+#else
+					if ((y2 - y1) != 0) {
+						float fdiv = y2 - y1;
+						dx3 = (fixed)(((x2 - x1) << FIXED_BITS) / fdiv);
+						du3 = (fixed)(((u2 - u1) << FIXED_BITS) / fdiv);
+						dv3 = (fixed)(((v2 - v1) << FIXED_BITS) / fdiv);
+						dr3 = (fixed)(((r2 - r1) << FIXED_BITS) / fdiv);
+						dg3 = (fixed)(((g2 - g1) << FIXED_BITS) / fdiv);
+						db3 = (fixed)(((b2 - b1) << FIXED_BITS) / fdiv);
+					} else {
+						dx3 = du3 = dv3 = dr3 = dg3 = db3 = 0;
+					}
+#endif
+#else  // Integer Division:
+#ifdef GPU_UNAI_USE_INT_DIV_MULTINV
+					if ((y2 - y1) != 0) {
+						int iF, iS;
+						xInv((y2 - y1), iF, iS);
+						dx3 = xInvMulx((x2 - x1), iF, iS);
+						du3 = xInvMulx((u2 - u1), iF, iS);
+						dv3 = xInvMulx((v2 - v1), iF, iS);
+						dr3 = xInvMulx((r2 - r1), iF, iS);
+						dg3 = xInvMulx((g2 - g1), iF, iS);
+						db3 = xInvMulx((b2 - b1), iF, iS);
+					} else {
+						dx3 = du3 = dv3 = dr3 = dg3 = db3 = 0;
+					}
+#else
+					if ((y2 - y1) != 0) {
+						dx3 = GPU_FAST_DIV((x2 - x1) << FIXED_BITS, (y2 - y1));
+						du3 = GPU_FAST_DIV((u2 - u1) << FIXED_BITS, (y2 - y1));
+						dv3 = GPU_FAST_DIV((v2 - v1) << FIXED_BITS, (y2 - y1));
+						dr3 = GPU_FAST_DIV((r2 - r1) << FIXED_BITS, (y2 - y1));
+						dg3 = GPU_FAST_DIV((g2 - g1) << FIXED_BITS, (y2 - y1));
+						db3 = GPU_FAST_DIV((b2 - b1) << FIXED_BITS, (y2 - y1));
+					} else {
+						dx3 = du3 = dv3 = dr3 = dg3 = db3 = 0;
+					}
+#endif
+#endif
+				}
 			}
-			else
-			{
-				u3 = i2x(u1);
-				v3 = i2x(v1);
-				r3 = i2x(r1);
-				g3 = i2x(g1);
-				b3 = i2x(b1);
-				x3 = i2x(x1);
-				x4 = i2x(x0) + (dx4 * (y1 - y0));
-
-				xInv(           (y2 - y1), iF, iS);
-				dx3 = xInvMulx( (x2 - x1), iF, iS);
-				du3 = xInvMulx( (u2 - u1), iF, iS);
-				dv3 = xInvMulx( (v2 - v1), iF, iS);
-				dr3 = xInvMulx( (r2 - r1), iF, iS);
-				dg3 = xInvMulx( (g2 - g1), iF, iS);
-				db3 = xInvMulx( (b2 - b1), iF, iS);
-			}
-		}
 
-		temp = ymin - ya;
-		if (temp > 0)
-		{
-			ya  = ymin;
-			x3 += dx3*temp;   x4 += dx4*temp;
-			u3 += du3*temp;   v3 += dv3*temp;
-			r3 += dr3*temp;   g3 += dg3*temp;   b3 += db3*temp;
-		}
-		if (yb > ymax) yb = ymax;
-		if (ya>=yb) continue;
-
-		x3+= fixed_HALF;  x4+= fixed_HALF;
-		u3+= fixed_HALF;  v4+= fixed_HALF;
-		r3+= fixed_HALF;  g3+= fixed_HALF;  b3+= fixed_HALF;
-		u16* PixelBase  = &((u16*)GPU_FrameBuffer)[FRAME_OFFSET(0, ya)];
-		
-		for(;ya<yb;++ya, PixelBase += FRAME_WIDTH, x3+=dx3, x4+=dx4, u3+=du3, v3+=dv3, r3+=dr3, g3+=dg3,	b3+=db3)
-		{
-			if (ya&li) continue;
-			xa = x2i(x3);
-			xb = x2i(x4);
-			if( (xa>xmax) || (xb<xmin))	continue;
-
-			temp = xmin - xa;
-			if(temp > 0)
-			{
-				xa  = xmin;
-				u4 = u3 + du4*temp;   v4 = v3 + dv4*temp;
-				r4 = r3 + dr4*temp;   g4 = g3 + dg4*temp;   b4 = b3 + db4*temp;
+			s32 xmin, xmax, ymin, ymax;
+			xmin = gpu_unai.DrawingArea[0];  xmax = gpu_unai.DrawingArea[2];
+			ymin = gpu_unai.DrawingArea[1];  ymax = gpu_unai.DrawingArea[3];
+
+			if ((ymin - ya) > 0) {
+				x3 += (dx3 * (ymin - ya));
+				x4 += (dx4 * (ymin - ya));
+				u3 += (du3 * (ymin - ya));
+				v3 += (dv3 * (ymin - ya));
+				r3 += (dr3 * (ymin - ya));
+				g3 += (dg3 * (ymin - ya));
+				b3 += (db3 * (ymin - ya));
+				ya = ymin;
 			}
-			else
+
+			if (yb > ymax) yb = ymax;
+
+			int loop1 = yb - ya;
+			if (loop1 <= 0)
+				continue;
+
+			u16* PixelBase = &((u16*)gpu_unai.vram)[FRAME_OFFSET(0, ya)];
+			int li=gpu_unai.ilace_mask;
+			int pi=(ProgressiveInterlaceEnabled()?(gpu_unai.ilace_mask+1):0);
+			int pif=(ProgressiveInterlaceEnabled()?(gpu_unai.prog_ilace_flag?(gpu_unai.ilace_mask+1):0):1);
+
+			for (; loop1; --loop1, ++ya, PixelBase += FRAME_WIDTH,
+					x3 += dx3, x4 += dx4,
+					u3 += du3, v3 += dv3,
+					r3 += dr3, g3 += dg3, b3 += db3 )
 			{
+				if (ya&li) continue;
+				if ((ya&pi)==pif) continue;
+
+				u32 u4, v4;
+				u32 r4, g4, b4;
+
+				xa = FixedCeilToInt(x3);
+				xb = FixedCeilToInt(x4);
 				u4 = u3;  v4 = v3;
 				r4 = r3;  g4 = g3;  b4 = b3;
+
+				fixed itmp = i2x(xa) - x3;
+				if (itmp != 0) {
+					u4 += (du4 * itmp) >> FIXED_BITS;
+					v4 += (dv4 * itmp) >> FIXED_BITS;
+					r4 += (dr4 * itmp) >> FIXED_BITS;
+					g4 += (dg4 * itmp) >> FIXED_BITS;
+					b4 += (db4 * itmp) >> FIXED_BITS;
+				}
+
+				u4 += fixed_HALF;
+				v4 += fixed_HALF;
+				r4 += fixed_HALF;
+				g4 += fixed_HALF;
+				b4 += fixed_HALF;
+
+				if ((xmin - xa) > 0) {
+					u4 += du4 * (xmin - xa);
+					v4 += dv4 * (xmin - xa);
+					r4 += dr4 * (xmin - xa);
+					g4 += dg4 * (xmin - xa);
+					b4 += db4 * (xmin - xa);
+					xa = xmin;
+				}
+
+				// Set packed Gouraud color and u,v coords for inner driver
+				gpu_unai.u = u4;
+				gpu_unai.v = v4;
+				gpu_unai.gCol = gpuPackGouraudCol(r4, g4, b4);
+
+				if (xb > xmax) xb = xmax;
+				if ((xb - xa) > 0)
+					gpuPolySpanDriver(gpu_unai, PixelBase + xa, (xb - xa));
 			}
-			if(xb > xmax) xb = xmax;
-			xb-=xa;
-			if(xb>0) gpuPolySpanDriver(PixelBase + xa,xb);
 		}
-	}
+	} while (++cur_pass < total_passes);
 }
diff --git a/plugins/gpu_unai/gpu_raster_sprite.h b/plugins/gpu_unai/gpu_raster_sprite.h
index a700db32..40a1a78a 100644
--- a/plugins/gpu_unai/gpu_raster_sprite.h
+++ b/plugins/gpu_unai/gpu_raster_sprite.h
@@ -21,73 +21,70 @@
 ///////////////////////////////////////////////////////////////////////////////
 //  GPU internal sprite drawing functions
 
-///////////////////////////////////////////////////////////////////////////////
-void gpuDrawS(const PS gpuSpriteSpanDriver)
+void gpuDrawS(PtrUnion packet, const PS gpuSpriteSpanDriver)
 {
-	s32 x0, x1;
-	s32 y0, y1;
-	s32 u0;
-	s32 v0;
-
-	x1 = x0 = GPU_EXPANDSIGN(PacketBuffer.S2[2]) + DrawingOffset[0];
-	y1 = y0 = GPU_EXPANDSIGN(PacketBuffer.S2[3]) + DrawingOffset[1];
-	x1+= PacketBuffer.S2[6];
-	y1+= PacketBuffer.S2[7];
-
-	{
-		s32 xmin, xmax;
-		s32 ymin, ymax;
-		xmin = DrawingArea[0];	xmax = DrawingArea[2];
-		ymin = DrawingArea[1];	ymax = DrawingArea[3];
-
-		{
-			int rx0 = Max2(xmin,Min2(x0,x1));
-			int ry0 = Max2(ymin,Min2(y0,y1));
-			int rx1 = Min2(xmax,Max2(x0,x1));
-			int ry1 = Min2(ymax,Max2(y0,y1));
-			if( rx0>=rx1 || ry0>=ry1) return;
-		}
-
-		u0 = PacketBuffer.U1[8];
-		v0 = PacketBuffer.U1[9];
-
-		r4 = s32(PacketBuffer.U1[0]);
-		g4 = s32(PacketBuffer.U1[1]);
-		b4 = s32(PacketBuffer.U1[2]);
-
-		{
-			s32 temp;
-			temp = ymin - y0;
-			if (temp > 0) { y0 = ymin; v0 += temp; }
-			if (y1 > ymax) y1 = ymax;
-			if (y1 <= y0) return;
-			
-			temp = xmin - x0;
-			if (temp > 0) { x0 = xmin; u0 += temp; }
-			if (x1 > xmax) x1 = xmax;
-			x1 -= x0;
-			if (x1 <= 0) return;
-		}
-	}
-
-	{
-		u16 *Pixel = &((u16*)GPU_FrameBuffer)[FRAME_OFFSET(x0, y0)];
-		const int li=linesInterlace;
-		const u32 masku=TextureWindow[2];
-		const u32 maskv=TextureWindow[3];
-
-		for (;y0<y1;++y0) {
-			if( 0 == (y0&li) ) gpuSpriteSpanDriver(Pixel,x1,FRAME_OFFSET(u0,v0),masku);
-			Pixel += FRAME_WIDTH;
-			v0 = (v0+1)&maskv;
-		}
+	s32 x0, x1, y0, y1;
+	u32 u0, v0;
+
+	//NOTE: Must 11-bit sign-extend the whole sum here, not just packet X/Y,
+	// or sprites in 1st level of SkullMonkeys disappear when walking right.
+	// This now matches behavior of Mednafen and PCSX Rearmed's gpu_neon:
+	x0 = GPU_EXPANDSIGN(packet.S2[2] + gpu_unai.DrawingOffset[0]);
+	y0 = GPU_EXPANDSIGN(packet.S2[3] + gpu_unai.DrawingOffset[1]);
+
+	u32 w = packet.U2[6] & 0x3ff; // Max width is 1023
+	u32 h = packet.U2[7] & 0x1ff; // Max height is 511
+	x1 = x0 + w;
+	y1 = y0 + h;
+
+	s32 xmin, xmax, ymin, ymax;
+	xmin = gpu_unai.DrawingArea[0];	xmax = gpu_unai.DrawingArea[2];
+	ymin = gpu_unai.DrawingArea[1];	ymax = gpu_unai.DrawingArea[3];
+
+	u0 = packet.U1[8];
+	v0 = packet.U1[9];
+
+	s32 temp;
+	temp = ymin - y0;
+	if (temp > 0) { y0 = ymin; v0 += temp; }
+	if (y1 > ymax) y1 = ymax;
+	if (y1 <= y0) return;
+
+	temp = xmin - x0;
+	if (temp > 0) { x0 = xmin; u0 += temp; }
+	if (x1 > xmax) x1 = xmax;
+	x1 -= x0;
+	if (x1 <= 0) return;
+
+	gpu_unai.r5 = packet.U1[0] >> 3;
+	gpu_unai.g5 = packet.U1[1] >> 3;
+	gpu_unai.b5 = packet.U1[2] >> 3;
+
+	u16 *Pixel = &((u16*)gpu_unai.vram)[FRAME_OFFSET(x0, y0)];
+	const int li=gpu_unai.ilace_mask;
+	const int pi=(ProgressiveInterlaceEnabled()?(gpu_unai.ilace_mask+1):0);
+	const int pif=(ProgressiveInterlaceEnabled()?(gpu_unai.prog_ilace_flag?(gpu_unai.ilace_mask+1):0):1);
+	unsigned int tmode = gpu_unai.TEXT_MODE >> 5;
+	const u32 v0_mask = gpu_unai.TextureWindow[3];
+	u8* pTxt_base = (u8*)gpu_unai.TBA;
+
+	// Texture is accessed byte-wise, so adjust idx if 16bpp
+	if (tmode == 3) u0 <<= 1;
+
+	for (; y0<y1; ++y0) {
+		u8* pTxt = pTxt_base + ((v0 & v0_mask) * 2048);
+		if (!(y0&li) && (y0&pi)!=pif)
+			gpuSpriteSpanDriver(Pixel, x1, pTxt, u0);
+		Pixel += FRAME_WIDTH;
+		v0++;
 	}
 }
 
 #ifdef __arm__
 #include "gpu_arm.h"
 
-void gpuDrawS16(void)
+/* Notaz 4bit sprites optimization */
+void gpuDrawS16(PtrUnion packet)
 {
 	s32 x0, y0;
 	s32 u0, v0;
@@ -95,18 +92,21 @@ void gpuDrawS16(void)
 	s32 ymin, ymax;
 	u32 h = 16;
 
-	x0 = GPU_EXPANDSIGN(PacketBuffer.S2[2]) + DrawingOffset[0];
-	y0 = GPU_EXPANDSIGN(PacketBuffer.S2[3]) + DrawingOffset[1];
+	//NOTE: Must 11-bit sign-extend the whole sum here, not just packet X/Y,
+	// or sprites in 1st level of SkullMonkeys disappear when walking right.
+	// This now matches behavior of Mednafen and PCSX Rearmed's gpu_neon:
+	x0 = GPU_EXPANDSIGN(packet.S2[2] + gpu_unai.DrawingOffset[0]);
+	y0 = GPU_EXPANDSIGN(packet.S2[3] + gpu_unai.DrawingOffset[1]);
 
-	xmin = DrawingArea[0];	xmax = DrawingArea[2];
-	ymin = DrawingArea[1];	ymax = DrawingArea[3];
-	u0 = PacketBuffer.U1[8];
-	v0 = PacketBuffer.U1[9];
+	xmin = gpu_unai.DrawingArea[0];	xmax = gpu_unai.DrawingArea[2];
+	ymin = gpu_unai.DrawingArea[1];	ymax = gpu_unai.DrawingArea[3];
+	u0 = packet.U1[8];
+	v0 = packet.U1[9];
 
 	if (x0 > xmax - 16 || x0 < xmin ||
-	    ((u0 | v0) & 15) || !(TextureWindow[2] & TextureWindow[3] & 8)) {
+	    ((u0 | v0) & 15) || !(gpu_unai.TextureWindow[2] & gpu_unai.TextureWindow[3] & 8)) {
 		// send corner cases to general handler
-		PacketBuffer.U4[3] = 0x00100010;
+		packet.U4[3] = 0x00100010;
 		gpuDrawS(gpuSpriteSpanFn<0x20>);
 		return;
 	}
@@ -121,54 +121,45 @@ void gpuDrawS16(void)
 	else if (ymax - y0 < 16)
 		h = ymax - y0;
 
-	draw_spr16_full(&GPU_FrameBuffer[FRAME_OFFSET(x0, y0)], &TBA[FRAME_OFFSET(u0/4, v0)], CBA, h);
+	draw_spr16_full(&gpu_unai.vram[FRAME_OFFSET(x0, y0)], &gpu_unai.TBA[FRAME_OFFSET(u0/4, v0)], gpu_unai.CBA, h);
 }
 #endif // __arm__
 
-///////////////////////////////////////////////////////////////////////////////
-void gpuDrawT(const PT gpuTileSpanDriver)
+void gpuDrawT(PtrUnion packet, const PT gpuTileSpanDriver)
 {
-	s32 x0, y0;
-	s32 x1, y1;
-
-	x1 = x0 = GPU_EXPANDSIGN(PacketBuffer.S2[2]) + DrawingOffset[0];
-	y1 = y0 = GPU_EXPANDSIGN(PacketBuffer.S2[3]) + DrawingOffset[1];
-	x1+= PacketBuffer.S2[4];
-	y1+= PacketBuffer.S2[5];
-
-	{
-		s32 xmin, xmax;
-		s32 ymin, ymax;
-		xmin = DrawingArea[0];	xmax = DrawingArea[2];
-		ymin = DrawingArea[1];	ymax = DrawingArea[3];
-
-		{
-			int rx0 = Max2(xmin,Min2(x0,x1));
-			int ry0 = Max2(ymin,Min2(y0,y1));
-			int rx1 = Min2(xmax,Max2(x0,x1));
-			int ry1 = Min2(ymax,Max2(y0,y1));
-			if(rx0>=rx1 || ry0>=ry1) return;
-		}
-
-		if (y0 < ymin) y0 = ymin;
-		if (y1 > ymax) y1 = ymax;
-		if (y1 <= y0) return;
-
-		if (x0 < xmin) x0 = xmin;
-		if (x1 > xmax) x1 = xmax;
-		x1 -= x0;
-		if (x1 <= 0) return;
-	}
-	
-	{
-		u16 *Pixel = &((u16*)GPU_FrameBuffer)[FRAME_OFFSET(x0, y0)];
-		const u16 Data = GPU_RGB16(PacketBuffer.U4[0]);
-		const int li=linesInterlace;
-
-		for (; y0<y1; ++y0)
-		{
-			if( 0 == (y0&li) ) gpuTileSpanDriver(Pixel,x1,Data);
-			Pixel += FRAME_WIDTH;
-		}
+	s32 x0, x1, y0, y1;
+
+	// This now matches behavior of Mednafen and PCSX Rearmed's gpu_neon:
+	x0 = GPU_EXPANDSIGN(packet.S2[2] + gpu_unai.DrawingOffset[0]);
+	y0 = GPU_EXPANDSIGN(packet.S2[3] + gpu_unai.DrawingOffset[1]);
+
+	u32 w = packet.U2[4] & 0x3ff; // Max width is 1023
+	u32 h = packet.U2[5] & 0x1ff; // Max height is 511
+	x1 = x0 + w;
+	y1 = y0 + h;
+
+	s32 xmin, xmax, ymin, ymax;
+	xmin = gpu_unai.DrawingArea[0];	xmax = gpu_unai.DrawingArea[2];
+	ymin = gpu_unai.DrawingArea[1];	ymax = gpu_unai.DrawingArea[3];
+
+	if (y0 < ymin) y0 = ymin;
+	if (y1 > ymax) y1 = ymax;
+	if (y1 <= y0) return;
+
+	if (x0 < xmin) x0 = xmin;
+	if (x1 > xmax) x1 = xmax;
+	x1 -= x0;
+	if (x1 <= 0) return;
+
+	const u16 Data = GPU_RGB16(packet.U4[0]);
+	u16 *Pixel = &((u16*)gpu_unai.vram)[FRAME_OFFSET(x0, y0)];
+	const int li=gpu_unai.ilace_mask;
+	const int pi=(ProgressiveInterlaceEnabled()?(gpu_unai.ilace_mask+1):0);
+	const int pif=(ProgressiveInterlaceEnabled()?(gpu_unai.prog_ilace_flag?(gpu_unai.ilace_mask+1):0):1);
+
+	for (; y0<y1; ++y0) {
+		if (!(y0&li) && (y0&pi)!=pif)
+			gpuTileSpanDriver(Pixel,x1,Data);
+		Pixel += FRAME_WIDTH;
 	}
 }
diff --git a/plugins/gpu_unai/gpu_unai.h b/plugins/gpu_unai/gpu_unai.h
new file mode 100644
index 00000000..e8c83adc
--- /dev/null
+++ b/plugins/gpu_unai/gpu_unai.h
@@ -0,0 +1,315 @@
+/***************************************************************************
+*   Copyright (C) 2010 PCSX4ALL Team                                      *
+*   Copyright (C) 2010 Unai                                               *
+*   Copyright (C) 2016 Senquack (dansilsby <AT> gmail <DOT> com)          *
+*                                                                         *
+*   This program is free software; you can redistribute it and/or modify  *
+*   it under the terms of the GNU General Public License as published by  *
+*   the Free Software Foundation; either version 2 of the License, or     *
+*   (at your option) any later version.                                   *
+*                                                                         *
+*   This program is distributed in the hope that it will be useful,       *
+*   but WITHOUT ANY WARRANTY; without even the implied warranty of        *
+*   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the         *
+*   GNU General Public License for more details.                          *
+*                                                                         *
+*   You should have received a copy of the GNU General Public License     *
+*   along with this program; if not, write to the                         *
+*   Free Software Foundation, Inc.,                                       *
+*   51 Franklin Street, Fifth Floor, Boston, MA 02111-1307 USA.           *
+***************************************************************************/
+
+#ifndef GPU_UNAI_H
+#define GPU_UNAI_H
+
+#include "gpu.h"
+
+// Header shared between both standalone gpu_unai (gpu.cpp) and new
+// gpulib-compatible gpu_unai (gpulib_if.cpp)
+// -> Anything here should be for gpu_unai's private use. <-
+
+///////////////////////////////////////////////////////////////////////////////
+//  Compile Options
+
+//#define ENABLE_GPU_NULL_SUPPORT   // Enables NullGPU support
+//#define ENABLE_GPU_LOG_SUPPORT    // Enables gpu logger, very slow only for windows debugging
+//#define ENABLE_GPU_ARMV7			// Enables ARMv7 optimized assembly
+
+//Poly routine options (default is integer math and accurate division)
+//#define GPU_UNAI_USE_FLOATMATH         // Use float math in poly routines
+//#define GPU_UNAI_USE_FLOAT_DIV_MULTINV // If GPU_UNAI_USE_FLOATMATH is defined,
+                                         //  use multiply-by-inverse for division
+//#define GPU_UNAI_USE_INT_DIV_MULTINV   // If GPU_UNAI_USE_FLOATMATH is *not*
+                                         //  defined, use old inaccurate division
+
+
+#define u8  uint8_t
+#define s8  int8_t
+#define u16 uint16_t
+#define s16 int16_t
+#define u32 uint32_t
+#define s32 int32_t
+#define s64 int64_t
+
+union PtrUnion
+{
+	u32  *U4;
+	s32  *S4;
+	u16  *U2;
+	s16  *S2;
+	u8   *U1;
+	s8   *S1;
+	void *ptr;
+};
+
+union GPUPacket
+{
+	u32 U4[16];
+	s32 S4[16];
+	u16 U2[32];
+	s16 S2[32];
+	u8  U1[64];
+	s8  S1[64];
+};
+
+template<class T> static inline void SwapValues(T &x, T &y)
+{
+	T tmp(x);  x = y;  y = tmp;
+}
+
+template<typename T>
+static inline T Min2 (const T a, const T b)
+{
+	return (a<b)?a:b;
+}
+
+template<typename T>
+static inline T Min3 (const T a, const T b, const T c)
+{
+	return  Min2(Min2(a,b),c);
+}
+
+template<typename T>
+static inline T Max2 (const T a, const T b)
+{
+	return  (a>b)?a:b;
+}
+
+template<typename T>
+static inline T Max3 (const T a, const T b, const T c)
+{
+	return  Max2(Max2(a,b),c);
+}
+
+
+///////////////////////////////////////////////////////////////////////////////
+//  GPU Raster Macros
+
+// Convert 24bpp color parameter of GPU command to 16bpp (15bpp + mask bit)
+#define	GPU_RGB16(rgb) ((((rgb)&0xF80000)>>9)|(((rgb)&0xF800)>>6)|(((rgb)&0xF8)>>3))
+
+// Sign-extend 11-bit coordinate command param
+#define GPU_EXPANDSIGN(x) (((s32)(x)<<(32-11))>>(32-11))
+
+// Max difference between any two X or Y primitive coordinates
+#define CHKMAX_X 1024
+#define CHKMAX_Y 512
+
+#define	FRAME_BUFFER_SIZE	(1024*512*2)
+#define	FRAME_WIDTH			  1024
+#define	FRAME_HEIGHT		  512
+#define	FRAME_OFFSET(x,y)	(((y)<<10)+(x))
+#define FRAME_BYTE_STRIDE     2048
+#define FRAME_BYTES_PER_PIXEL 2
+
+static inline s32 GPU_DIV(s32 rs, s32 rt)
+{
+	return rt ? (rs / rt) : (0);
+}
+
+// 'Unsafe' version of above that doesn't check for div-by-zero
+#define GPU_FAST_DIV(rs, rt) ((signed)(rs) / (signed)(rt))
+
+struct gpu_unai_t {
+	u32 GPU_GP1;
+	GPUPacket PacketBuffer;
+	u16 *vram;
+
+	////////////////////////////////////////////////////////////////////////////
+	// Variables used only by older standalone version of gpu_unai (gpu.cpp)
+#ifndef USE_GPULIB
+	u32  GPU_GP0;
+	u32  tex_window;       // Current texture window vals (set by GP0(E2h) cmd)
+	s32  PacketCount;
+	s32  PacketIndex;
+	bool fb_dirty;         // Framebuffer is dirty (according to GPU)
+
+	//  Display status
+	//  NOTE: Standalone older gpu_unai didn't care about horiz display range
+	u16  DisplayArea[6];   // [0] : Start of display area (in VRAM) X
+	                       // [1] : Start of display area (in VRAM) Y
+	                       // [2] : Display mode resolution HORIZONTAL
+	                       // [3] : Display mode resolution VERTICAL
+	                       // [4] : Vertical display range (on TV) START
+	                       // [5] : Vertical display range (on TV) END
+
+	////////////////////////////////////////////////////////////////////////////
+	//  Dma Transfers info
+	struct {
+		s32  px,py;
+		s32  x_end,y_end;
+		u16* pvram;
+		u32 *last_dma;     // Last dma pointer
+		bool FrameToRead;  // Load image in progress
+		bool FrameToWrite; // Store image in progress
+	} dma;
+
+	////////////////////////////////////////////////////////////////////////////
+	//  Frameskip
+	struct {
+		int  skipCount;    // Frame skip (0,1,2,3...)
+		bool isSkip;       // Skip frame (according to GPU)
+		bool skipFrame;    // Skip this frame (according to frame skip)
+		bool wasSkip;      // Skip frame old value (according to GPU)
+		bool skipGPU;      // Skip GPU primitives
+	} frameskip;
+#endif
+	// END of standalone gpu_unai variables
+	////////////////////////////////////////////////////////////////////////////
+
+	u32 TextureWindowCur;  // Current setting from last GP0(0xE2) cmd (raw form)
+	u8  TextureWindow[4];  // [0] : Texture window offset X
+	                       // [1] : Texture window offset Y
+	                       // [2] : Texture window mask X
+	                       // [3] : Texture window mask Y
+
+	u16 DrawingArea[4];    // [0] : Drawing area top left X
+	                       // [1] : Drawing area top left Y
+	                       // [2] : Drawing area bottom right X
+	                       // [3] : Drawing area bottom right Y
+
+	s16 DrawingOffset[2];  // [0] : Drawing offset X (signed)
+	                       // [1] : Drawing offset Y (signed)
+
+	u16* TBA;              // Ptr to current texture in VRAM
+	u16* CBA;              // Ptr to current CLUT in VRAM
+
+	////////////////////////////////////////////////////////////////////////////
+	//  Inner Loop parameters
+
+	// 22.10 Fixed-pt texture coords, mask, scanline advance
+	// NOTE: U,V are no longer packed together into one u32, this proved to be
+	//  too imprecise, leading to pixel dropouts.  Example: NFS3's skybox.
+	u32 u, v;
+	u32 u_msk, v_msk;
+	s32 u_inc, v_inc;
+
+	// Color for Gouraud-shaded prims
+	// Packed fixed-pt 8.3:8.3:8.2 rgb triplet
+	//  layout:  rrrrrrrrXXXggggggggXXXbbbbbbbbXX
+	//           ^ bit 31                       ^ bit 0
+	u32 gCol;
+	u32 gInc;          // Increment along scanline for gCol
+
+	// Color for flat-shaded, texture-blended prims
+	u8  r5, g5, b5;    // 5-bit light for undithered prims
+	u8  r8, g8, b8;    // 8-bit light for dithered prims
+
+	// Color for flat-shaded, untextured prims
+	u16 PixelData;      // bgr555 color for untextured flat-shaded polys
+
+	// End of inner Loop parameters
+	////////////////////////////////////////////////////////////////////////////
+
+
+	u8 blit_mask;           // Determines what pixels to skip when rendering.
+	                        //  Only useful on low-resolution devices using
+	                        //  a simple pixel-dropping downscaler for PS1
+	                        //  high-res modes. See 'pixel_skip' option.
+
+	u8 ilace_mask;          // Determines what lines to skip when rendering.
+	                        //  Normally 0 when PS1 240 vertical res is in
+	                        //  use and ilace_force is 0. When running in
+	                        //  PS1 480 vertical res on a low-resolution
+	                        //  device (320x240), will usually be set to 1
+	                        //  so odd lines are not rendered. (Unless future
+	                        //  full-screen scaling option is in use ..TODO)
+
+	bool prog_ilace_flag;   // Tracks successive frames for 'prog_ilace' option
+
+	u8 BLEND_MODE;
+	u8 TEXT_MODE;
+	u8 Masking;
+
+	u16 PixelMSB;
+
+	gpu_unai_config_t config;
+
+	u8  LightLUT[32*32];    // 5-bit lighting LUT (gpu_inner_light.h)
+	u32 DitherMatrix[64];   // Matrix of dither coefficients
+};
+
+static gpu_unai_t gpu_unai;
+
+// Global config that frontend can alter.. Values are read in GPU_init().
+// TODO: if frontend menu modifies a setting, add a function that can notify
+// GPU plugin to use new setting.
+gpu_unai_config_t gpu_unai_config_ext;
+
+///////////////////////////////////////////////////////////////////////////////
+// Internal inline funcs to get option status: (Allows flexibility)
+static inline bool LightingEnabled()
+{
+	return gpu_unai.config.lighting;
+}
+
+static inline bool FastLightingEnabled()
+{
+	return gpu_unai.config.fast_lighting;
+}
+
+static inline bool BlendingEnabled()
+{
+	return gpu_unai.config.blending;
+}
+
+static inline bool DitheringEnabled()
+{
+	return gpu_unai.config.dithering;
+}
+
+// For now, this is just for development/experimentation purposes..
+// If modified to return true, it will allow ignoring the status register
+//  bit 9 setting (dither enable). It will still restrict dithering only
+//  to Gouraud-shaded or texture-blended polys.
+static inline bool ForcedDitheringEnabled()
+{
+	return false;
+}
+
+static inline bool ProgressiveInterlaceEnabled()
+{
+#ifdef USE_GPULIB
+	// Using this old option greatly decreases quality of image. Disabled
+	//  for now when using new gpulib, since it also adds more work in loops.
+	return false;
+#else
+	return gpu_unai.config.prog_ilace;
+#endif
+}
+
+// For now, 320x240 output resolution is assumed, using simple line-skipping
+//  and pixel-skipping downscaler.
+// TODO: Flesh these out so they return useful values based on whether
+//       running on higher-res device or a resampling downscaler is enabled.
+static inline bool PixelSkipEnabled()
+{
+	return gpu_unai.config.pixel_skip;
+}
+
+static inline bool LineSkipEnabled()
+{
+	return true;
+}
+
+#endif // GPU_UNAI_H
diff --git a/plugins/gpu_unai/gpulib_if.cpp b/plugins/gpu_unai/gpulib_if.cpp
index e9a199c2..d62b53cd 100644
--- a/plugins/gpu_unai/gpulib_if.cpp
+++ b/plugins/gpu_unai/gpulib_if.cpp
@@ -2,6 +2,7 @@
 *   Copyright (C) 2010 PCSX4ALL Team                                      *
 *   Copyright (C) 2010 Unai                                               *
 *   Copyright (C) 2011 notaz                                              *
+*   Copyright (C) 2016 Senquack (dansilsby <AT> gmail <DOT> com)          *
 *                                                                         *
 *   This program is free software; you can redistribute it and/or modify  *
 *   it under the terms of the GNU General Public License as published by  *
@@ -19,140 +20,82 @@
 *   51 Franklin Street, Fifth Floor, Boston, MA 02111-1307 USA.           *
 ***************************************************************************/
 
+#include <stddef.h>
 #include <stdio.h>
 #include <stdlib.h>
 #include <string.h>
 #include "../gpulib/gpu.h"
-#include "arm_features.h"
-
-#define u8 uint8_t
-#define s8 int8_t
-#define u16 uint16_t
-#define s16 int16_t
-#define u32 uint32_t
-#define s32 int32_t
-#define s64 int64_t
-
-#define INLINE static
-
-#define	FRAME_BUFFER_SIZE  (1024*512*2)
-#define	FRAME_WIDTH        1024
-#define	FRAME_HEIGHT       512
-#define	FRAME_OFFSET(x,y)  (((y)<<10)+(x))
-
-#define isSkip 0 /* skip frame (info coming from GPU) */
-#define alt_fps 0
-static int linesInterlace;  /* internal lines interlace */
-static int force_interlace;
-
-static bool light = true; /* lighting */
-static bool blend = true; /* blending */
-static bool FrameToRead = false; /* load image in progress */
-static bool FrameToWrite = false; /* store image in progress */
-
-static bool enableAbbeyHack = false; /* Abe's Odyssey hack */
-
-static u8 BLEND_MODE;
-static u8 TEXT_MODE;
-static u8 Masking;
-
-static u16 PixelMSB;
-static u16 PixelData;
-
-///////////////////////////////////////////////////////////////////////////////
-//  GPU Global data
-///////////////////////////////////////////////////////////////////////////////
-
-//  Dma Transfers info
-static s32		px,py;
-static s32		x_end,y_end;
-static u16*  pvram;
-
-static s32 PacketCount;
-static s32 PacketIndex;
-
-//  Rasterizer status
-static u32 TextureWindow [4];
-static u32 DrawingArea   [4];
-static u32 DrawingOffset [2];
-
-static u16* TBA;
-static u16* CBA;
-
-//  Inner Loops
-static s32   u4, du4;
-static s32   v4, dv4;
-static s32   r4, dr4;
-static s32   g4, dg4;
-static s32   b4, db4;
-static u32   lInc;
-static u32   tInc, tMsk;
-
-union GPUPacket
-{
-	u32 U4[16];
-	s32 S4[16];
-	u16 U2[32];
-	s16 S2[32];
-	u8  U1[64];
-	s8  S1[64];
-};
-
-static GPUPacket PacketBuffer;
-static u16  *GPU_FrameBuffer;
-static u32   GPU_GP1;
-
-///////////////////////////////////////////////////////////////////////////////
-
-#include "../gpu_unai/gpu_fixedpoint.h"
-
-//  Inner loop driver instanciation file
-#include "../gpu_unai/gpu_inner.h"
-
-//  GPU Raster Macros
-#define	GPU_RGB16(rgb)        ((((rgb)&0xF80000)>>9)|(((rgb)&0xF800)>>6)|(((rgb)&0xF8)>>3))
+#include "gpu_unai.h"
 
-#define GPU_EXPANDSIGN(x)  (((s32)(x)<<21)>>21)
+#define GPU_INLINE static inline __attribute__((always_inline))
 
-#define CHKMAX_X 1024
-#define CHKMAX_Y 512
+// GPU fixed point math
+#include "gpu_fixedpoint.h"
 
-#define	GPU_SWAP(a,b,t)	{(t)=(a);(a)=(b);(b)=(t);}
+// Inner loop driver instantiation file
+#include "gpu_inner.h"
 
 // GPU internal image drawing functions
-#include "../gpu_unai/gpu_raster_image.h"
+#include "gpu_raster_image.h"
 
 // GPU internal line drawing functions
-#include "../gpu_unai/gpu_raster_line.h"
+#include "gpu_raster_line.h"
 
 // GPU internal polygon drawing functions
-#include "../gpu_unai/gpu_raster_polygon.h"
+#include "gpu_raster_polygon.h"
 
 // GPU internal sprite drawing functions
-#include "../gpu_unai/gpu_raster_sprite.h"
+#include "gpu_raster_sprite.h"
 
 // GPU command buffer execution/store
-#include "../gpu_unai/gpu_command.h"
+#include "gpu_command.h"
 
 /////////////////////////////////////////////////////////////////////////////
 
 int renderer_init(void)
 {
-	GPU_FrameBuffer = (u16 *)gpu.vram;
-
-	// s_invTable
-	for(int i=1;i<=(1<<TABLE_BITS);++i)
-	{
-		double v = 1.0 / double(i);
-		#ifdef GPU_TABLE_10_BITS
-		v *= double(0xffffffff>>1);
-		#else
-		v *= double(0x80000000);
-		#endif
-		s_invTable[i-1]=s32(v);
-	}
-
-	return 0;
+  memset((void*)&gpu_unai, 0, sizeof(gpu_unai));
+  gpu_unai.vram = (u16*)gpu.vram;
+
+  // Original standalone gpu_unai initialized TextureWindow[]. I added the
+  //  same behavior here, since it seems unsafe to leave [2],[3] unset when
+  //  using HLE and Rearmed gpu_neon sets this similarly on init. -senquack
+  gpu_unai.TextureWindow[0] = 0;
+  gpu_unai.TextureWindow[1] = 0;
+  gpu_unai.TextureWindow[2] = 255;
+  gpu_unai.TextureWindow[3] = 255;
+  //senquack - new vars must be updated whenever texture window is changed:
+  //           (used for polygon-drawing in gpu_inner.h, gpu_raster_polygon.h)
+  const u32 fb = FIXED_BITS;  // # of fractional fixed-pt bits of u4/v4
+  gpu_unai.u_msk = (((u32)gpu_unai.TextureWindow[2]) << fb) | ((1 << fb) - 1);
+  gpu_unai.v_msk = (((u32)gpu_unai.TextureWindow[3]) << fb) | ((1 << fb) - 1);
+
+  // Configuration options
+  gpu_unai.config = gpu_unai_config_ext;
+  //senquack - disabled, not sure this is needed and would require modifying
+  // sprite-span functions, perhaps unnecessarily. No Abe Oddysey hack was
+  // present in latest PCSX4ALL sources we were using.
+  //gpu_unai.config.enableAbbeyHack = gpu_unai_config_ext.abe_hack;
+  gpu_unai.ilace_mask = gpu_unai.config.ilace_force;
+
+#ifdef GPU_UNAI_USE_INT_DIV_MULTINV
+  // s_invTable
+  for(int i=1;i<=(1<<TABLE_BITS);++i)
+  {
+    double v = 1.0 / double(i);
+#ifdef GPU_TABLE_10_BITS
+    v *= double(0xffffffff>>1);
+#else
+    v *= double(0x80000000);
+#endif
+    s_invTable[i-1]=s32(v);
+  }
+#endif
+
+  SetupLightLUT();
+  SetupDitheringConstants();
+
+  return 0;
 }
 
 void renderer_finish(void)
@@ -161,8 +104,115 @@ void renderer_finish(void)
 
 void renderer_notify_res_change(void)
 {
+  if (PixelSkipEnabled()) {
+    // Set blit_mask for high horizontal resolutions. This allows skipping
+    //  rendering pixels that would never get displayed on low-resolution
+    //  platforms that use simple pixel-dropping scaler.
+
+    switch (gpu.screen.hres)
+    {
+      case 512: gpu_unai.blit_mask = 0xa4; break; // GPU_BlitWWSWWSWS
+      case 640: gpu_unai.blit_mask = 0xaa; break; // GPU_BlitWS
+      default:  gpu_unai.blit_mask = 0;    break;
+    }
+  } else {
+    gpu_unai.blit_mask = 0;
+  }
+
+  if (LineSkipEnabled()) {
+    // Set rendering line-skip (only render every other line in high-res
+    //  480 vertical mode, or, optionally, force it for all video modes)
+
+    if (gpu.screen.vres == 480) {
+      if (gpu_unai.config.ilace_force) {
+        gpu_unai.ilace_mask = 3; // Only need 1/4 of lines
+      } else {
+        gpu_unai.ilace_mask = 1; // Only need 1/2 of lines
+      }
+    } else {
+      // Vert resolution changed from 480 to lower one
+      gpu_unai.ilace_mask = gpu_unai.config.ilace_force;
+    }
+  } else {
+    gpu_unai.ilace_mask = 0;
+  }
+
+  /*
+  printf("res change hres: %d   vres: %d   depth: %d   ilace_mask: %d\n",
+      gpu.screen.hres, gpu.screen.vres, gpu.status.rgb24 ? 24 : 15,
+      gpu_unai.ilace_mask);
+  */
 }
 
+#ifdef USE_GPULIB
+// Handles GP0 draw settings commands 0xE1...0xE6
+static void gpuGP0Cmd_0xEx(gpu_unai_t &gpu_unai, u32 cmd_word)
+{
+  // Assume incoming GP0 command is 0xE1..0xE6, convert to 1..6
+  u8 num = (cmd_word >> 24) & 7;
+  gpu.ex_regs[num] = cmd_word; // Update gpulib register
+  switch (num) {
+    case 1: {
+      // GP0(E1h) - Draw Mode setting (aka "Texpage")
+      u32 cur_texpage = gpu_unai.GPU_GP1 & 0x7FF;
+      u32 new_texpage = cmd_word & 0x7FF;
+      if (cur_texpage != new_texpage) {
+        gpu_unai.GPU_GP1 = (gpu_unai.GPU_GP1 & ~0x7FF) | new_texpage;
+        gpuSetTexture(gpu_unai.GPU_GP1);
+      }
+    } break;
+
+    case 2: {
+      // GP0(E2h) - Texture Window setting
+      if (cmd_word != gpu_unai.TextureWindowCur) {
+        static const u8 TextureMask[32] = {
+          255, 7, 15, 7, 31, 7, 15, 7, 63, 7, 15, 7, 31, 7, 15, 7,
+          127, 7, 15, 7, 31, 7, 15, 7, 63, 7, 15, 7, 31, 7, 15, 7
+        };
+        gpu_unai.TextureWindowCur = cmd_word;
+        gpu_unai.TextureWindow[0] = ((cmd_word >> 10) & 0x1F) << 3;
+        gpu_unai.TextureWindow[1] = ((cmd_word >> 15) & 0x1F) << 3;
+        gpu_unai.TextureWindow[2] = TextureMask[(cmd_word >> 0) & 0x1F];
+        gpu_unai.TextureWindow[3] = TextureMask[(cmd_word >> 5) & 0x1F];
+        gpu_unai.TextureWindow[0] &= ~gpu_unai.TextureWindow[2];
+        gpu_unai.TextureWindow[1] &= ~gpu_unai.TextureWindow[3];
+
+        // Inner loop vars must be updated whenever texture window is changed:
+        const u32 fb = FIXED_BITS;  // # of fractional fixed-pt bits of u4/v4
+        gpu_unai.u_msk = (((u32)gpu_unai.TextureWindow[2]) << fb) | ((1 << fb) - 1);
+        gpu_unai.v_msk = (((u32)gpu_unai.TextureWindow[3]) << fb) | ((1 << fb) - 1);
+
+        gpuSetTexture(gpu_unai.GPU_GP1);
+      }
+    } break;
+
+    case 3: {
+      // GP0(E3h) - Set Drawing Area top left (X1,Y1)
+      gpu_unai.DrawingArea[0] = cmd_word         & 0x3FF;
+      gpu_unai.DrawingArea[1] = (cmd_word >> 10) & 0x3FF;
+    } break;
+
+    case 4: {
+      // GP0(E4h) - Set Drawing Area bottom right (X2,Y2)
+      gpu_unai.DrawingArea[2] = (cmd_word         & 0x3FF) + 1;
+      gpu_unai.DrawingArea[3] = ((cmd_word >> 10) & 0x3FF) + 1;
+    } break;
+
+    case 5: {
+      // GP0(E5h) - Set Drawing Offset (X,Y)
+      gpu_unai.DrawingOffset[0] = ((s32)cmd_word<<(32-11))>>(32-11);
+      gpu_unai.DrawingOffset[1] = ((s32)cmd_word<<(32-22))>>(32-11);
+    } break;
+
+    case 6: {
+      // GP0(E6h) - Mask Bit Setting
+      gpu_unai.Masking  = (cmd_word & 0x2) <<  1;
+      gpu_unai.PixelMSB = (cmd_word & 0x1) <<  8;
+    } break;
+  }
+}
+#endif
+
 extern const unsigned char cmd_lengths[256];
 
 int do_cmd_list(u32 *list, int list_len, int *last_cmd)
@@ -171,9 +221,12 @@ int do_cmd_list(u32 *list, int list_len, int *last_cmd)
   u32 *list_start = list;
   u32 *list_end = list + list_len;
 
-  linesInterlace = force_interlace;
+  //TODO: set ilace_mask when resolution changes instead of every time,
+  // eliminate #ifdef below.
+  gpu_unai.ilace_mask = gpu_unai.config.ilace_force;
+
 #ifdef HAVE_PRE_ARMV7 /* XXX */
-  linesInterlace |= gpu.status.interlace;
+  gpu_unai.ilace_mask |= gpu.status.interlace;
 #endif
 
   for (; list < list_end; list += 1 + len)
@@ -186,126 +239,175 @@ int do_cmd_list(u32 *list, int list_len, int *last_cmd)
     }
 
     #define PRIM cmd
-    PacketBuffer.U4[0] = list[0];
+    gpu_unai.PacketBuffer.U4[0] = list[0];
     for (i = 1; i <= len; i++)
-      PacketBuffer.U4[i] = list[i];
+      gpu_unai.PacketBuffer.U4[i] = list[i];
+
+    PtrUnion packet = { .ptr = (void*)&gpu_unai.PacketBuffer };
 
     switch (cmd)
     {
       case 0x02:
-        gpuClearImage();
+        gpuClearImage(packet);
         break;
 
       case 0x20:
       case 0x21:
       case 0x22:
-      case 0x23:
-        gpuDrawF3(gpuPolySpanDrivers [Blending_Mode | Masking | Blending | PixelMSB]);
-        break;
+      case 0x23: {          // Monochrome 3-pt poly
+        PP driver = gpuPolySpanDrivers[
+          (gpu_unai.blit_mask?1024:0) |
+          Blending_Mode |
+          gpu_unai.Masking | Blending | gpu_unai.PixelMSB
+        ];
+        gpuDrawPolyF(packet, driver, false);
+      } break;
 
       case 0x24:
       case 0x25:
       case 0x26:
-      case 0x27:
-        gpuSetCLUT   (PacketBuffer.U4[2] >> 16);
-        gpuSetTexture(PacketBuffer.U4[4] >> 16);
-        if ((PacketBuffer.U1[0]>0x5F) && (PacketBuffer.U1[1]>0x5F) && (PacketBuffer.U1[2]>0x5F))
-          gpuDrawFT3(gpuPolySpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | PixelMSB]);
-        else
-          gpuDrawFT3(gpuPolySpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | Lighting | PixelMSB]);
-        break;
+      case 0x27: {          // Textured 3-pt poly
+        gpuSetCLUT   (gpu_unai.PacketBuffer.U4[2] >> 16);
+        gpuSetTexture(gpu_unai.PacketBuffer.U4[4] >> 16);
+
+        u32 driver_idx =
+          (gpu_unai.blit_mask?1024:0) |
+          Dithering |
+          Blending_Mode | gpu_unai.TEXT_MODE |
+          gpu_unai.Masking | Blending | gpu_unai.PixelMSB;
+
+        if (!FastLightingEnabled()) {
+          driver_idx |= Lighting;
+        } else {
+          if (!((gpu_unai.PacketBuffer.U1[0]>0x5F) && (gpu_unai.PacketBuffer.U1[1]>0x5F) && (gpu_unai.PacketBuffer.U1[2]>0x5F)))
+            driver_idx |= Lighting;
+        }
+
+        PP driver = gpuPolySpanDrivers[driver_idx];
+        gpuDrawPolyFT(packet, driver, false);
+      } break;
 
       case 0x28:
       case 0x29:
       case 0x2A:
-      case 0x2B: {
-        const PP gpuPolySpanDriver = gpuPolySpanDrivers [Blending_Mode | Masking | Blending | PixelMSB];
-        gpuDrawF3(gpuPolySpanDriver);
-        PacketBuffer.U4[1] = PacketBuffer.U4[4];
-        gpuDrawF3(gpuPolySpanDriver);
-        break;
-      }
+      case 0x2B: {          // Monochrome 4-pt poly
+        PP driver = gpuPolySpanDrivers[
+          (gpu_unai.blit_mask?1024:0) |
+          Blending_Mode |
+          gpu_unai.Masking | Blending | gpu_unai.PixelMSB
+        ];
+        gpuDrawPolyF(packet, driver, true); // is_quad = true
+      } break;
 
       case 0x2C:
       case 0x2D:
       case 0x2E:
-      case 0x2F: {
-        gpuSetCLUT   (PacketBuffer.U4[2] >> 16);
-        gpuSetTexture(PacketBuffer.U4[4] >> 16);
-        PP gpuPolySpanDriver;
-        if ((PacketBuffer.U1[0]>0x5F) && (PacketBuffer.U1[1]>0x5F) && (PacketBuffer.U1[2]>0x5F))
-          gpuPolySpanDriver = gpuPolySpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | PixelMSB];
-        else
-          gpuPolySpanDriver = gpuPolySpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | Lighting | PixelMSB];
-        gpuDrawFT3(gpuPolySpanDriver);
-        PacketBuffer.U4[1] = PacketBuffer.U4[7];
-        PacketBuffer.U4[2] = PacketBuffer.U4[8];
-        gpuDrawFT3(gpuPolySpanDriver);
-        break;
-      }
+      case 0x2F: {          // Textured 4-pt poly
+        gpuSetCLUT   (gpu_unai.PacketBuffer.U4[2] >> 16);
+        gpuSetTexture(gpu_unai.PacketBuffer.U4[4] >> 16);
+
+        u32 driver_idx =
+          (gpu_unai.blit_mask?1024:0) |
+          Dithering |
+          Blending_Mode | gpu_unai.TEXT_MODE |
+          gpu_unai.Masking | Blending | gpu_unai.PixelMSB;
+
+        if (!FastLightingEnabled()) {
+          driver_idx |= Lighting;
+        } else {
+          if (!((gpu_unai.PacketBuffer.U1[0]>0x5F) && (gpu_unai.PacketBuffer.U1[1]>0x5F) && (gpu_unai.PacketBuffer.U1[2]>0x5F)))
+            driver_idx |= Lighting;
+        }
+
+        PP driver = gpuPolySpanDrivers[driver_idx];
+        gpuDrawPolyFT(packet, driver, true); // is_quad = true
+      } break;
 
       case 0x30:
       case 0x31:
       case 0x32:
-      case 0x33:
-        gpuDrawG3(gpuPolySpanDrivers [Blending_Mode | Masking | Blending | 129 | PixelMSB]);
-        break;
+      case 0x33: {          // Gouraud-shaded 3-pt poly
+        //NOTE: The '129' here is CF_GOURAUD | CF_LIGHT, however
+        // this is an untextured poly, so CF_LIGHT (texture blend)
+        // shouldn't apply. Until the original array of template
+        // instantiation ptrs is fixed, we're stuck with this. (TODO)
+        PP driver = gpuPolySpanDrivers[
+          (gpu_unai.blit_mask?1024:0) |
+          Dithering |
+          Blending_Mode |
+          gpu_unai.Masking | Blending | 129 | gpu_unai.PixelMSB
+        ];
+        gpuDrawPolyG(packet, driver, false);
+      } break;
 
       case 0x34:
       case 0x35:
       case 0x36:
-      case 0x37:
-        gpuSetCLUT    (PacketBuffer.U4[2] >> 16);
-        gpuSetTexture (PacketBuffer.U4[5] >> 16);
-        gpuDrawGT3(gpuPolySpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | ((Lighting)?129:0) | PixelMSB]);
-        break;
+      case 0x37: {          // Gouraud-shaded, textured 3-pt poly
+        gpuSetCLUT    (gpu_unai.PacketBuffer.U4[2] >> 16);
+        gpuSetTexture (gpu_unai.PacketBuffer.U4[5] >> 16);
+        PP driver = gpuPolySpanDrivers[
+          (gpu_unai.blit_mask?1024:0) |
+          Dithering |
+          Blending_Mode | gpu_unai.TEXT_MODE |
+          gpu_unai.Masking | Blending | ((Lighting)?129:0) | gpu_unai.PixelMSB
+        ];
+        gpuDrawPolyGT(packet, driver, false);
+      } break;
 
       case 0x38:
       case 0x39:
       case 0x3A:
-      case 0x3B: {
-        const PP gpuPolySpanDriver  = gpuPolySpanDrivers [Blending_Mode | Masking | Blending | 129 | PixelMSB];
-        gpuDrawG3(gpuPolySpanDriver);
-        PacketBuffer.U4[0] = PacketBuffer.U4[6];
-        PacketBuffer.U4[1] = PacketBuffer.U4[7];
-        gpuDrawG3(gpuPolySpanDriver);
-        break;
-      }
+      case 0x3B: {          // Gouraud-shaded 4-pt poly
+        // See notes regarding '129' for 0x30..0x33 further above -senquack
+        PP driver = gpuPolySpanDrivers[
+          (gpu_unai.blit_mask?1024:0) |
+          Dithering |
+          Blending_Mode |
+          gpu_unai.Masking | Blending | 129 | gpu_unai.PixelMSB
+        ];
+        gpuDrawPolyG(packet, driver, true); // is_quad = true
+      } break;
 
       case 0x3C:
       case 0x3D:
       case 0x3E:
-      case 0x3F: {
-        gpuSetCLUT    (PacketBuffer.U4[2] >> 16);
-        gpuSetTexture (PacketBuffer.U4[5] >> 16);
-        const PP gpuPolySpanDriver  = gpuPolySpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | ((Lighting)?129:0) | PixelMSB];
-        gpuDrawGT3(gpuPolySpanDriver);
-        PacketBuffer.U4[0] = PacketBuffer.U4[9];
-        PacketBuffer.U4[1] = PacketBuffer.U4[10];
-        PacketBuffer.U4[2] = PacketBuffer.U4[11];
-        gpuDrawGT3(gpuPolySpanDriver);
-        break;
-      }
+      case 0x3F: {          // Gouraud-shaded, textured 4-pt poly
+        gpuSetCLUT    (gpu_unai.PacketBuffer.U4[2] >> 16);
+        gpuSetTexture (gpu_unai.PacketBuffer.U4[5] >> 16);
+        PP driver = gpuPolySpanDrivers[
+          (gpu_unai.blit_mask?1024:0) |
+          Dithering |
+          Blending_Mode | gpu_unai.TEXT_MODE |
+          gpu_unai.Masking | Blending | ((Lighting)?129:0) | gpu_unai.PixelMSB
+        ];
+        gpuDrawPolyGT(packet, driver, true); // is_quad = true
+      } break;
 
       case 0x40:
       case 0x41:
       case 0x42:
-      case 0x43:
-        gpuDrawLF(gpuPixelDrivers [ (Blending_Mode | Masking | Blending | (PixelMSB>>3)) >> 1]);
-        break;
-
-      case 0x48 ... 0x4F:
-      {
+      case 0x43: {          // Monochrome line
+        // Shift index right by one, as untextured prims don't use lighting
+        u32 driver_idx = (Blending_Mode | gpu_unai.Masking | Blending | (gpu_unai.PixelMSB>>3)) >> 1;
+        PSD driver = gpuPixelSpanDrivers[driver_idx];
+        gpuDrawLineF(packet, driver);
+      } break;
+
+      case 0x48 ... 0x4F: { // Monochrome line strip
         u32 num_vertexes = 1;
         u32 *list_position = &(list[2]);
 
-        gpuDrawLF(gpuPixelDrivers [ (Blending_Mode | Masking | Blending | (PixelMSB>>3)) >> 1]);
+        // Shift index right by one, as untextured prims don't use lighting
+        u32 driver_idx = (Blending_Mode | gpu_unai.Masking | Blending | (gpu_unai.PixelMSB>>3)) >> 1;
+        PSD driver = gpuPixelSpanDrivers[driver_idx];
+        gpuDrawLineF(packet, driver);
 
         while(1)
         {
-          PacketBuffer.U4[1] = PacketBuffer.U4[2];
-          PacketBuffer.U4[2] = *list_position++;
-          gpuDrawLF(gpuPixelDrivers [ (Blending_Mode | Masking | Blending | (PixelMSB>>3)) >> 1]);
+          gpu_unai.PacketBuffer.U4[1] = gpu_unai.PacketBuffer.U4[2];
+          gpu_unai.PacketBuffer.U4[2] = *list_position++;
+          gpuDrawLineF(packet, driver);
 
           num_vertexes++;
           if(list_position >= list_end) {
@@ -317,30 +419,38 @@ int do_cmd_list(u32 *list, int list_len, int *last_cmd)
         }
 
         len += (num_vertexes - 2);
-        break;
-      }
+      } break;
 
       case 0x50:
       case 0x51:
       case 0x52:
-      case 0x53:
-        gpuDrawLG(gpuPixelDrivers [ (Blending_Mode | Masking | Blending | (PixelMSB>>3)) >> 1]);
-        break;
-
-      case 0x58 ... 0x5F:
-      {
+      case 0x53: {          // Gouraud-shaded line
+        // Shift index right by one, as untextured prims don't use lighting
+        u32 driver_idx = (Blending_Mode | gpu_unai.Masking | Blending | (gpu_unai.PixelMSB>>3)) >> 1;
+        // Index MSB selects Gouraud-shaded PixelSpanDriver:
+        driver_idx |= (1 << 5);
+        PSD driver = gpuPixelSpanDrivers[driver_idx];
+        gpuDrawLineG(packet, driver);
+      } break;
+
+      case 0x58 ... 0x5F: { // Gouraud-shaded line strip
         u32 num_vertexes = 1;
         u32 *list_position = &(list[2]);
 
-        gpuDrawLG(gpuPixelDrivers [ (Blending_Mode | Masking | Blending | (PixelMSB>>3)) >> 1]);
+        // Shift index right by one, as untextured prims don't use lighting
+        u32 driver_idx = (Blending_Mode | gpu_unai.Masking | Blending | (gpu_unai.PixelMSB>>3)) >> 1;
+        // Index MSB selects Gouraud-shaded PixelSpanDriver:
+        driver_idx |= (1 << 5);
+        PSD driver = gpuPixelSpanDrivers[driver_idx];
+        gpuDrawLineG(packet, driver);
 
         while(1)
         {
-          PacketBuffer.U4[0] = PacketBuffer.U4[2];
-          PacketBuffer.U4[1] = PacketBuffer.U4[3];
-          PacketBuffer.U4[2] = *list_position++;
-          PacketBuffer.U4[3] = *list_position++;
-          gpuDrawLG(gpuPixelDrivers [ (Blending_Mode | Masking | Blending | (PixelMSB>>3)) >> 1]);
+          gpu_unai.PacketBuffer.U4[0] = gpu_unai.PacketBuffer.U4[2];
+          gpu_unai.PacketBuffer.U4[1] = gpu_unai.PacketBuffer.U4[3];
+          gpu_unai.PacketBuffer.U4[2] = *list_position++;
+          gpu_unai.PacketBuffer.U4[3] = *list_position++;
+          gpuDrawLineG(packet, driver);
 
           num_vertexes++;
           if(list_position >= list_end) {
@@ -352,91 +462,116 @@ int do_cmd_list(u32 *list, int list_len, int *last_cmd)
         }
 
         len += (num_vertexes - 2) * 2;
-        break;
-      }
+      } break;
 
       case 0x60:
       case 0x61:
       case 0x62:
-      case 0x63:
-        gpuDrawT(gpuTileSpanDrivers [Blending_Mode | Masking | Blending | (PixelMSB>>3)]);
-        break;
+      case 0x63: {          // Monochrome rectangle (variable size)
+        PT driver = gpuTileSpanDrivers[(Blending_Mode | gpu_unai.Masking | Blending | (gpu_unai.PixelMSB>>3)) >> 1];
+        gpuDrawT(packet, driver);
+      } break;
 
       case 0x64:
       case 0x65:
       case 0x66:
-      case 0x67:
-        gpuSetCLUT    (PacketBuffer.U4[2] >> 16);
-        gpuSetTexture (GPU_GP1);
-        if ((PacketBuffer.U1[0]>0x5F) && (PacketBuffer.U1[1]>0x5F) && (PacketBuffer.U1[2]>0x5F))
-          gpuDrawS(gpuSpriteSpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | (enableAbbeyHack<<7)  | PixelMSB]);
-        else
-          gpuDrawS(gpuSpriteSpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | Lighting | (enableAbbeyHack<<7)  | PixelMSB]);
-        break;
+      case 0x67: {          // Textured rectangle (variable size)
+        gpuSetCLUT    (gpu_unai.PacketBuffer.U4[2] >> 16);
+        u32 driver_idx = Blending_Mode | gpu_unai.TEXT_MODE | gpu_unai.Masking | Blending | (gpu_unai.PixelMSB>>1);
+
+        //senquack - Only color 808080h-878787h allows skipping lighting calculation:
+        // This fixes Silent Hill running animation on loading screens:
+        // (On PSX, color values 0x00-0x7F darken the source texture's color,
+        //  0x81-FF lighten textures (ultimately clamped to 0x1F),
+        //  0x80 leaves source texture color unchanged, HOWEVER,
+        //   gpu_unai uses a simple lighting LUT whereby only the upper
+        //   5 bits of an 8-bit color are used, so 0x80-0x87 all behave as
+        //   0x80.
+        // 
+        // NOTE: I've changed all textured sprite draw commands here and
+        //  elsewhere to use proper behavior, but left poly commands
+        //  alone, I don't want to slow rendering down too much. (TODO)
+        //if ((gpu_unai.PacketBuffer.U1[0]>0x5F) && (gpu_unai.PacketBuffer.U1[1]>0x5F) && (gpu_unai.PacketBuffer.U1[2]>0x5F))
+        // Strip lower 3 bits of each color and determine if lighting should be used:
+        if ((gpu_unai.PacketBuffer.U4[0] & 0xF8F8F8) != 0x808080)
+          driver_idx |= Lighting;
+        PS driver = gpuSpriteSpanDrivers[driver_idx];
+        gpuDrawS(packet, driver);
+      } break;
 
       case 0x68:
       case 0x69:
       case 0x6A:
-      case 0x6B:
-        PacketBuffer.U4[2] = 0x00010001;
-        gpuDrawT(gpuTileSpanDrivers [Blending_Mode | Masking | Blending | (PixelMSB>>3)]);
-        break;
+      case 0x6B: {          // Monochrome rectangle (1x1 dot)
+        gpu_unai.PacketBuffer.U4[2] = 0x00010001;
+        PT driver = gpuTileSpanDrivers[(Blending_Mode | gpu_unai.Masking | Blending | (gpu_unai.PixelMSB>>3)) >> 1];
+        gpuDrawT(packet, driver);
+      } break;
 
       case 0x70:
       case 0x71:
       case 0x72:
-      case 0x73:
-        PacketBuffer.U4[2] = 0x00080008;
-        gpuDrawT(gpuTileSpanDrivers [Blending_Mode | Masking | Blending | (PixelMSB>>3)]);
-        break;
+      case 0x73: {          // Monochrome rectangle (8x8)
+        gpu_unai.PacketBuffer.U4[2] = 0x00080008;
+        PT driver = gpuTileSpanDrivers[(Blending_Mode | gpu_unai.Masking | Blending | (gpu_unai.PixelMSB>>3)) >> 1];
+        gpuDrawT(packet, driver);
+      } break;
 
       case 0x74:
       case 0x75:
       case 0x76:
-      case 0x77:
-        PacketBuffer.U4[3] = 0x00080008;
-        gpuSetCLUT    (PacketBuffer.U4[2] >> 16);
-        gpuSetTexture (GPU_GP1);
-        if ((PacketBuffer.U1[0]>0x5F) && (PacketBuffer.U1[1]>0x5F) && (PacketBuffer.U1[2]>0x5F))
-          gpuDrawS(gpuSpriteSpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | (enableAbbeyHack<<7)  | PixelMSB]);
-        else
-          gpuDrawS(gpuSpriteSpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | Lighting | (enableAbbeyHack<<7)  | PixelMSB]);
-        break;
+      case 0x77: {          // Textured rectangle (8x8)
+        gpu_unai.PacketBuffer.U4[3] = 0x00080008;
+        gpuSetCLUT    (gpu_unai.PacketBuffer.U4[2] >> 16);
+        u32 driver_idx = Blending_Mode | gpu_unai.TEXT_MODE | gpu_unai.Masking | Blending | (gpu_unai.PixelMSB>>1);
+
+        //senquack - Only color 808080h-878787h allows skipping lighting calculation:
+        //if ((gpu_unai.PacketBuffer.U1[0]>0x5F) && (gpu_unai.PacketBuffer.U1[1]>0x5F) && (gpu_unai.PacketBuffer.U1[2]>0x5F))
+        // Strip lower 3 bits of each color and determine if lighting should be used:
+        if ((gpu_unai.PacketBuffer.U4[0] & 0xF8F8F8) != 0x808080)
+          driver_idx |= Lighting;
+        PS driver = gpuSpriteSpanDrivers[driver_idx];
+        gpuDrawS(packet, driver);
+      } break;
 
       case 0x78:
       case 0x79:
       case 0x7A:
-      case 0x7B:
-        PacketBuffer.U4[2] = 0x00100010;
-        gpuDrawT(gpuTileSpanDrivers [Blending_Mode | Masking | Blending | (PixelMSB>>3)]);
-        break;
+      case 0x7B: {          // Monochrome rectangle (16x16)
+        gpu_unai.PacketBuffer.U4[2] = 0x00100010;
+        PT driver = gpuTileSpanDrivers[(Blending_Mode | gpu_unai.Masking | Blending | (gpu_unai.PixelMSB>>3)) >> 1];
+        gpuDrawT(packet, driver);
+      } break;
 
       case 0x7C:
       case 0x7D:
 #ifdef __arm__
-        if ((GPU_GP1 & 0x180) == 0 && (Masking | PixelMSB) == 0)
+        if ((gpu_unai.GPU_GP1 & 0x180) == 0 && (gpu_unai.Masking | gpu_unai.PixelMSB) == 0)
         {
-          gpuSetCLUT    (PacketBuffer.U4[2] >> 16);
-          gpuSetTexture (GPU_GP1);
-          gpuDrawS16();
+          gpuSetCLUT    (gpu_unai.PacketBuffer.U4[2] >> 16);
+          gpuDrawS16(packet);
           break;
         }
         // fallthrough
 #endif
       case 0x7E:
-      case 0x7F:
-        PacketBuffer.U4[3] = 0x00100010;
-        gpuSetCLUT    (PacketBuffer.U4[2] >> 16);
-        gpuSetTexture (GPU_GP1);
-        if ((PacketBuffer.U1[0]>0x5F) && (PacketBuffer.U1[1]>0x5F) && (PacketBuffer.U1[2]>0x5F))
-          gpuDrawS(gpuSpriteSpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | (enableAbbeyHack<<7)  | PixelMSB]);
-        else
-          gpuDrawS(gpuSpriteSpanDrivers [Blending_Mode | TEXT_MODE | Masking | Blending | Lighting | (enableAbbeyHack<<7)  | PixelMSB]);
-        break;
+      case 0x7F: {          // Textured rectangle (16x16)
+        gpu_unai.PacketBuffer.U4[3] = 0x00100010;
+        gpuSetCLUT    (gpu_unai.PacketBuffer.U4[2] >> 16);
+        u32 driver_idx = Blending_Mode | gpu_unai.TEXT_MODE | gpu_unai.Masking | Blending | (gpu_unai.PixelMSB>>1);
+        //senquack - Only color 808080h-878787h allows skipping lighting calculation:
+        //if ((gpu_unai.PacketBuffer.U1[0]>0x5F) && (gpu_unai.PacketBuffer.U1[1]>0x5F) && (gpu_unai.PacketBuffer.U1[2]>0x5F))
+        // Strip lower 3 bits of each color and determine if lighting should be used:
+        if ((gpu_unai.PacketBuffer.U4[0] & 0xF8F8F8) != 0x808080)
+          driver_idx |= Lighting;
+        PS driver = gpuSpriteSpanDrivers[driver_idx];
+        gpuDrawS(packet, driver);
+      } break;
 
       case 0x80:          //  vid -> vid
-        gpuMoveImage();   //  prim handles updateLace && skip
+        gpuMoveImage(packet);
         break;
+
 #ifdef TEST
       case 0xA0:          //  sys -> vid
       {
@@ -445,70 +580,25 @@ int do_cmd_list(u32 *list, int list_len, int *last_cmd)
         u32 load_size = load_width * load_height;
 
         len += load_size / 2;
-        break;
-      }
+      } break;
+
       case 0xC0:
         break;
 #else
       case 0xA0:          //  sys ->vid
       case 0xC0:          //  vid -> sys
+        // Handled by gpulib
         goto breakloop;
 #endif
-      case 0xE1: {
-        const u32 temp = PacketBuffer.U4[0];
-        GPU_GP1 = (GPU_GP1 & ~0x000007FF) | (temp & 0x000007FF);
-        gpuSetTexture(temp);
-        gpu.ex_regs[1] = temp;
-        break;
-      }
-      case 0xE2: {
-        static const u8  TextureMask[32] = {
-          255, 7, 15, 7, 31, 7, 15, 7, 63, 7, 15, 7, 31, 7, 15, 7,
-          127, 7, 15, 7, 31, 7, 15, 7, 63, 7, 15, 7, 31, 7, 15, 7
-        };
-        const u32 temp = PacketBuffer.U4[0];
-        TextureWindow[0] = ((temp >> 10) & 0x1F) << 3;
-        TextureWindow[1] = ((temp >> 15) & 0x1F) << 3;
-        TextureWindow[2] = TextureMask[(temp >> 0) & 0x1F];
-        TextureWindow[3] = TextureMask[(temp >> 5) & 0x1F];
-        gpuSetTexture(GPU_GP1);
-        gpu.ex_regs[2] = temp;
-        break;
-      }
-      case 0xE3: {
-        const u32 temp = PacketBuffer.U4[0];
-        DrawingArea[0] = temp         & 0x3FF;
-        DrawingArea[1] = (temp >> 10) & 0x3FF;
-        gpu.ex_regs[3] = temp;
-        break;
-      }
-      case 0xE4: {
-        const u32 temp = PacketBuffer.U4[0];
-        DrawingArea[2] = (temp         & 0x3FF) + 1;
-        DrawingArea[3] = ((temp >> 10) & 0x3FF) + 1;
-        gpu.ex_regs[4] = temp;
-        break;
-      }
-      case 0xE5: {
-        const u32 temp = PacketBuffer.U4[0];
-        DrawingOffset[0] = ((s32)temp<<(32-11))>>(32-11);
-        DrawingOffset[1] = ((s32)temp<<(32-22))>>(32-11);
-        gpu.ex_regs[5] = temp;
-        break;
-      }
-      case 0xE6: {
-        const u32 temp = PacketBuffer.U4[0];
-        Masking = (temp & 0x2) <<  1;
-        PixelMSB =(temp & 0x1) <<  8;
-        gpu.ex_regs[6] = temp;
-        break;
-      }
+      case 0xE1 ... 0xE6: { // Draw settings
+        gpuGP0Cmd_0xEx(gpu_unai, gpu_unai.PacketBuffer.U4[0]);
+      } break;
     }
   }
 
 breakloop:
   gpu.ex_regs[1] &= ~0x1ff;
-  gpu.ex_regs[1] |= GPU_GP1 & 0x1ff;
+  gpu.ex_regs[1] |= gpu_unai.GPU_GP1 & 0x1ff;
 
   *last_cmd = cmd;
   return list - list_start;
@@ -532,20 +622,20 @@ void renderer_set_interlace(int enable, int is_odd)
 {
 }
 
-#ifndef TEST
-
-#include "../../frontend/plugin_lib.h"
-
+#include "../frontend/plugin_lib.h"
+// Handle any gpulib settings applicable to gpu_unai:
+//void renderer_set_config(const gpulib_config_t *config)
 void renderer_set_config(const struct rearmed_cbs *cbs)
 {
-  force_interlace = cbs->gpu_unai.lineskip;
-  enableAbbeyHack = cbs->gpu_unai.abe_hack;
-  light = !cbs->gpu_unai.no_light;
-  blend = !cbs->gpu_unai.no_blend;
-
-  GPU_FrameBuffer = (u16 *)gpu.vram;
+  gpu_unai.vram = (u16*)gpu.vram;
+  gpu_unai.config.lighting = !cbs->gpu_unai.no_light;
+  gpu_unai.config.blending = !cbs->gpu_unai.no_blend;
+  //force_interlace = cbs->gpu_unai.lineskip;
+  //enableAbbeyHack = cbs->gpu_unai.abe_hack;
+  //light = !cbs->gpu_unai.no_light;
+  //blend = !cbs->gpu_unai.no_blend;
+
+  //GPU_FrameBuffer = (u16 *)gpu.vram;
 }
 
-#endif
-
 // vim:shiftwidth=2:expandtab
diff --git a/plugins/gpu_unai/port.h b/plugins/gpu_unai/port.h
deleted file mode 100644
index 238b98bc..00000000
--- a/plugins/gpu_unai/port.h
+++ /dev/null
@@ -1,36 +0,0 @@
-#include <stddef.h>
-#include <string.h>
-
-#define INLINE static inline
-
-#define GPU_init	GPUinit
-#define GPU_shutdown	GPUshutdown
-//#define GPU_freeze	GPUfreeze
-#define GPU_writeDataMem GPUwriteDataMem
-#define GPU_dmaChain	GPUdmaChain
-#define GPU_writeData	GPUwriteData
-#define GPU_readDataMem	GPUreadDataMem
-#define GPU_readData	GPUreadData
-#define GPU_readStatus	GPUreadStatus
-#define GPU_writeStatus	GPUwriteStatus
-#define GPU_updateLace	GPUupdateLace
-
-extern "C" {
-
-#define u32 unsigned int
-#define s32 signed int
-
-bool GPUinit(void);
-void GPUshutdown(void);
-void GPUwriteDataMem(u32* dmaAddress, s32 dmaCount);
-long GPUdmaChain(u32* baseAddr, u32 dmaVAddr);
-void GPUwriteData(u32 data);
-void GPUreadDataMem(u32* dmaAddress, s32 dmaCount);
-u32  GPUreadData(void);
-u32  GPUreadStatus(void);
-void GPUwriteStatus(u32 data);
-
-#undef u32
-#undef s32
-
-}
diff --git a/plugins/gpu_unai/profiler.h b/plugins/gpu_unai/profiler.h
deleted file mode 100644
index c09c95f5..00000000
--- a/plugins/gpu_unai/profiler.h
+++ /dev/null
@@ -1,4 +0,0 @@
-#define pcsx4all_prof_pause(...)
-#define pcsx4all_prof_start_with_pause(...)
-#define pcsx4all_prof_end_with_resume(...)
-#define pcsx4all_prof_resume(...)
diff --git a/plugins/gpulib/gpu.c b/plugins/gpulib/gpu.c
index 9fc5f430..d79e121d 100644
--- a/plugins/gpulib/gpu.c
+++ b/plugins/gpulib/gpu.c
@@ -10,6 +10,7 @@
 
 #include <stdio.h>
 #include <string.h>
+//#include "../../libpcsxcore/plugins.h"    // For GPUFreeze_t, GPUScreenInfo_t
 #include "gpu.h"
 
 #define ARRAY_SIZE(x) (sizeof(x) / sizeof((x)[0]))
@@ -65,6 +66,8 @@ static noinline void do_reset(void)
 
 static noinline void update_width(void)
 {
+  int old_width = gpu.screen.w;
+
   int sw = gpu.screen.x2 - gpu.screen.x1;
   if (sw <= 0 || sw >= 2560)
     // full width
@@ -76,6 +79,7 @@ static noinline void update_width(void)
 static noinline void update_height(void)
 {
   // TODO: emulate this properly..
+  int old_height = gpu.screen.h;
   int sh = gpu.screen.y2 - gpu.screen.y1;
   if (gpu.status.dheight)
     sh *= 2;
@@ -126,11 +130,11 @@ static noinline void get_gpu_info(uint32_t data)
     case 0x02:
     case 0x03:
     case 0x04:
-    case 0x05:
       gpu.gp0 = gpu.ex_regs[data & 7] & 0xfffff;
       break;
+    case 0x05:
     case 0x06:
-      gpu.gp0 = gpu.ex_regs[5] & 0xfffff;
+      gpu.gp0 = gpu.ex_regs[5] & 0x3fffff;
       break;
     case 0x07:
       gpu.gp0 = 2;
@@ -141,14 +145,31 @@ static noinline void get_gpu_info(uint32_t data)
   }
 }
 
-// double, for overdraw guard
-#define VRAM_SIZE (1024 * 512 * 2 * 2)
+// double, for overdraw guard, plus 4kb front guard,
+#define VRAM_SIZE ((1024 * 512 * 2 * 2) + 4096)
 
+//  Minimum 16-byte VRAM alignment needed by gpu_unai's pixel-skipping
+//  renderer/downscaler it uses in high res modes:
+#ifdef GCW_ZERO
+	// On GCW platform (MIPS), align to 8192 bytes (1 TLB entry) to reduce # of
+	// fills. (Will change this value if it ever gets large page support)
+	#define VRAM_ALIGN 8192
+#else
+	#define VRAM_ALIGN 16
+#endif
+
+// vram ptr received from mmap/malloc/alloc (will deallocate using this)
+static uint16_t *vram_ptr_orig = NULL;
+
+#ifdef GPULIB_USE_MMAP
 static int map_vram(void)
 {
-  gpu.vram = gpu.mmap(VRAM_SIZE);
+  gpu.vram = vram_ptr_orig = gpu.mmap(VRAM_SIZE + (VRAM_ALIGN-1));
   if (gpu.vram != NULL) {
-    gpu.vram += 4096 / 2;
+	// 4kb guard in front
+    gpu.vram += (4096 / 2);
+	// Align
+	gpu.vram = (uint16_t*)(((uintptr_t)gpu.vram + (VRAM_ALIGN-1)) & ~(VRAM_ALIGN-1));
     return 0;
   }
   else {
@@ -156,9 +177,53 @@ static int map_vram(void)
     return -1;
   }
 }
+#else
+static int map_vram(void)
+{
+  gpu.vram = vram_ptr_orig = (uint16_t*)calloc(VRAM_SIZE + (VRAM_ALIGN-1), 1);
+  if (gpu.vram != NULL) {
+	// 4kb guard in front
+    gpu.vram += (4096 / 2);
+	// Align
+	gpu.vram = (uint16_t*)(((uintptr_t)gpu.vram + (VRAM_ALIGN-1)) & ~(VRAM_ALIGN-1));
+    return 0;
+  } else {
+    fprintf(stderr, "could not allocate vram, expect crashes\n");
+    return -1;
+  }
+}
+static int allocate_vram(void)
+{
+  gpu.vram = vram_ptr_orig = (uint16_t*)calloc(VRAM_SIZE + (VRAM_ALIGN-1), 1);
+  if (gpu.vram != NULL) {
+	// 4kb guard in front
+    gpu.vram += (4096 / 2);
+	// Align
+	gpu.vram = (uint16_t*)(((uintptr_t)gpu.vram + (VRAM_ALIGN-1)) & ~(VRAM_ALIGN-1));
+    return 0;
+  } else {
+    fprintf(stderr, "could not allocate vram, expect crashes\n");
+    return -1;
+  }
+}
+#endif
 
 long GPUinit(void)
 {
+#ifndef GPULIB_USE_MMAP
+  if (gpu.vram == NULL) {
+    if (allocate_vram() != 0) {
+      printf("ERROR: could not allocate VRAM, exiting..\n");
+	  exit(1);
+	}
+  }
+#endif
+
+  extern uint32_t hSyncCount;         // in psxcounters.cpp
+  extern uint32_t frame_counter;      // in psxcounters.cpp
+  gpu.state.hcnt = &hSyncCount;
+  gpu.state.frame_count = &frame_counter;
+
   int ret;
   ret  = vout_init();
   ret |= renderer_init();
@@ -169,30 +234,31 @@ long GPUinit(void)
   gpu.cmd_len = 0;
   do_reset();
 
-  if (gpu.mmap != NULL) {
-    if (map_vram() != 0)
-      ret = -1;
-  }
   return ret;
 }
 
 long GPUshutdown(void)
 {
-  long ret;
-
   renderer_finish();
-  ret = vout_finish();
-  if (gpu.vram != NULL) {
-    gpu.vram -= 4096 / 2;
-    gpu.munmap(gpu.vram, VRAM_SIZE);
+  long ret = vout_finish();
+
+  if (vram_ptr_orig != NULL) {
+#ifdef GPULIB_USE_MMAP
+    gpu.munmap(vram_ptr_orig, VRAM_SIZE);
+#else
+    free(vram_ptr_orig);
+#endif
   }
-  gpu.vram = NULL;
+  vram_ptr_orig = gpu.vram = NULL;
 
   return ret;
 }
 
 void GPUwriteStatus(uint32_t data)
 {
+	//senquack TODO: Would it be wise to add cmd buffer flush here, since
+	// status settings can affect commands already in buffer?
+
   static const short hres[8] = { 256, 368, 320, 384, 512, 512, 640, 640 };
   static const short vres[4] = { 240, 480, 256, 480 };
   uint32_t cmd = data >> 24;
@@ -241,6 +307,7 @@ void GPUwriteStatus(uint32_t data)
       break;
     case 0x08:
       gpu.status.reg = (gpu.status.reg & ~0x7f0000) | ((data & 0x3F) << 17) | ((data & 0x40) << 10);
+
       gpu.screen.hres = hres[(gpu.status.reg >> 16) & 7];
       gpu.screen.vres = vres[(gpu.status.reg >> 19) & 3];
       update_width();
@@ -387,7 +454,7 @@ static noinline int do_cmd_list_skip(uint32_t *data, int count, int *last_cmd)
 
     switch (cmd) {
       case 0x02:
-        if ((list[2] & 0x3ff) > gpu.screen.w || ((list[2] >> 16) & 0x1ff) > gpu.screen.h)
+        if ((int)(list[2] & 0x3ff) > gpu.screen.w || (int)((list[2] >> 16) & 0x1ff) > gpu.screen.h)
           // clearing something large, don't skip
           do_cmd_list(list, 3, &dummy);
         else

From 45309e8eafc8bce59be1a59b2962783f1cbbda02 Mon Sep 17 00:00:00 2001
From: M4xw <m4x@m4xw.net>
Date: Thu, 28 Mar 2019 21:17:02 +0100
Subject: [PATCH 2/8] Add ipch to .gitignore

---
 .gitignore | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/.gitignore b/.gitignore
index 27671da9..cbae72ba 100644
--- a/.gitignore
+++ b/.gitignore
@@ -14,3 +14,5 @@ obj/
 
 # Switch
 *.d
+.vscode/ipch/*
+

From 9da984e84bad56be9dacd28c9e4886dff9dca099 Mon Sep 17 00:00:00 2001
From: M4xw <m4x@m4xw.net>
Date: Mon, 1 Apr 2019 11:41:53 +0200
Subject: [PATCH 3/8] Buildfix and Unai changes Special thanks to retrowertz!

---
 .gitignore                     |  1 -
 Makefile                       |  2 ++
 Makefile.libretro              |  8 +----
 frontend/libretro.c            | 66 ++++++++++++++++++++++++++++++++++
 frontend/main.c                |  7 ++++
 frontend/menu.c                | 32 +++++++++++------
 frontend/plugin_lib.h          |  7 ++++
 frontend/switch/pthread.h      | 28 +++++++--------
 jni/Android.mk                 |  4 +++
 plugins/gpu_unai/Makefile      |  5 ++-
 plugins/gpu_unai/gpu.cpp       |  2 +-
 plugins/gpu_unai/gpu_inner.h   | 19 +++++-----
 plugins/gpu_unai/gpulib_if.cpp | 17 ++++-----
 plugins/gpulib/gpu.c           |  9 ++---
 14 files changed, 151 insertions(+), 56 deletions(-)

diff --git a/.gitignore b/.gitignore
index cbae72ba..f8e88089 100644
--- a/.gitignore
+++ b/.gitignore
@@ -15,4 +15,3 @@ obj/
 # Switch
 *.d
 .vscode/ipch/*
-
diff --git a/Makefile b/Makefile
index 18529795..0f057907 100644
--- a/Makefile
+++ b/Makefile
@@ -147,6 +147,8 @@ plugins/dfxvideo/gpulib_if.o: plugins/dfxvideo/prim.c plugins/dfxvideo/soft.c
 OBJS += plugins/dfxvideo/gpulib_if.o
 endif
 ifeq "$(BUILTIN_GPU)" "unai"
+CFLAGS += -DUSE_GPULIB=1 -DGPU_UNAI
+CFLAGS += -DINLINE="static __inline__" -Dasm="__asm__ __volatile__"
 OBJS += plugins/gpu_unai/gpulib_if.o
 ifeq "$(ARCH)" "arm"
 OBJS += plugins/gpu_unai/gpu_arm.o
diff --git a/Makefile.libretro b/Makefile.libretro
index 3da2a39e..5831e9ef 100644
--- a/Makefile.libretro
+++ b/Makefile.libretro
@@ -22,10 +22,6 @@ AS ?= as
 CC_AS ?= $(CC)
 CFLAGS ?=
 
-CFLAGS += -DINLINE="static __inline__" -Dasm="__asm__ __volatile__" -DUSE_GPULIB=1
-USE_DYNAREC = 0
-BUILTIN_GPU = unai
-
 TARGET_NAME := pcsx_rearmed
 GIT_VERSION := " $(shell git rev-parse --short HEAD || echo unknown)"
 ifneq ($(GIT_VERSION)," unknown")
@@ -49,8 +45,6 @@ EXTRA_LDFLAGS =
 ifeq ($(platform), unix)
 	TARGET := $(TARGET_NAME)_libretro.so
 	fpic := -fPIC
-	BUILTIN_GPU = unai
-	USE_DYNAREC = 0
 ifneq ($(findstring SunOS,$(shell uname -s)),)
 	CC = gcc
 endif
@@ -102,7 +96,7 @@ else ifeq ($(platform), libnx)
    CFLAGS += -O3 -fomit-frame-pointer -ffast-math -I$(DEVKITPRO)/libnx/include/ -fPIE -Wl,--allow-multiple-definition -include $(LIBNX)/include/switch.h
    CFLAGS += -specs=$(DEVKITPRO)/libnx/switch.specs -DNO_OS -DNO_DYLIB -DNO_SOCKET -D__arm64__ -D__ARM_NEON__
    CFLAGS += -D__SWITCH__
-   CFLAGS += -DARM -D__aarch64__=1 -march=armv8-a -mtune=cortex-a57 -mtp=soft -DHAVE_INTTYPES -DLSB_FIRST -DINLINE=inline -ffast-math -mcpu=cortex-a57+crc+fp+simd -ffunction-sections
+   CFLAGS += -DARM -D__aarch64__=1 -march=armv8-a -mtune=cortex-a57 -mtp=soft -DHAVE_INTTYPES -DLSB_FIRST -ffast-math -mcpu=cortex-a57+crc+fp+simd -ffunction-sections
    CFLAGS += -Ifrontend/switch -ftree-vectorize
    CFLAGS += $(DEFINES_THREAD)
    OBJS += frontend/switch/pthread.o
diff --git a/frontend/libretro.c b/frontend/libretro.c
index 4fe35cb4..092a5f37 100644
--- a/frontend/libretro.c
+++ b/frontend/libretro.c
@@ -496,6 +496,13 @@ void retro_set_environment(retro_environment_t cb)
       { "pcsx_rearmed_negcon_response", "NegCon Twist Response; linear|quadratic|cubic" },
       { "pcsx_rearmed_vibration", "Enable Vibration; enabled|disabled" },
       { "pcsx_rearmed_dithering", "Enable Dithering; enabled|disabled" },
+#ifdef GPU_UNAI
+      { "pcsx_rearmed_blending", "Enable Blending; enabled|disabled" },
+      { "pcsx_rearmed_lighting", "Enable Lighting; enabled|disabled" },
+      { "pcsx_rearmed_fast_lighting", "Enable Fast Lighting; enabled|disabled" },
+      { "pcsx_rearmed_ilace_force", "Enable Forced Interlace; disabled|enabled" },
+      { "pcsx_rearmed_pixel_skip", "Enable Pixel Skip; disabled|enabled" },
+#endif
 #ifndef DRC_DISABLE
       { "pcsx_rearmed_drc", "Dynamic recompiler; enabled|disabled" },
 #ifdef HAVE_PRE_ARMV7
@@ -1448,6 +1455,7 @@ static void update_variables(bool in_flight)
       if (strcmp(var.value, "disabled") == 0) {
          pl_rearmed_cbs.gpu_peops.iUseDither = 0;
          pl_rearmed_cbs.gpu_peopsgl.bDrawDither = 0;
+         pl_rearmed_cbs.gpu_unai.dithering = 0;
 #ifdef __ARM_NEON__
          pl_rearmed_cbs.gpu_neon.allow_dithering = 0;
 #endif
@@ -1455,12 +1463,70 @@ static void update_variables(bool in_flight)
       else if (strcmp(var.value, "enabled") == 0) {
          pl_rearmed_cbs.gpu_peops.iUseDither = 1;
          pl_rearmed_cbs.gpu_peopsgl.bDrawDither = 1;
+         pl_rearmed_cbs.gpu_unai.dithering = 1;
 #ifdef __ARM_NEON__
          pl_rearmed_cbs.gpu_neon.allow_dithering = 1;
 #endif
       }
    }
 
+#ifdef GPU_UNAI
+   var.value = "NULL";
+   var.key = "pcsx_rearmed_ilace_force";
+
+   if (environ_cb(RETRO_ENVIRONMENT_GET_VARIABLE, &var) || var.value)
+   {
+      if (strcmp(var.value, "disabled") == 0)
+         pl_rearmed_cbs.gpu_unai.ilace_force = 0;
+      else if (strcmp(var.value, "enabled") == 0)
+         pl_rearmed_cbs.gpu_unai.ilace_force = 1;
+   }
+
+   var.value = "NULL";
+   var.key = "pcsx_rearmed_pixel_skip";
+
+   if (environ_cb(RETRO_ENVIRONMENT_GET_VARIABLE, &var) || var.value)
+   {
+      if (strcmp(var.value, "disabled") == 0)
+         pl_rearmed_cbs.gpu_unai.pixel_skip = 0;
+      else if (strcmp(var.value, "enabled") == 0)
+         pl_rearmed_cbs.gpu_unai.pixel_skip = 1;
+   }
+
+   var.value = "NULL";
+   var.key = "pcsx_rearmed_lighting";
+
+   if (environ_cb(RETRO_ENVIRONMENT_GET_VARIABLE, &var) || var.value)
+   {
+      if (strcmp(var.value, "disabled") == 0)
+         pl_rearmed_cbs.gpu_unai.lighting = 0;
+      else if (strcmp(var.value, "enabled") == 0)
+         pl_rearmed_cbs.gpu_unai.lighting = 1;
+   }
+
+   var.value = "NULL";
+   var.key = "pcsx_rearmed_fast_lighting";
+
+   if (environ_cb(RETRO_ENVIRONMENT_GET_VARIABLE, &var) || var.value)
+   {
+      if (strcmp(var.value, "disabled") == 0)
+         pl_rearmed_cbs.gpu_unai.fast_lighting = 0;
+      else if (strcmp(var.value, "enabled") == 0)
+         pl_rearmed_cbs.gpu_unai.fast_lighting = 1;
+   }
+
+   var.value = "NULL";
+   var.key = "pcsx_rearmed_blending";
+
+   if (environ_cb(RETRO_ENVIRONMENT_GET_VARIABLE, &var) || var.value)
+   {
+      if (strcmp(var.value, "disabled") == 0)
+         pl_rearmed_cbs.gpu_unai.blending = 0;
+      else if (strcmp(var.value, "enabled") == 0)
+         pl_rearmed_cbs.gpu_unai.blending = 1;
+   }
+#endif // GPU_UNAI
+
 #ifdef __ARM_NEON__
    var.value = "NULL";
    var.key = "pcsx_rearmed_neon_interlace_enable";
diff --git a/frontend/main.c b/frontend/main.c
index 45d25288..4cbfbd52 100644
--- a/frontend/main.c
+++ b/frontend/main.c
@@ -130,6 +130,13 @@ void emu_set_default_config(void)
 	pl_rearmed_cbs.gpu_neon.enhancement_no_main = 0;
 	pl_rearmed_cbs.gpu_peops.iUseDither = 0;
 	pl_rearmed_cbs.gpu_peops.dwActFixes = 1<<7;
+	pl_rearmed_cbs.gpu_unai.ilace_force = 0;
+	pl_rearmed_cbs.gpu_unai.pixel_skip = 0;
+	pl_rearmed_cbs.gpu_unai.lighting = 1;
+	pl_rearmed_cbs.gpu_unai.fast_lighting = 1;
+	pl_rearmed_cbs.gpu_unai.blending = 1;
+	pl_rearmed_cbs.gpu_unai.dithering = 0;
+	// old gpu_unai config
 	pl_rearmed_cbs.gpu_unai.abe_hack =
 	pl_rearmed_cbs.gpu_unai.no_light =
 	pl_rearmed_cbs.gpu_unai.no_blend = 0;
diff --git a/frontend/menu.c b/frontend/menu.c
index babe1092..47523b20 100644
--- a/frontend/menu.c
+++ b/frontend/menu.c
@@ -305,14 +305,14 @@ static void menu_sync_config(void)
 	cycle_multiplier = 10000 / psx_clock;
 
 	switch (in_type_sel1) {
-	case 1:  in_type1 = PSE_PAD_TYPE_ANALOGPAD; break;
-	case 2:  in_type1 = PSE_PAD_TYPE_NEGCON;    break;
-	default: in_type1 = PSE_PAD_TYPE_STANDARD;
+	case 1:  in_type[0] = PSE_PAD_TYPE_ANALOGPAD; break;
+	case 2:  in_type[0] = PSE_PAD_TYPE_NEGCON;    break;
+	default: in_type[0] = PSE_PAD_TYPE_STANDARD;
 	}
 	switch (in_type_sel2) {
-	case 1:  in_type2 = PSE_PAD_TYPE_ANALOGPAD; break;
-	case 2:  in_type2 = PSE_PAD_TYPE_NEGCON;    break;
-	default: in_type2 = PSE_PAD_TYPE_STANDARD;
+	case 1:  in_type[1] = PSE_PAD_TYPE_ANALOGPAD; break;
+	case 2:  in_type[1] = PSE_PAD_TYPE_NEGCON;    break;
+	default: in_type[1] = PSE_PAD_TYPE_STANDARD;
 	}
 	if (in_evdev_allow_abs_only != allow_abs_only_old) {
 		in_probe();
@@ -422,6 +422,12 @@ static const struct {
 	CE_INTVAL_V(frameskip, 3),
 	CE_INTVAL_P(gpu_peops.iUseDither),
 	CE_INTVAL_P(gpu_peops.dwActFixes),
+	CE_INTVAL_P(gpu_unai.ilace_force),
+	CE_INTVAL_P(gpu_unai.pixel_skip),
+	CE_INTVAL_P(gpu_unai.lighting),
+	CE_INTVAL_P(gpu_unai.fast_lighting),
+	CE_INTVAL_P(gpu_unai.blending),
+	CE_INTVAL_P(gpu_unai.dithering),
 	CE_INTVAL_P(gpu_unai.lineskip),
 	CE_INTVAL_P(gpu_unai.abe_hack),
 	CE_INTVAL_P(gpu_unai.no_light),
@@ -1358,10 +1364,16 @@ static int menu_loop_plugin_gpu_neon(int id, int keys)
 
 static menu_entry e_menu_plugin_gpu_unai[] =
 {
-	mee_onoff     ("Skip every 2nd line",        0, pl_rearmed_cbs.gpu_unai.lineskip, 1),
-	mee_onoff     ("Abe's Odyssey hack",         0, pl_rearmed_cbs.gpu_unai.abe_hack, 1),
-	mee_onoff     ("Disable lighting",           0, pl_rearmed_cbs.gpu_unai.no_light, 1),
-	mee_onoff     ("Disable blending",           0, pl_rearmed_cbs.gpu_unai.no_blend, 1),
+	//mee_onoff     ("Skip every 2nd line",        0, pl_rearmed_cbs.gpu_unai.lineskip, 1),
+	//mee_onoff     ("Abe's Odyssey hack",         0, pl_rearmed_cbs.gpu_unai.abe_hack, 1),
+	//mee_onoff     ("Disable lighting",           0, pl_rearmed_cbs.gpu_unai.no_light, 1),
+	//mee_onoff     ("Disable blending",           0, pl_rearmed_cbs.gpu_unai.no_blend, 1),
+	mee_onoff     ("Interlace",                  0, pl_rearmed_cbs.gpu_unai.ilace_force, 1),
+	mee_onoff     ("Dithering",                  0, pl_rearmed_cbs.gpu_unai.dithering, 1),
+	mee_onoff     ("Lighting",                   0, pl_rearmed_cbs.gpu_unai.lighting, 1),
+	mee_onoff     ("Fast lighting",              0, pl_rearmed_cbs.gpu_unai.fast_lighting, 1),
+	mee_onoff     ("Blending",                   0, pl_rearmed_cbs.gpu_unai.blending, 1),
+	mee_onoff     ("Pixel skip",                 0, pl_rearmed_cbs.gpu_unai.pixel_skip, 1),
 	mee_end,
 };
 
diff --git a/frontend/plugin_lib.h b/frontend/plugin_lib.h
index 92e62e9d..d51c5e7d 100644
--- a/frontend/plugin_lib.h
+++ b/frontend/plugin_lib.h
@@ -80,6 +80,13 @@ struct rearmed_cbs {
 		int   dwFrameRateTicks;
 	} gpu_peops;
 	struct {
+		int ilace_force;
+		int pixel_skip;
+		int lighting;
+		int fast_lighting;
+		int blending;
+		int dithering;
+		// old gpu_unai config for compatibility
 		int   abe_hack;
 		int   no_light, no_blend;
 		int   lineskip;
diff --git a/frontend/switch/pthread.h b/frontend/switch/pthread.h
index d01fd8cf..0aea0a43 100644
--- a/frontend/switch/pthread.h
+++ b/frontend/switch/pthread.h
@@ -51,30 +51,30 @@ typedef struct
    void *tls_tp; /* !! Offset needs to be TLS+0x1F8 for __aarch64_read_tp !! */
 } ThreadVars;
 
-static INLINE ThreadVars *getThreadVars(void)
+INLINE ThreadVars *getThreadVars(void)
 {
    return (ThreadVars *)((u8 *)armGetTls() + 0x1E0);
 }
 
-static INLINE Thread threadGetCurrent(void)
+INLINE Thread threadGetCurrent(void)
 {
    ThreadVars *tv = getThreadVars();
    return *tv->thread_ptr;
 }
 
-static INLINE pthread_t pthread_self(void)
+INLINE pthread_t pthread_self(void)
 {
    return threadGetCurrent();
 }
 
-static INLINE int pthread_mutex_init(pthread_mutex_t *mutex, const pthread_mutexattr_t *attr)
+INLINE int pthread_mutex_init(pthread_mutex_t *mutex, const pthread_mutexattr_t *attr)
 {
    mutexInit(mutex);
 
    return 0;
 }
 
-static INLINE int pthread_mutex_destroy(pthread_mutex_t *mutex)
+INLINE int pthread_mutex_destroy(pthread_mutex_t *mutex)
 {
    /* Nothing */
    *mutex = 0;
@@ -82,13 +82,13 @@ static INLINE int pthread_mutex_destroy(pthread_mutex_t *mutex)
    return 0;
 }
 
-static INLINE int pthread_mutex_lock(pthread_mutex_t *mutex)
+INLINE int pthread_mutex_lock(pthread_mutex_t *mutex)
 {
    mutexLock(mutex);
    return 0;
 }
 
-static INLINE int pthread_mutex_unlock(pthread_mutex_t *mutex)
+INLINE int pthread_mutex_unlock(pthread_mutex_t *mutex)
 {
    mutexUnlock(mutex);
 
@@ -102,7 +102,7 @@ INLINE int pthread_detach(pthread_t thread)
    return 0;
 }
 
-static INLINE int pthread_join(pthread_t thread, void **retval)
+INLINE int pthread_join(pthread_t thread, void **retval)
 {
    printf("[Threading]: Waiting for Thread Exit\n");
    threadWaitForExit(&thread);
@@ -111,39 +111,39 @@ static INLINE int pthread_join(pthread_t thread, void **retval)
    return 0;
 }
 
-static INLINE int pthread_mutex_trylock(pthread_mutex_t *mutex)
+INLINE int pthread_mutex_trylock(pthread_mutex_t *mutex)
 {
    return mutexTryLock(mutex) ? 0 : 1;
 }
 
-static INLINE int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex)
+INLINE int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex)
 {
    condvarWait(cond, mutex);
 
    return 0;
 }
 
-static INLINE int pthread_cond_timedwait(pthread_cond_t *cond, pthread_mutex_t *mutex, const struct timespec *abstime)
+INLINE int pthread_cond_timedwait(pthread_cond_t *cond, pthread_mutex_t *mutex, const struct timespec *abstime)
 {
    condvarWaitTimeout(cond, mutex, abstime->tv_nsec);
 
    return 0;
 }
 
-static INLINE int pthread_cond_init(pthread_cond_t *cond, const pthread_condattr_t *attr)
+INLINE int pthread_cond_init(pthread_cond_t *cond, const pthread_condattr_t *attr)
 {
    condvarInit(cond);
 
    return 0;
 }
 
-static INLINE int pthread_cond_signal(pthread_cond_t *cond)
+INLINE int pthread_cond_signal(pthread_cond_t *cond)
 {
    condvarWakeOne(cond);
    return 0;
 }
 
-static INLINE int pthread_cond_broadcast(pthread_cond_t *cond)
+INLINE int pthread_cond_broadcast(pthread_cond_t *cond)
 {
    condvarWakeAll(cond);
    return 0;
diff --git a/jni/Android.mk b/jni/Android.mk
index 756f54cc..4c7021d8 100644
--- a/jni/Android.mk
+++ b/jni/Android.mk
@@ -91,10 +91,14 @@ ifeq ($(TARGET_ARCH_ABI),armeabi-v7a)
                  $(FRONTEND_DIR)/cspace_neon.S
   SOURCES_C   += $(NEON_DIR)/psx_gpu_if.c
 else ifeq ($(TARGET_ARCH_ABI),armeabi)
+  COREFLAGS += -DUSE_GPULIB=1 -DGPU_UNAI
+  COREFLAGS += -DINLINE="static __inline__" -Dasm="__asm__ __volatile__"
   SOURCES_ASM += $(UNAI_DIR)/gpu_arm.S \
                  $(FRONTEND_DIR)/cspace_arm.S
   SOURCES_C += $(UNAI_DIR)/gpulib_if.cpp
 else
+  COREFLAGS += -DUSE_GPULIB=1 -DGPU_UNAI
+  COREFLAGS += -DINLINE="static __inline__" -Dasm="__asm__ __volatile__"
   SOURCES_C += $(UNAI_DIR)/gpulib_if.cpp
 endif
 
diff --git a/plugins/gpu_unai/Makefile b/plugins/gpu_unai/Makefile
index 1075ee52..fcd60662 100644
--- a/plugins/gpu_unai/Makefile
+++ b/plugins/gpu_unai/Makefile
@@ -1,6 +1,9 @@
 CFLAGS += -ggdb -Wall -O3 -ffast-math
 CFLAGS += -DREARMED
 CFLAGS += -I../../include
+CFLAGS += -DINLINE="static __inline__"
+CFLAGS += -Dasm="__asm__ __volatile__"
+CFLAGS += -DUSE_GPULIB=1
 
 include ../../config.mak
 
@@ -8,7 +11,7 @@ SRC_STANDALONE += gpu.cpp
 SRC_GPULIB += gpulib_if.cpp
 
 ifeq "$(ARCH)" "arm"
-SRC += gpu_arm.s
+SRC += gpu_arm.S
 endif
 
 #BIN_STANDALONE = gpuPCSX4ALL.so
diff --git a/plugins/gpu_unai/gpu.cpp b/plugins/gpu_unai/gpu.cpp
index cac64a31..4e12c4fc 100644
--- a/plugins/gpu_unai/gpu.cpp
+++ b/plugins/gpu_unai/gpu.cpp
@@ -22,7 +22,7 @@
 #include <stddef.h>
 #include "plugins.h"
 #include "psxcommon.h"
-#include "port.h"
+//#include "port.h"
 #include "gpu_unai.h"
 
 #define GPU_INLINE static inline __attribute__((always_inline))
diff --git a/plugins/gpu_unai/gpu_inner.h b/plugins/gpu_unai/gpu_inner.h
index 2228f04e..723e09f2 100644
--- a/plugins/gpu_unai/gpu_inner.h
+++ b/plugins/gpu_unai/gpu_inner.h
@@ -36,17 +36,20 @@
                                    //  that wouldn't end up displayed on
                                    //  low-res screen using simple downscaler)
 
-#ifdef __arm__
-#ifndef ENABLE_GPU_ARMV7
+//#ifdef __arm__
+//#ifndef ENABLE_GPU_ARMV7
 /* ARMv5 */
-#include "gpu_inner_blend_arm5.h"
-#else
+//#include "gpu_inner_blend_arm5.h"
+//#else
 /* ARMv7 optimized */
-#include "gpu_inner_blend_arm7.h"
-#endif
-#else
+//#include "gpu_inner_blend_arm7.h"
+//#endif
+//#else
+//#include "gpu_inner_blend.h"
+//#endif
+
+// TODO: use the arm-optimized gpu_inner_blends for arm builds
 #include "gpu_inner_blend.h"
-#endif
 
 #include "gpu_inner_quantization.h"
 #include "gpu_inner_light.h"
diff --git a/plugins/gpu_unai/gpulib_if.cpp b/plugins/gpu_unai/gpulib_if.cpp
index d62b53cd..cd9e3713 100644
--- a/plugins/gpu_unai/gpulib_if.cpp
+++ b/plugins/gpu_unai/gpulib_if.cpp
@@ -622,20 +622,17 @@ void renderer_set_interlace(int enable, int is_odd)
 {
 }
 
-#include "../frontend/plugin_lib.h"
+#include "../../frontend/plugin_lib.h"
 // Handle any gpulib settings applicable to gpu_unai:
-//void renderer_set_config(const gpulib_config_t *config)
 void renderer_set_config(const struct rearmed_cbs *cbs)
 {
   gpu_unai.vram = (u16*)gpu.vram;
-  gpu_unai.config.lighting = !cbs->gpu_unai.no_light;
-  gpu_unai.config.blending = !cbs->gpu_unai.no_blend;
-  //force_interlace = cbs->gpu_unai.lineskip;
-  //enableAbbeyHack = cbs->gpu_unai.abe_hack;
-  //light = !cbs->gpu_unai.no_light;
-  //blend = !cbs->gpu_unai.no_blend;
-
-  //GPU_FrameBuffer = (u16 *)gpu.vram;
+  gpu_unai.config.ilace_force   = cbs->gpu_unai.ilace_force;
+  gpu_unai.config.pixel_skip    = cbs->gpu_unai.pixel_skip;
+  gpu_unai.config.lighting      = cbs->gpu_unai.lighting;
+  gpu_unai.config.fast_lighting = cbs->gpu_unai.fast_lighting;
+  gpu_unai.config.blending      = cbs->gpu_unai.blending;
+  gpu_unai.config.dithering     = cbs->gpu_unai.dithering;
 }
 
 // vim:shiftwidth=2:expandtab
diff --git a/plugins/gpulib/gpu.c b/plugins/gpulib/gpu.c
index d79e121d..e5bab593 100644
--- a/plugins/gpulib/gpu.c
+++ b/plugins/gpulib/gpu.c
@@ -9,6 +9,7 @@
  */
 
 #include <stdio.h>
+#include <stdlib.h>
 #include <string.h>
 //#include "../../libpcsxcore/plugins.h"    // For GPUFreeze_t, GPUScreenInfo_t
 #include "gpu.h"
@@ -219,10 +220,10 @@ long GPUinit(void)
   }
 #endif
 
-  extern uint32_t hSyncCount;         // in psxcounters.cpp
-  extern uint32_t frame_counter;      // in psxcounters.cpp
-  gpu.state.hcnt = &hSyncCount;
-  gpu.state.frame_count = &frame_counter;
+  //extern uint32_t hSyncCount;         // in psxcounters.cpp
+  //extern uint32_t frame_counter;      // in psxcounters.cpp
+  //gpu.state.hcnt = &hSyncCount;
+  //gpu.state.frame_count = &frame_counter;
 
   int ret;
   ret  = vout_init();

From 691d1b0064b5b62f0a2ce9bf0ef2100f964bfc4f Mon Sep 17 00:00:00 2001
From: M4xw <m4x@m4xw.net>
Date: Fri, 26 Apr 2019 21:50:19 +0200
Subject: [PATCH 4/8] [LIBNX] Deprecate switch_pthread, update rthreads

---
 Makefile.libretro         |   5 +-
 frontend/switch/pthread.c |  60 --------------
 frontend/switch/pthread.h | 166 --------------------------------------
 3 files changed, 1 insertion(+), 230 deletions(-)
 delete mode 100644 frontend/switch/pthread.c
 delete mode 100644 frontend/switch/pthread.h

diff --git a/Makefile.libretro b/Makefile.libretro
index 5831e9ef..fc261c70 100644
--- a/Makefile.libretro
+++ b/Makefile.libretro
@@ -92,14 +92,11 @@ else ifeq ($(platform), libnx)
    ARCH := arm64
    BUILTIN_GPU = unai
    HAVE_VFS_FD = 0
-   DEFINES_THREAD := -Dpthread_t=Thread -Dpthread_mutex_t=Mutex -Dpthread_mutexattr_t='void*' -Dpthread_attr_t=int -Dpthread_cond_t=CondVar -Dpthread_condattr_t='int' -D_SYS__PTHREADTYPES_H_
    CFLAGS += -O3 -fomit-frame-pointer -ffast-math -I$(DEVKITPRO)/libnx/include/ -fPIE -Wl,--allow-multiple-definition -include $(LIBNX)/include/switch.h
    CFLAGS += -specs=$(DEVKITPRO)/libnx/switch.specs -DNO_OS -DNO_DYLIB -DNO_SOCKET -D__arm64__ -D__ARM_NEON__
    CFLAGS += -D__SWITCH__
    CFLAGS += -DARM -D__aarch64__=1 -march=armv8-a -mtune=cortex-a57 -mtp=soft -DHAVE_INTTYPES -DLSB_FIRST -ffast-math -mcpu=cortex-a57+crc+fp+simd -ffunction-sections
-   CFLAGS += -Ifrontend/switch -ftree-vectorize
-   CFLAGS += $(DEFINES_THREAD)
-   OBJS += frontend/switch/pthread.o
+   CFLAGS += -ftree-vectorize
    LIBPTHREAD :=
    USE_DYNAREC = 0
    STATIC_LINKING=1
diff --git a/frontend/switch/pthread.c b/frontend/switch/pthread.c
deleted file mode 100644
index beab4376..00000000
--- a/frontend/switch/pthread.c
+++ /dev/null
@@ -1,60 +0,0 @@
-/* Copyright  (C) 2018 - M4xw <m4x@m4xw.net>, RetroArch Team
- *
- * ---------------------------------------------------------------------------------------
- * The following license statement only applies to this file (switch_pthread.c).
- * ---------------------------------------------------------------------------------------
- *
- * Permission is hereby granted, free of charge,
- * to any person obtaining a copy of this software and associated documentation files (the "Software"),
- * to deal in the Software without restriction, including without limitation the rights to
- * use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,
- * and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
- *
- * The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
- * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
- * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
- * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
- * WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
- * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
- */
-
-#include "pthread.h"
-
-#define STACKSIZE 1000000 * 12 // 12 MB
-static uint32_t threadCounter = 1;
-int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine)(void *), void *arg)
-{
-   u32 prio = 0;
-
-   Thread new_switch_thread;
-
-   svcGetThreadPriority(&prio, CUR_THREAD_HANDLE);
-
-   // Launch threads on Core 1
-   int rc = threadCreate(&new_switch_thread, (void (*)(void *))start_routine, arg, STACKSIZE, prio - 1, 1);
-
-   if (R_FAILED(rc))
-   {
-      return EAGAIN;
-   }
-
-   printf("[Threading]: Starting Thread(#%i)\n", threadCounter);
-   if (R_FAILED(threadStart(&new_switch_thread)))
-   {
-      threadClose(&new_switch_thread);
-      return -1;
-   }
-
-   *thread = new_switch_thread;
-
-   return 0;
-}
-
-void pthread_exit(void *retval)
-{
-   (void)retval;
-   printf("[Threading]: Exiting Thread\n");
-   svcExitThread();
-}
diff --git a/frontend/switch/pthread.h b/frontend/switch/pthread.h
deleted file mode 100644
index 0aea0a43..00000000
--- a/frontend/switch/pthread.h
+++ /dev/null
@@ -1,166 +0,0 @@
-/* Copyright  (C) 2018 - M4xw <m4x@m4xw.net>, RetroArch Team
- *
- * ---------------------------------------------------------------------------------------
- * The following license statement only applies to this file (switch_pthread.h).
- * ---------------------------------------------------------------------------------------
- *
- * Permission is hereby granted, free of charge,
- * to any person obtaining a copy of this software and associated documentation files (the "Software"),
- * to deal in the Software without restriction, including without limitation the rights to
- * use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,
- * and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
- *
- * The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
- * INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
- * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
- * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
- * WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
- * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
- */
-
-#ifndef _SWITCH_PTHREAD_WRAP_
-#define _SWITCH_PTHREAD_WRAP_
-
-#include <time.h>
-#include <stdio.h>
-#include <switch.h>
-#include <errno.h>
-
-#define THREADVARS_MAGIC 0x21545624 /* !TV$ */
-int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine)(void *), void *arg);
-void pthread_exit(void *retval);
-
-/* This structure is exactly 0x20 bytes, if more is needed modify getThreadVars() below */
-typedef struct
-{
-   /* Magic value used to check if the struct is initialized */
-   u32 magic;
-
-   /* Thread handle, for mutexes */
-   Handle handle;
-
-   /* Pointer to the current thread (if exists) */
-   Thread *thread_ptr;
-
-   /* Pointer to this thread's newlib state */
-   struct _reent *reent;
-
-   /* Pointer to this thread's thread-local segment */
-   void *tls_tp; /* !! Offset needs to be TLS+0x1F8 for __aarch64_read_tp !! */
-} ThreadVars;
-
-INLINE ThreadVars *getThreadVars(void)
-{
-   return (ThreadVars *)((u8 *)armGetTls() + 0x1E0);
-}
-
-INLINE Thread threadGetCurrent(void)
-{
-   ThreadVars *tv = getThreadVars();
-   return *tv->thread_ptr;
-}
-
-INLINE pthread_t pthread_self(void)
-{
-   return threadGetCurrent();
-}
-
-INLINE int pthread_mutex_init(pthread_mutex_t *mutex, const pthread_mutexattr_t *attr)
-{
-   mutexInit(mutex);
-
-   return 0;
-}
-
-INLINE int pthread_mutex_destroy(pthread_mutex_t *mutex)
-{
-   /* Nothing */
-   *mutex = 0;
-
-   return 0;
-}
-
-INLINE int pthread_mutex_lock(pthread_mutex_t *mutex)
-{
-   mutexLock(mutex);
-   return 0;
-}
-
-INLINE int pthread_mutex_unlock(pthread_mutex_t *mutex)
-{
-   mutexUnlock(mutex);
-
-   return 0;
-}
-
-INLINE int pthread_detach(pthread_t thread)
-{
-   (void)thread;
-   /* Nothing for now */
-   return 0;
-}
-
-INLINE int pthread_join(pthread_t thread, void **retval)
-{
-   printf("[Threading]: Waiting for Thread Exit\n");
-   threadWaitForExit(&thread);
-   threadClose(&thread);
-
-   return 0;
-}
-
-INLINE int pthread_mutex_trylock(pthread_mutex_t *mutex)
-{
-   return mutexTryLock(mutex) ? 0 : 1;
-}
-
-INLINE int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex)
-{
-   condvarWait(cond, mutex);
-
-   return 0;
-}
-
-INLINE int pthread_cond_timedwait(pthread_cond_t *cond, pthread_mutex_t *mutex, const struct timespec *abstime)
-{
-   condvarWaitTimeout(cond, mutex, abstime->tv_nsec);
-
-   return 0;
-}
-
-INLINE int pthread_cond_init(pthread_cond_t *cond, const pthread_condattr_t *attr)
-{
-   condvarInit(cond);
-
-   return 0;
-}
-
-INLINE int pthread_cond_signal(pthread_cond_t *cond)
-{
-   condvarWakeOne(cond);
-   return 0;
-}
-
-INLINE int pthread_cond_broadcast(pthread_cond_t *cond)
-{
-   condvarWakeAll(cond);
-   return 0;
-}
-
-INLINE int pthread_cond_destroy(pthread_cond_t *cond)
-{
-   /* Nothing */
-   return 0;
-}
-
-INLINE int pthread_equal(pthread_t t1, pthread_t t2)
-{
-   if (t1.handle == t2.handle)
-      return 1;
-
-   return 0;
-}
-
-#endif

From c43e0b63367473583ca5db49cb54ad6efc32f7e2 Mon Sep 17 00:00:00 2001
From: M4xw <m4x@m4xw.net>
Date: Sat, 27 Apr 2019 01:07:56 +0200
Subject: [PATCH 5/8] [LIBNX] Build fix

---
 Makefile.libretro | 1 +
 1 file changed, 1 insertion(+)

diff --git a/Makefile.libretro b/Makefile.libretro
index fc261c70..01419c6a 100644
--- a/Makefile.libretro
+++ b/Makefile.libretro
@@ -97,6 +97,7 @@ else ifeq ($(platform), libnx)
    CFLAGS += -D__SWITCH__
    CFLAGS += -DARM -D__aarch64__=1 -march=armv8-a -mtune=cortex-a57 -mtp=soft -DHAVE_INTTYPES -DLSB_FIRST -ffast-math -mcpu=cortex-a57+crc+fp+simd -ffunction-sections
    CFLAGS += -ftree-vectorize
+   CFLAGS += -Ifrontend/switch -ftree-vectorize
    LIBPTHREAD :=
    USE_DYNAREC = 0
    STATIC_LINKING=1

From a962151e5fe40005eddd73029be84e1077c27f1d Mon Sep 17 00:00:00 2001
From: M4xw <m4x@m4xw.net>
Date: Tue, 30 Apr 2019 18:26:06 +0200
Subject: [PATCH 6/8] [LIBNX] Disable dithering by default

---
 frontend/libretro.c | 4 ++++
 1 file changed, 4 insertions(+)

diff --git a/frontend/libretro.c b/frontend/libretro.c
index 092a5f37..b4a98838 100644
--- a/frontend/libretro.c
+++ b/frontend/libretro.c
@@ -495,7 +495,11 @@ void retro_set_environment(retro_environment_t cb)
       { "pcsx_rearmed_negcon_deadzone", "NegCon Twist Deadzone (percent); 0|5|10|15|20|25|30" },
       { "pcsx_rearmed_negcon_response", "NegCon Twist Response; linear|quadratic|cubic" },
       { "pcsx_rearmed_vibration", "Enable Vibration; enabled|disabled" },
+#ifdef HAVE_LIBNX
+      { "pcsx_rearmed_dithering", "Enable Dithering; disabled|enabled" },
+#else
       { "pcsx_rearmed_dithering", "Enable Dithering; enabled|disabled" },
+#endif
 #ifdef GPU_UNAI
       { "pcsx_rearmed_blending", "Enable Blending; enabled|disabled" },
       { "pcsx_rearmed_lighting", "Enable Lighting; enabled|disabled" },

From 7841722cc134f1c0348bdc8537d74c5455e6e911 Mon Sep 17 00:00:00 2001
From: M4xw <m4x@m4xw.net>
Date: Thu, 9 May 2019 13:25:01 +0200
Subject: [PATCH 7/8] Linker build fix

---
 Makefile | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/Makefile b/Makefile
index 0f057907..d660ec9d 100644
--- a/Makefile
+++ b/Makefile
@@ -51,7 +51,7 @@ OBJS += libpcsxcore/cdriso.o libpcsxcore/cdrom.o libpcsxcore/cheat.o libpcsxcore
 	libpcsxcore/psxcommon.o libpcsxcore/psxcounters.o libpcsxcore/psxdma.o libpcsxcore/psxhle.o \
 	libpcsxcore/psxhw.o libpcsxcore/psxinterpreter.o libpcsxcore/psxmem.o libpcsxcore/r3000a.o \
 	libpcsxcore/sio.o libpcsxcore/socket.o libpcsxcore/spu.o
-OBJS += libpcsxcore/gte.o libpcsxcore/gte_nf.o libpcsxcore/gte_divider.o
+OBJS += libpcsxcore/gte.o libpcsxcore/gte_divider.o
 ifeq ($(WANT_ZLIB),1)
 CFLAGS += -Ideps/zlib
 OBJS += deps/zlib/adler32.o \

From 901f0d92d42255630d22f1fbeaba7eb8fe2db726 Mon Sep 17 00:00:00 2001
From: "Tomsic, Jason" <jrtomsic@gmail.com>
Date: Thu, 9 May 2019 15:16:48 -0400
Subject: [PATCH 8/8] adding lakka-switch makefile platform

---
 Makefile.libretro | 10 ++++++++++
 1 file changed, 10 insertions(+)

diff --git a/Makefile.libretro b/Makefile.libretro
index 01419c6a..af86c1b4 100644
--- a/Makefile.libretro
+++ b/Makefile.libretro
@@ -102,6 +102,16 @@ else ifeq ($(platform), libnx)
    USE_DYNAREC = 0
    STATIC_LINKING=1
 
+# Lakka Switch (arm64)
+else ifeq ($(platform), arm64)
+   TARGET := $(TARGET_NAME)_libretro.so
+   ARCH := arm64
+   BUILTIN_GPU = unai
+   fpic := -fPIC
+   CFLAGS := $(filter-out -O2, $(CFLAGS))
+   CFLAGS += -O3 -ftree-vectorize
+   USE_DYNAREC = 0
+
 else ifneq (,$(findstring ios,$(platform)))
 	ARCH := arm
 	USE_DYNAREC ?= 1
